import os
import numpy as np
from PIL import Image
import fitz
from scipy import ndimage
import matplotlib.pyplot as plt
from scipy.ndimage import label, gaussian_filter
import math

# è®¾ç½®å­—ä½“
plt.rcParams['font.sans-serif'] = ['DejaVu Sans', 'Arial']
plt.rcParams['axes.unicode_minus'] = False


class GTLearningCoastlineDetector:
    """Ground Truthå­¦ä¹ å¢å¼ºæµ·å²¸çº¿æ£€æµ‹å™¨"""

    def __init__(self):
        print("âœ… GTå­¦ä¹ æ£€æµ‹å™¨åˆå§‹åŒ–å®Œæˆ")
        self.edge_kernels = self._create_edge_kernels()

    def _create_edge_kernels(self):
        """åˆ›å»ºè¾¹ç¼˜æ£€æµ‹æ ¸"""
        sobel_x = np.array([[-1, 0, 1], [-2, 0, 2], [-1, 0, 1]], dtype=float)
        sobel_y = np.array([[-1, -2, -1], [0, 0, 0], [1, 2, 1]], dtype=float)
        laplacian = np.array([[0, -1, 0], [-1, 4, -1], [0, -1, 0]], dtype=float)
        prewitt_x = np.array([[-1, 0, 1], [-1, 0, 1], [-1, 0, 1]], dtype=float)
        prewitt_y = np.array([[-1, -1, -1], [0, 0, 0], [1, 1, 1]], dtype=float)

        return {
            'sobel_x': sobel_x,
            'sobel_y': sobel_y,
            'laplacian': laplacian,
            'prewitt_x': prewitt_x,
            'prewitt_y': prewitt_y
        }

    def enhanced_color_detection(self, image):
        """å¢å¼ºçš„é¢œè‰²åŒºåŸŸæ£€æµ‹"""
        print("\nğŸ¨ å¢å¼ºé¢œè‰²åŒºåŸŸæ£€æµ‹...")

        if len(image.shape) == 3:
            rgb_image = image.copy()
            if rgb_image.max() <= 1.0:
                rgb_image = (rgb_image * 255).astype(np.uint8)
        else:
            gray = image.copy()
            if gray.max() <= 1.0:
                gray = (gray * 255).astype(np.uint8)
            rgb_image = np.stack([gray, gray, gray], axis=2)

        r, g, b = rgb_image[:, :, 0], rgb_image[:, :, 1], rgb_image[:, :, 2]

        print("   ğŸŒŠ å¢å¼ºè“è‰²æ£€æµ‹ï¼ˆæµ·æ´‹ï¼‰...")
        blue_mask = self._enhanced_blue_detection(r, g, b)
        blue_pixels = np.sum(blue_mask)
        print(f"      æ‰¾åˆ° {blue_pixels:,} ä¸ªè“è‰²åƒç´ ")

        print("   ğŸŒ¿ å¢å¼ºç»¿è‰²æ£€æµ‹ï¼ˆæ¤è¢«ï¼‰...")
        green_mask = self._enhanced_green_detection(r, g, b)
        green_pixels = np.sum(green_mask)
        print(f"      æ‰¾åˆ° {green_pixels:,} ä¸ªç»¿è‰²åƒç´ ")

        print("   ğŸœï¸ æ£€æµ‹åœŸåœ°åŒºåŸŸ...")
        land_mask = self._detect_land_regions(r, g, b)
        land_pixels = np.sum(land_mask)
        print(f"      æ‰¾åˆ° {land_pixels:,} ä¸ªåœŸåœ°åƒç´ ")

        print("   âšª å¢å¼ºç™½è‰²æ£€æµ‹...")
        white_mask = self._enhanced_white_detection(r, g, b)
        white_pixels = np.sum(white_mask)
        print(f"      æ‰¾åˆ° {white_pixels:,} ä¸ªç™½è‰²åƒç´ ")

        return {
            'blue_mask': blue_mask,
            'green_mask': green_mask,
            'land_mask': land_mask,
            'white_mask': white_mask,
            'rgb_image': rgb_image
        }

    def _enhanced_blue_detection(self, r, g, b):
        """å¢å¼ºçš„è“è‰²æ£€æµ‹"""
        strategy1 = (b > r + 25) & (b > g + 25) & (b > 70)
        strategy2 = (b > 100) & (b > r + 15) & (b > g + 15)

        total_intensity = r.astype(float) + g.astype(float) + b.astype(float)
        blue_ratio = b.astype(float) / (total_intensity + 1e-8)
        strategy3 = (blue_ratio > 0.4) & (b > 60) & (total_intensity > 120)

        dark_water = (r < 80) & (g < 80) & (b > 40) & (b > r) & (b > g)
        blue_green_water = (b > 60) & (g > 50) & (b > r + 20) & (g < b + 20)

        blue_mask = strategy1 | strategy2 | strategy3 | dark_water | blue_green_water

        kernel = np.ones((3, 3), dtype=bool)
        blue_mask = ndimage.binary_opening(blue_mask, structure=kernel)
        blue_mask = ndimage.binary_closing(blue_mask, structure=kernel)

        return blue_mask

    def _enhanced_green_detection(self, r, g, b):
        """å¢å¼ºçš„ç»¿è‰²æ£€æµ‹"""
        strategy1 = (g > r + 20) & (g > b + 20) & (g > 80)
        strategy2 = (g > 120) & (g > r + 10) & (g > b + 10)

        ndvi_like = (g.astype(float) - r.astype(float)) / (g.astype(float) + r.astype(float) + 1e-8)
        strategy3 = (ndvi_like > 0.1) & (g > 70)

        natural_green = (g > r + 15) & (g > b) & (g > 60) & (r < 150) & (b < 150)
        dark_green = (g > 40) & (g > r + 10) & (g > b + 5) & (r < 100) & (b < 100)

        green_mask = strategy1 | strategy2 | strategy3 | natural_green | dark_green

        kernel = np.ones((2, 2), dtype=bool)
        green_mask = ndimage.binary_opening(green_mask, structure=kernel)

        return green_mask

    def _detect_land_regions(self, r, g, b):
        """æ£€æµ‹åœŸåœ°åŒºåŸŸ"""
        beach_color = (r > 120) & (g > 100) & (b < 120) & (r > g) & (g > b)
        soil_color = (r > 80) & (g > 60) & (b < 80) & (abs(r.astype(int) - g.astype(int)) < 40)
        rock_color = (abs(r.astype(int) - g.astype(int)) < 20) & \
                     (abs(g.astype(int) - b.astype(int)) < 20) & \
                     (r > 60) & (r < 140)
        red_brown = (r > g + 20) & (r > b + 20) & (r > 80) & (r < 180)
        bare_ground = (r > 60) & (g > 40) & (b < 80) & (r > b + 20)

        land_mask = beach_color | soil_color | rock_color | red_brown | bare_ground
        return land_mask

    def _enhanced_white_detection(self, r, g, b):
        """å¢å¼ºçš„ç™½è‰²æ£€æµ‹"""
        strategy1 = (r > 200) & (g > 200) & (b > 200)

        rgb_diff = np.maximum(np.maximum(np.abs(r.astype(int) - g.astype(int)),
                                         np.abs(g.astype(int) - b.astype(int))),
                              np.abs(r.astype(int) - b.astype(int)))
        strategy2 = (rgb_diff < 30) & (r > 180) & (g > 180) & (b > 180)

        brightness = (r.astype(float) + g.astype(float) + b.astype(float)) / 3
        brightness_mean = gaussian_filter(brightness, sigma=5)
        local_bright = (brightness - brightness_mean) > 25
        strategy3 = local_bright & (brightness > 150)

        foam_like = (r > 160) & (g > 160) & (b > 160) & (rgb_diff < 50)
        high_reflect = (brightness > 220) & (rgb_diff < 25)

        white_mask = strategy1 | strategy2 | strategy3 | foam_like | high_reflect
        return white_mask

    def learn_from_ground_truth(self, gt_image, original_image):
        """ä»Ground Truthå­¦ä¹ æµ·å²¸çº¿ç‰¹å¾æ¨¡å¼"""
        print("   ğŸ“ ä»Ground Truthå­¦ä¹ æµ·å²¸çº¿æ¨¡å¼...")

        if gt_image is None:
            return None

        # 1. æå–GTä¸­çš„æµ·å²¸çº¿
        if len(gt_image.shape) == 3:
            gt_gray = np.dot(gt_image[..., :3], [0.2989, 0.5870, 0.1140])
        else:
            gt_gray = gt_image.copy()

        # å¤šé˜ˆå€¼æå–GTæµ·å²¸çº¿
        gt_coastline_high = (gt_gray > 200).astype(float)
        gt_coastline_med = (gt_gray > 150).astype(float)
        gt_coastline_low = (gt_gray > 100).astype(float)

        # ç»„åˆGTæµ·å²¸çº¿
        gt_coastline = gt_coastline_high * 1.0 + gt_coastline_med * 0.6 + gt_coastline_low * 0.3
        gt_coastline = (gt_coastline > 0.5).astype(float)

        # 2. åˆ†æGTæµ·å²¸çº¿å‘¨å›´çš„å›¾åƒç‰¹å¾
        learned_features = self._analyze_coastline_context(gt_coastline, original_image)

        print(f"      å­¦ä¹ åˆ° {len(learned_features)} ä¸ªç‰¹å¾æ¨¡å¼")
        return learned_features

    def _analyze_coastline_context(self, gt_coastline, original_image):
        """åˆ†æGTæµ·å²¸çº¿å‘¨å›´çš„å›¾åƒç‰¹å¾"""
        features = {}

        # ç¡®ä¿å°ºå¯¸ä¸€è‡´
        if gt_coastline.shape != original_image.shape[:2]:
            gt_coastline = ndimage.zoom(gt_coastline,
                                        (original_image.shape[0] / gt_coastline.shape[0],
                                         original_image.shape[1] / gt_coastline.shape[1]))

        # è·å–æµ·å²¸çº¿åƒç´ ä½ç½®
        coastline_pixels = np.where(gt_coastline > 0.5)

        if len(coastline_pixels[0]) == 0:
            return features

        # åˆ†ææµ·å²¸çº¿åƒç´ çš„é¢œè‰²ç‰¹å¾
        if len(original_image.shape) == 3:
            r, g, b = original_image[:, :, 0], original_image[:, :, 1], original_image[:, :, 2]

            coastline_r = r[coastline_pixels]
            coastline_g = g[coastline_pixels]
            coastline_b = b[coastline_pixels]

            features['color_stats'] = {
                'r_mean': np.mean(coastline_r),
                'g_mean': np.mean(coastline_g),
                'b_mean': np.mean(coastline_b),
                'r_std': np.std(coastline_r),
                'g_std': np.std(coastline_g),
                'b_std': np.std(coastline_b)
            }

            features['contrast_patterns'] = self._analyze_coastline_sides(gt_coastline, r, g, b)

        # åˆ†æè¾¹ç¼˜ç‰¹å¾
        gray = np.dot(original_image[..., :3], [0.2989, 0.5870, 0.1140]) if len(
            original_image.shape) == 3 else original_image

        sobel_x = ndimage.convolve(gray.astype(float), self.edge_kernels['sobel_x'])
        sobel_y = ndimage.convolve(gray.astype(float), self.edge_kernels['sobel_y'])
        edge_magnitude = np.sqrt(sobel_x ** 2 + sobel_y ** 2)

        coastline_edges = edge_magnitude[coastline_pixels]
        features['edge_stats'] = {
            'edge_mean': np.mean(coastline_edges),
            'edge_std': np.std(coastline_edges),
            'edge_percentiles': np.percentile(coastline_edges, [25, 50, 75, 90])
        }

        return features

    def _analyze_coastline_sides(self, gt_coastline, r, g, b):
        """åˆ†ææµ·å²¸çº¿ä¸¤ä¾§çš„é¢œè‰²å¯¹æ¯”"""
        kernel = np.ones((5, 5), dtype=bool)
        dilated = ndimage.binary_dilation(gt_coastline > 0.5, structure=kernel)

        kernel_sea = np.ones((10, 10), dtype=bool)
        sea_side = ndimage.binary_dilation(gt_coastline > 0.5, structure=kernel_sea)

        land_side = dilated & (~sea_side)

        sea_pixels = np.where(sea_side)
        land_pixels = np.where(land_side)

        contrast_patterns = {}

        if len(sea_pixels[0]) > 0 and len(land_pixels[0]) > 0:
            sea_r, sea_g, sea_b = r[sea_pixels], g[sea_pixels], b[sea_pixels]
            land_r, land_g, land_b = r[land_pixels], g[land_pixels], b[land_pixels]

            contrast_patterns = {
                'sea_color': [np.mean(sea_r), np.mean(sea_g), np.mean(sea_b)],
                'land_color': [np.mean(land_r), np.mean(land_g), np.mean(land_b)],
                'color_contrast': [
                    abs(np.mean(sea_r) - np.mean(land_r)),
                    abs(np.mean(sea_g) - np.mean(land_g)),
                    abs(np.mean(sea_b) - np.mean(land_b))
                ]
            }

        return contrast_patterns

    def apply_learned_features(self, image, learned_features):
        """åº”ç”¨ä»GTå­¦ä¹ åˆ°çš„ç‰¹å¾æ¥æ”¹è¿›æ£€æµ‹"""
        print("   ğŸ¯ åº”ç”¨å­¦ä¹ åˆ°çš„ç‰¹å¾æ¨¡å¼...")

        if learned_features is None:
            return np.zeros(image.shape[:2])

        if len(image.shape) == 3:
            r, g, b = image[:, :, 0], image[:, :, 1], image[:, :, 2]
        else:
            r = g = b = image

        learned_coastline = np.zeros(image.shape[:2])

        # 1. åŸºäºå­¦ä¹ åˆ°çš„é¢œè‰²ç‰¹å¾
        if 'color_stats' in learned_features:
            color_stats = learned_features['color_stats']

            r_match = np.abs(r - color_stats['r_mean']) < (2 * color_stats['r_std'] + 20)
            g_match = np.abs(g - color_stats['g_mean']) < (2 * color_stats['g_std'] + 20)
            b_match = np.abs(b - color_stats['b_mean']) < (2 * color_stats['b_std'] + 20)

            color_match = r_match & g_match & b_match
            learned_coastline += color_match.astype(float) * 0.3

        # 2. åŸºäºå­¦ä¹ åˆ°çš„å¯¹æ¯”æ¨¡å¼
        if 'contrast_patterns' in learned_features:
            contrast = learned_features['contrast_patterns']
            if 'sea_color' in contrast and 'land_color' in contrast:
                sea_color = contrast['sea_color']
                land_color = contrast['land_color']

                sea_similarity = self._calculate_color_similarity([r, g, b], sea_color)
                land_similarity = self._calculate_color_similarity([r, g, b], land_color)

                boundary_mask = self._find_color_boundaries(sea_similarity, land_similarity)
                learned_coastline += boundary_mask * 0.4

        # 3. åŸºäºå­¦ä¹ åˆ°çš„è¾¹ç¼˜ç‰¹å¾
        if 'edge_stats' in learned_features:
            edge_stats = learned_features['edge_stats']

            gray = np.dot(image[..., :3], [0.2989, 0.5870, 0.1140]) if len(image.shape) == 3 else image
            sobel_x = ndimage.convolve(gray.astype(float), self.edge_kernels['sobel_x'])
            sobel_y = ndimage.convolve(gray.astype(float), self.edge_kernels['sobel_y'])
            edge_magnitude = np.sqrt(sobel_x ** 2 + sobel_y ** 2)

            edge_threshold_low = edge_stats['edge_percentiles'][1]
            edge_threshold_high = edge_stats['edge_percentiles'][2]

            edge_match = (edge_magnitude >= edge_threshold_low) & (edge_magnitude <= edge_threshold_high * 2)
            learned_coastline += edge_match.astype(float) * 0.3

        if learned_coastline.max() > 0:
            learned_coastline = learned_coastline / learned_coastline.max()

        final_learned = (learned_coastline > 0.3).astype(float)

        print(f"      å­¦ä¹ æ£€æµ‹åˆ° {np.sum(final_learned):,} ä¸ªæµ·å²¸çº¿åƒç´ ")
        return final_learned

    def _calculate_color_similarity(self, current_colors, target_color):
        """è®¡ç®—é¢œè‰²ç›¸ä¼¼åº¦"""
        r, g, b = current_colors
        tr, tg, tb = target_color

        distance = np.sqrt((r - tr) ** 2 + (g - tg) ** 2 + (b - tb) ** 2)
        similarity = 1.0 / (1.0 + distance / 100.0)

        return similarity

    def _find_color_boundaries(self, similarity1, similarity2):
        """å¯»æ‰¾ä¸¤ç§é¢œè‰²çš„è¾¹ç•Œ"""
        smooth1 = gaussian_filter(similarity1, sigma=2)
        smooth2 = gaussian_filter(similarity2, sigma=2)

        grad1_x = np.gradient(smooth1, axis=1)
        grad1_y = np.gradient(smooth1, axis=0)
        grad2_x = np.gradient(smooth2, axis=1)
        grad2_y = np.gradient(smooth2, axis=0)

        boundary1 = np.sqrt(grad1_x ** 2 + grad1_y ** 2)
        boundary2 = np.sqrt(grad2_x ** 2 + grad2_y ** 2)

        combined_boundary = np.maximum(boundary1, boundary2)

        threshold = np.percentile(combined_boundary, 85)
        boundary_mask = (combined_boundary > threshold).astype(float)

        return boundary_mask

    def enhanced_edge_sensitivity_detection(self, image, color_regions):
        """å¢å¼ºé¢œè‰²äº¤æ¥è¾¹ç¼˜æ•æ„Ÿåº¦æ£€æµ‹"""
        print("   ğŸ” å¢å¼ºè¾¹ç¼˜æ•æ„Ÿåº¦æ£€æµ‹...")

        if len(image.shape) == 3:
            r, g, b = image[:, :, 0], image[:, :, 1], image[:, :, 2]
        else:
            r = g = b = image

        # åˆ›å»ºé¢œè‰²åŒºåŸŸæ©ç 
        blue_mask = color_regions['blue_mask']
        green_mask = color_regions['green_mask']
        land_mask = color_regions['land_mask']

        # 1. è“-ç»¿äº¤æ¥è¾¹ç¼˜ï¼ˆæœ€é‡è¦çš„æµ·å²¸çº¿ï¼‰
        blue_green_interface = self._detect_color_interface_enhanced(
            blue_mask, green_mask, r, g, b, interface_type="blue_green")

        # 2. è“-åœŸåœ°äº¤æ¥è¾¹ç¼˜
        blue_land_interface = self._detect_color_interface_enhanced(
            blue_mask, land_mask, r, g, b, interface_type="blue_land")

        # 3. ç»¿-åœŸåœ°äº¤æ¥è¾¹ç¼˜
        green_land_interface = self._detect_color_interface_enhanced(
            green_mask, land_mask, r, g, b, interface_type="green_land")

        # ç»„åˆæ‰€æœ‰äº¤æ¥è¾¹ç¼˜ï¼Œç»™äºˆä¸åŒæƒé‡
        enhanced_edges = (blue_green_interface * 1.0 +
                          blue_land_interface * 0.8 +
                          green_land_interface * 0.6)

        # å½’ä¸€åŒ–
        if enhanced_edges.max() > 0:
            enhanced_edges = enhanced_edges / enhanced_edges.max()

        edge_pixels = np.sum(enhanced_edges > 0.3)
        print(f"      å¢å¼ºè¾¹ç¼˜æ£€æµ‹åˆ° {edge_pixels:,} ä¸ªåƒç´ ")

        return enhanced_edges

    def _detect_color_interface_enhanced(self, mask1, mask2, r, g, b, interface_type="general"):
        """å¢å¼ºçš„é¢œè‰²äº¤æ¥æ£€æµ‹"""
        # å¤šå°ºåº¦è†¨èƒ€æ£€æµ‹äº¤æ¥åŒºåŸŸ
        interfaces = []

        # ä¸åŒç±»å‹çš„äº¤æ¥ä½¿ç”¨ä¸åŒçš„æ£€æµ‹ç­–ç•¥
        if interface_type == "blue_green":
            # è“ç»¿äº¤æ¥æœ€é‡è¦ï¼Œä½¿ç”¨æœ€ç²¾ç»†çš„æ£€æµ‹
            dilation_sizes = [2, 3, 4, 5]
            weights = [0.4, 0.3, 0.2, 0.1]
        elif interface_type == "blue_land":
            # è“åœŸäº¤æ¥æ¬¡é‡è¦
            dilation_sizes = [3, 4, 5]
            weights = [0.5, 0.3, 0.2]
        else:
            # å…¶ä»–äº¤æ¥
            dilation_sizes = [3, 5]
            weights = [0.6, 0.4]

        for i, dilation_size in enumerate(dilation_sizes):
            kernel = np.ones((dilation_size, dilation_size), dtype=bool)
            dilated1 = ndimage.binary_dilation(mask1, structure=kernel)
            dilated2 = ndimage.binary_dilation(mask2, structure=kernel)

            # äº¤æ¥åŒºåŸŸ
            interface = dilated1 & dilated2

            # åœ¨äº¤æ¥åŒºåŸŸå†…åˆ†æé¢œè‰²æ¢¯åº¦
            if np.sum(interface) > 0:
                color_gradient = self._calculate_color_gradient_at_interface(
                    interface, r, g, b)
                enhanced_interface = interface.astype(float) * color_gradient
            else:
                enhanced_interface = interface.astype(float)

            interfaces.append(enhanced_interface)

        # æƒé‡ç»„åˆ
        combined = sum(w * interface for w, interface in zip(weights, interfaces))

        return combined

    def _calculate_color_gradient_at_interface(self, interface_mask, r, g, b):
        """åœ¨äº¤æ¥åŒºåŸŸè®¡ç®—é¢œè‰²æ¢¯åº¦å¼ºåº¦"""
        # è®¡ç®—RGBå„é€šé“çš„æ¢¯åº¦
        grad_r_x = np.gradient(r.astype(float), axis=1)
        grad_r_y = np.gradient(r.astype(float), axis=0)
        grad_g_x = np.gradient(g.astype(float), axis=1)
        grad_g_y = np.gradient(g.astype(float), axis=0)
        grad_b_x = np.gradient(b.astype(float), axis=1)
        grad_b_y = np.gradient(b.astype(float), axis=0)

        # è®¡ç®—æ€»æ¢¯åº¦å¼ºåº¦
        gradient_magnitude = np.sqrt(
            (grad_r_x ** 2 + grad_r_y ** 2) +
            (grad_g_x ** 2 + grad_g_y ** 2) +
            (grad_b_x ** 2 + grad_b_y ** 2)
        )

        # åœ¨äº¤æ¥åŒºåŸŸå†…å½’ä¸€åŒ–æ¢¯åº¦
        if np.sum(interface_mask) > 0:
            interface_gradients = gradient_magnitude[interface_mask]
            if len(interface_gradients) > 0:
                threshold = np.percentile(interface_gradients, 70)
                gradient_strength = np.where(gradient_magnitude > threshold, 1.0, 0.5)
            else:
                gradient_strength = np.ones_like(gradient_magnitude)
        else:
            gradient_strength = np.ones_like(gradient_magnitude)

        return gradient_strength

    def dqn_curiosity_exploration(self, coastlines, image):
        """DQNå¥½å¥‡å¿ƒæœºåˆ¶ - æ¢ç´¢æœªæ£€æµ‹åŒºåŸŸ"""
        print("   ğŸ¤” DQNå¥½å¥‡å¿ƒæ¢ç´¢æœºåˆ¶...")

        # 1. è®¡ç®—å½“å‰æ£€æµ‹çš„è¦†ç›–æƒ…å†µ
        current_detection = np.zeros_like(list(coastlines.values())[0])
        for name, coastline in coastlines.items():
            if name != 'learned_from_gt':  # æš‚æ—¶æ’é™¤å­¦ä¹ ç‰¹å¾
                current_detection += (coastline > 0.3).astype(float)

        current_detection = (current_detection > 0.5).astype(float)

        # 2. å¯»æ‰¾"æœ‰è¶£"çš„æœªæ¢ç´¢åŒºåŸŸ
        curiosity_map = self._generate_curiosity_map(current_detection, image)

        # 3. åœ¨å¥½å¥‡åŒºåŸŸè¿›è¡Œç²¾ç»†æ¢ç´¢
        curiosity_coastlines = self._explore_curious_regions(curiosity_map, image)

        curiosity_pixels = np.sum(curiosity_coastlines > 0.3)
        print(f"      å¥½å¥‡å¿ƒæ¢ç´¢å‘ç° {curiosity_pixels:,} ä¸ªæ–°åƒç´ ")

        return curiosity_coastlines

    def _generate_curiosity_map(self, current_detection, image):
        """ç”Ÿæˆå¥½å¥‡å¿ƒåœ°å›¾ - æ ‡è¯†å€¼å¾—æ¢ç´¢çš„åŒºåŸŸ"""

        # 1. è·ç¦»å½“å‰æ£€æµ‹çš„è·ç¦»åœº
        from scipy.ndimage import distance_transform_edt
        distance_field = distance_transform_edt(~(current_detection > 0.5))

        # 2. å›¾åƒå¤æ‚åº¦ï¼ˆåŸºäºå±€éƒ¨æ–¹å·®ï¼‰
        if len(image.shape) == 3:
            gray = np.dot(image[..., :3], [0.2989, 0.5870, 0.1140])
        else:
            gray = image

        complexity = ndimage.generic_filter(gray.astype(float), np.var, size=7)

        # 3. è¾¹ç¼˜å¯†åº¦
        sobel_x = ndimage.convolve(gray.astype(float), self.edge_kernels['sobel_x'])
        sobel_y = ndimage.convolve(gray.astype(float), self.edge_kernels['sobel_y'])
        edge_density = np.sqrt(sobel_x ** 2 + sobel_y ** 2)

        # 4. ç»„åˆå¥½å¥‡å¿ƒæŒ‡æ ‡
        # è·ç¦»é€‚ä¸­(ä¸å¤ªè¿‘ä¸å¤ªè¿œ) + å¤æ‚åº¦é«˜ + è¾¹ç¼˜å¯†åº¦é€‚ä¸­
        distance_curiosity = np.exp(-(distance_field - 10) ** 2 / 50)  # è·ç¦»10åƒç´ å·¦å³æœ€æœ‰è¶£
        complexity_curiosity = (complexity - np.mean(complexity)) / (np.std(complexity) + 1e-8)
        edge_curiosity = (edge_density - np.mean(edge_density)) / (np.std(edge_density) + 1e-8)

        # ç»„åˆå¥½å¥‡å¿ƒåœ°å›¾
        curiosity_map = (distance_curiosity * 0.4 +
                         np.maximum(0, complexity_curiosity) * 0.3 +
                         np.maximum(0, edge_curiosity) * 0.3)

        # å½’ä¸€åŒ–
        if curiosity_map.max() > 0:
            curiosity_map = curiosity_map / curiosity_map.max()

        return curiosity_map

    def _explore_curious_regions(self, curiosity_map, image):
        """åœ¨å¥½å¥‡åŒºåŸŸè¿›è¡Œç²¾ç»†æ¢ç´¢"""

        # é€‰æ‹©é«˜å¥½å¥‡å¿ƒåŒºåŸŸ
        high_curiosity = curiosity_map > np.percentile(curiosity_map, 80)

        if np.sum(high_curiosity) == 0:
            return np.zeros_like(curiosity_map)

        # åœ¨é«˜å¥½å¥‡å¿ƒåŒºåŸŸè¿›è¡Œå¤šç§æ£€æµ‹
        exploration_results = []

        if len(image.shape) == 3:
            r, g, b = image[:, :, 0], image[:, :, 1], image[:, :, 2]

            # 1. å±€éƒ¨é¢œè‰²å˜åŒ–æ£€æµ‹
            local_color_change = self._detect_local_color_changes(r, g, b)
            exploration_results.append(local_color_change * high_curiosity)

            # 2. äº®åº¦çªå˜æ£€æµ‹
            brightness = (r + g + b) / 3
            brightness_change = self._detect_brightness_changes(brightness)
            exploration_results.append(brightness_change * high_curiosity)

        # 3. çº¹ç†è¾¹ç•Œæ£€æµ‹
        gray = np.dot(image[..., :3], [0.2989, 0.5870, 0.1140]) if len(image.shape) == 3 else image
        texture_boundaries = self._detect_texture_boundaries(gray)
        exploration_results.append(texture_boundaries * high_curiosity)

        # ç»„åˆæ¢ç´¢ç»“æœ
        if exploration_results:
            combined_exploration = np.maximum.reduce(exploration_results)

            # åº”ç”¨å¥½å¥‡å¿ƒæƒé‡
            weighted_exploration = combined_exploration * curiosity_map

            return weighted_exploration
        else:
            return np.zeros_like(curiosity_map)

    def _detect_local_color_changes(self, r, g, b):
        """æ£€æµ‹å±€éƒ¨é¢œè‰²å˜åŒ–"""
        # è®¡ç®—å±€éƒ¨é¢œè‰²æ ‡å‡†å·®
        local_r_std = ndimage.generic_filter(r.astype(float), np.std, size=5)
        local_g_std = ndimage.generic_filter(g.astype(float), np.std, size=5)
        local_b_std = ndimage.generic_filter(b.astype(float), np.std, size=5)

        # é¢œè‰²å˜åŒ–å¼ºåº¦
        color_change = (local_r_std + local_g_std + local_b_std) / 3

        # å½’ä¸€åŒ–
        if color_change.max() > 0:
            color_change = color_change / color_change.max()

        return color_change

    def _detect_brightness_changes(self, brightness):
        """æ£€æµ‹äº®åº¦çªå˜"""
        # è®¡ç®—äº®åº¦æ¢¯åº¦
        grad_x = np.gradient(brightness.astype(float), axis=1)
        grad_y = np.gradient(brightness.astype(float), axis=0)
        brightness_gradient = np.sqrt(grad_x ** 2 + grad_y ** 2)

        # å½’ä¸€åŒ–
        if brightness_gradient.max() > 0:
            brightness_gradient = brightness_gradient / brightness_gradient.max()

        return brightness_gradient

    def _detect_texture_boundaries(self, gray):
        """æ£€æµ‹çº¹ç†è¾¹ç•Œ"""
        # ä½¿ç”¨ä¸åŒå°ºåº¦çš„å±€éƒ¨äºŒå€¼æ¨¡å¼ç±»ä¼¼çš„æ–¹æ³•
        texture_responses = []

        for size in [3, 5, 7]:
            local_mean = ndimage.uniform_filter(gray.astype(float), size=size)
            local_var = ndimage.generic_filter(gray.astype(float), np.var, size=size)

            # çº¹ç†å¼ºåº¦
            texture_strength = local_var / (local_mean + 1e-8)
            texture_responses.append(texture_strength)

        # ç»„åˆä¸åŒå°ºåº¦çš„çº¹ç†å“åº”
        combined_texture = np.mean(texture_responses, axis=0)

        # è®¡ç®—çº¹ç†è¾¹ç•Œ
        texture_grad_x = np.gradient(combined_texture, axis=1)
        texture_grad_y = np.gradient(combined_texture, axis=0)
        texture_boundaries = np.sqrt(texture_grad_x ** 2 + texture_grad_y ** 2)

        # å½’ä¸€åŒ–
        if texture_boundaries.max() > 0:
            texture_boundaries = texture_boundaries / texture_boundaries.max()

        return texture_boundaries

    def spatial_importance_weighting(self, coastlines, color_regions):
        """ç©ºé—´é‡è¦æ€§åŠ æƒ - å‡å°‘å†…é™†åŒºåŸŸçš„æƒé‡"""
        print("   ğŸ“ ç©ºé—´é‡è¦æ€§åŠ æƒ...")

        blue_mask = color_regions['blue_mask']
        green_mask = color_regions['green_mask']
        land_mask = color_regions['land_mask']

        # 1. è®¡ç®—è·ç¦»æµ·æ´‹è¾¹ç•Œçš„è·ç¦»
        ocean_boundary = self._extract_smart_boundary(blue_mask)
        distance_to_ocean = self._calculate_distance_to_boundary(ocean_boundary)

        # 2. è®¡ç®—è·ç¦»é™†åœ°è¾¹ç•Œçš„è·ç¦»
        land_combined = green_mask | land_mask
        land_boundary = self._extract_smart_boundary(land_combined)
        distance_to_land = self._calculate_distance_to_boundary(land_boundary)

        # 3. åˆ›å»ºé‡è¦æ€§æƒé‡å›¾
        importance_map = self._create_importance_map(
            distance_to_ocean, distance_to_land, blue_mask, land_combined)

        # 4. å¯¹æ¯ä¸ªæµ·å²¸çº¿æ£€æµ‹ç»“æœåº”ç”¨æƒé‡
        weighted_coastlines = {}
        for name, coastline in coastlines.items():
            weighted_coastline = coastline * importance_map
            weighted_coastlines[name] = weighted_coastline

            original_pixels = np.sum(coastline > 0.5)
            weighted_pixels = np.sum(weighted_coastline > 0.3)
            print(f"      {name}: {original_pixels:,} -> {weighted_pixels:,} åƒç´ ")

        return weighted_coastlines, importance_map

    def _calculate_distance_to_boundary(self, boundary_mask):
        """è®¡ç®—åˆ°è¾¹ç•Œçš„è·ç¦»"""
        from scipy.ndimage import distance_transform_edt

        # è·ç¦»å˜æ¢
        distance = distance_transform_edt(~(boundary_mask > 0.5))

        return distance

    def _create_importance_map(self, dist_to_ocean, dist_to_land, blue_mask, land_mask):
        """åˆ›å»ºç©ºé—´é‡è¦æ€§åœ°å›¾"""

        # 1. æµ·æ´‹å†…éƒ¨é‡è¦æ€§é€’å‡
        # è·ç¦»æµ·æ´‹è¾¹ç•Œè¶Šè¿œï¼Œé‡è¦æ€§è¶Šä½
        ocean_importance = np.where(blue_mask,
                                    np.exp(-dist_to_ocean / 20), 1.0)  # 20åƒç´ å†…é‡è¦

        # 2. é™†åœ°å†…éƒ¨é‡è¦æ€§é€’å‡
        # è·ç¦»é™†åœ°è¾¹ç•Œè¶Šè¿œï¼Œé‡è¦æ€§è¶Šä½
        land_importance = np.where(land_mask,
                                   np.exp(-dist_to_land / 15), 1.0)  # 15åƒç´ å†…é‡è¦

        # 3. æµ·é™†äº¤æ¥åŒºåŸŸæœ€é‡è¦
        interface_importance = np.exp(-(dist_to_ocean + dist_to_land) / 10)

        # 4. ç»„åˆé‡è¦æ€§
        # åœ¨æµ·æ´‹ä¸­ï¼šæµ·æ´‹é‡è¦æ€§ + äº¤æ¥é‡è¦æ€§
        # åœ¨é™†åœ°ä¸­ï¼šé™†åœ°é‡è¦æ€§ + äº¤æ¥é‡è¦æ€§
        # åœ¨å…¶ä»–åŒºåŸŸï¼šäº¤æ¥é‡è¦æ€§
        importance_map = np.where(blue_mask,
                                  ocean_importance * 0.3 + interface_importance * 0.7,
                                  np.where(land_mask,
                                           land_importance * 0.3 + interface_importance * 0.7,
                                           interface_importance))

        # 5. ç¡®ä¿è¾¹ç•ŒåŒºåŸŸé‡è¦æ€§æœ€é«˜
        boundary_boost = (dist_to_ocean < 5) | (dist_to_land < 5)
        importance_map = np.where(boundary_boost,
                                  np.maximum(importance_map, 0.8),
                                  importance_map)

        # å½’ä¸€åŒ–åˆ°0-1
        if importance_map.max() > 0:
            importance_map = importance_map / importance_map.max()

        return importance_map
        """CNNæ ·å¼çš„ç‰¹å¾æå–"""
        print("\nğŸ§  CNNç‰¹å¾æå–...")

        if len(image.shape) == 3:
            gray = np.dot(image[..., :3], [0.2989, 0.5870, 0.1140])
        else:
            gray = image.copy()

        if gray.max() <= 1.0:
            gray = (gray * 255).astype(np.uint8)

        features = {}

        sobel_x = ndimage.convolve(gray.astype(float), self.edge_kernels['sobel_x'])
        sobel_y = ndimage.convolve(gray.astype(float), self.edge_kernels['sobel_y'])
        edge_magnitude = np.sqrt(sobel_x ** 2 + sobel_y ** 2)
        features['edges'] = edge_magnitude

        prewitt_x = ndimage.convolve(gray.astype(float), self.edge_kernels['prewitt_x'])
        prewitt_y = ndimage.convolve(gray.astype(float), self.edge_kernels['prewitt_y'])
        prewitt_magnitude = np.sqrt(prewitt_x ** 2 + prewitt_y ** 2)
        features['prewitt_edges'] = prewitt_magnitude

        texture = ndimage.generic_filter(gray.astype(float), np.std, size=5)
        features['texture'] = texture

        gradient_direction = np.arctan2(sobel_y, sobel_x)
        features['gradient_direction'] = gradient_direction

        laplacian = ndimage.convolve(gray.astype(float), self.edge_kernels['laplacian'])
        features['laplacian'] = np.abs(laplacian)

        local_mean = ndimage.uniform_filter(gray.astype(float), size=5)
        local_contrast = np.abs(gray.astype(float) - local_mean)
        features['local_contrast'] = local_contrast

        print(f"   âœ… æå–äº† {len(features)} ä¸ªç‰¹å¾å›¾")

        return features

    def dqn_like_coastline_extraction(self, color_regions, cnn_features):
        """DQNæ ·å¼çš„æµ·å²¸çº¿æå–"""
        print("\nğŸ¤– DQNæ ·å¼æµ·å²¸çº¿æå–...")

        coastlines = {}

        print("   ğŸ“ é¢œè‰²è¾¹ç•Œæå–...")

        ocean_boundary = self._extract_smart_boundary(color_regions['blue_mask'])
        coastlines['ocean_boundary'] = ocean_boundary

        land_combined = color_regions['green_mask'] | color_regions['land_mask']
        land_boundary = self._extract_smart_boundary(land_combined)
        coastlines['land_boundary'] = land_boundary

        print("   ğŸ§  CNNç‰¹å¾è¾¹ç•Œ...")

        edge_threshold = np.percentile(cnn_features['edges'], 85)
        strong_edges = cnn_features['edges'] > edge_threshold
        coastlines['cnn_edges'] = strong_edges.astype(float)

        prewitt_threshold = np.percentile(cnn_features['prewitt_edges'], 80)
        prewitt_strong = cnn_features['prewitt_edges'] > prewitt_threshold
        coastlines['prewitt_edges'] = prewitt_strong.astype(float)

        texture_threshold = np.percentile(cnn_features['texture'], 80)
        high_texture = cnn_features['texture'] > texture_threshold
        coastlines['texture_edges'] = high_texture.astype(float)

        contrast_threshold = np.percentile(cnn_features['local_contrast'], 85)
        high_contrast = cnn_features['local_contrast'] > contrast_threshold
        coastlines['contrast_edges'] = high_contrast.astype(float)

        print("   ğŸŒŠ æµ·é™†äº¤æ¥çº¿...")
        ocean_land_interface = self._extract_interface_advanced(
            color_regions['blue_mask'],
            land_combined
        )
        coastlines['ocean_land_interface'] = ocean_land_interface

        print("   âšª ç™½è‰²æ ‡æ³¨å¤„ç†...")
        white_processed = self._process_white_annotations(color_regions['white_mask'])
        coastlines['white_annotations'] = white_processed

        return coastlines

    def _extract_smart_boundary(self, mask):
        """æ™ºèƒ½è¾¹ç•Œæå–"""
        boundaries = []

        for kernel_size in [3, 5, 7]:
            kernel = np.ones((kernel_size, kernel_size), dtype=bool)
            eroded = ndimage.binary_erosion(mask, structure=kernel)
            boundary = mask & (~eroded)
            boundaries.append(boundary.astype(float))

        combined_boundary = np.maximum.reduce(boundaries)

        kernel = np.ones((3, 3), dtype=bool)
        connected = ndimage.binary_closing(combined_boundary > 0.5, structure=kernel)

        return connected.astype(float)

    def _extract_interface_advanced(self, mask1, mask2):
        """é«˜çº§äº¤æ¥çº¿æå–"""
        interfaces = []

        for dilation_size in [3, 5, 7]:
            kernel = np.ones((dilation_size, dilation_size), dtype=bool)
            dilated1 = ndimage.binary_dilation(mask1, structure=kernel)
            dilated2 = ndimage.binary_dilation(mask2, structure=kernel)
            interface = dilated1 & dilated2
            interfaces.append(interface.astype(float))

        weights = [0.5, 0.3, 0.2]
        combined = sum(w * interface for w, interface in zip(weights, interfaces))

        return combined

    def _process_white_annotations(self, white_mask):
        """å¤„ç†ç™½è‰²æ ‡æ³¨"""
        kernel_line = np.ones((5, 1), dtype=bool)
        kernel_line2 = np.ones((1, 5), dtype=bool)
        kernel_diag1 = np.array([[1, 0, 0], [0, 1, 0], [0, 0, 1]], dtype=bool)
        kernel_diag2 = np.array([[0, 0, 1], [0, 1, 0], [1, 0, 0]], dtype=bool)

        connected_v = ndimage.binary_closing(white_mask, structure=kernel_line)
        connected_h = ndimage.binary_closing(white_mask, structure=kernel_line2)
        connected_d1 = ndimage.binary_closing(white_mask, structure=kernel_diag1)
        connected_d2 = ndimage.binary_closing(white_mask, structure=kernel_diag2)

        connected = connected_v | connected_h | connected_d1 | connected_d2

        labeled, num_features = label(connected)
        filtered = np.zeros_like(connected, dtype=bool)

        for i in range(1, num_features + 1):
            component = (labeled == i)
            if np.sum(component) >= 5:
                filtered = filtered | component

        return filtered.astype(float)

    def intelligent_coastline_fusion_with_learning(self, coastlines, cnn_features, learned_features):
        """æ™ºèƒ½æµ·å²¸çº¿èåˆ - é›†æˆå­¦ä¹ ç‰¹å¾"""
        print("\nğŸ”„ æ™ºèƒ½æµ·å²¸çº¿èåˆï¼ˆå«å­¦ä¹ ç‰¹å¾ï¼‰...")

        weights = self._calculate_dynamic_weights_with_learning(coastlines, cnn_features, learned_features)

        combined = np.zeros_like(list(coastlines.values())[0])

        for name, coastline in coastlines.items():
            weight = weights.get(name, 0.1)
            combined += weight * coastline
            pixels = np.sum(coastline > 0.5)
            print(f"   {name}: {pixels:,} åƒç´  (æƒé‡: {weight:.2f})")

        if combined.max() > 0:
            combined = combined / combined.max()

        threshold = self._calculate_adaptive_threshold(combined)
        final_coastline = (combined > threshold).astype(float)

        final_coastline = self._post_process_coastline(final_coastline)

        final_pixels = np.sum(final_coastline > 0.5)
        print(f"âœ… æœ€ç»ˆæµ·å²¸çº¿: {final_pixels:,} åƒç´  (é˜ˆå€¼: {threshold:.3f})")

        return final_coastline, combined

    def _calculate_dynamic_weights_with_learning(self, coastlines, cnn_features, learned_features):
        """è®¡ç®—åŠ¨æ€æƒé‡ - åŒ…å«å­¦ä¹ ç‰¹å¾"""
        weights = {
            'ocean_boundary': 0.20,
            'land_boundary': 0.15,
            'ocean_land_interface': 0.25,
            'cnn_edges': 0.12,
            'prewitt_edges': 0.08,
            'texture_edges': 0.10,
            'contrast_edges': 0.08,
            'white_annotations': 0.15,
            'learned_from_gt': 0.50
        }

        if learned_features is not None and 'learned_from_gt' in coastlines:
            learned_pixels = np.sum(coastlines['learned_from_gt'] > 0.5)
            if learned_pixels > 500:
                weights['learned_from_gt'] = 0.60
                for key in weights:
                    if key != 'learned_from_gt':
                        weights[key] *= 0.8
            elif learned_pixels < 100:
                weights['learned_from_gt'] = 0.20

        for name, coastline in coastlines.items():
            pixels = np.sum(coastline > 0.5)
            if pixels < 50:
                weights[name] = weights.get(name, 0.1) * 0.3
            elif pixels > 20000:
                weights[name] = weights.get(name, 0.1) * 0.5

        return weights

    def _calculate_adaptive_threshold(self, combined):
        """è®¡ç®—è‡ªé€‚åº”é˜ˆå€¼"""
        hist, bins = np.histogram(combined.flatten(), bins=50, range=(0, 1))

        best_threshold = 0.2
        max_variance = 0

        for i in range(5, 45):
            threshold = i / 50.0

            w1 = np.sum(hist[:i])
            w2 = np.sum(hist[i:])

            if w1 > 0 and w2 > 0:
                mean1 = np.sum(np.arange(i) * hist[:i]) / w1 if w1 > 0 else 0
                mean2 = np.sum(np.arange(i, 50) * hist[i:]) / w2 if w2 > 0 else 0
                variance = w1 * w2 * (mean1 - mean2) ** 2

                if variance > max_variance:
                    max_variance = variance
                    best_threshold = threshold

        return max(0.15, min(0.4, best_threshold))

    def _post_process_coastline(self, coastline):
        """æµ·å²¸çº¿åå¤„ç†"""
        labeled, num_features = label(coastline > 0.5)
        filtered = np.zeros_like(coastline, dtype=bool)

        for i in range(1, num_features + 1):
            component = (labeled == i)
            if np.sum(component) >= 8:
                filtered = filtered | component

        kernel = np.ones((3, 3), dtype=bool)
        connected = ndimage.binary_closing(filtered, structure=kernel)

        smoothed = gaussian_filter(connected.astype(float), sigma=0.8)
        final = (smoothed > 0.4).astype(float)

        return final

    def load_ground_truth(self, gt_path):
        """åŠ è½½Ground Truthæ•°æ®"""
        try:
            if gt_path and gt_path.endswith('.pdf'):
                doc = fitz.open(gt_path)
                page = doc.load_page(0)
                zoom = 200 / 72
                mat = fitz.Matrix(zoom, zoom)
                pix = page.get_pixmap(matrix=mat)
                img_data = pix.tobytes("png")

                from io import BytesIO
                img = Image.open(BytesIO(img_data))
                gt_image = np.array(img)
                doc.close()

                gt_processed = self.preprocess_image(gt_image, (400, 400))

                if len(gt_processed.shape) == 3:
                    gray = np.dot(gt_processed[..., :3], [0.2989, 0.5870, 0.1140])
                else:
                    gray = gt_processed

                gt_strategy1 = (gray > 200).astype(float)
                gt_strategy2 = (gray > 150).astype(float)

                gt_coastline = gt_strategy1 * 0.8 + gt_strategy2 * 0.2
                gt_coastline = (gt_coastline > 0.5).astype(float)

                return gt_coastline, gt_processed
            else:
                return None, None

        except Exception as e:
            print(f"âŒ æ— æ³•åŠ è½½Ground Truth: {e}")
            return None, None

    def calculate_accuracy_metrics(self, predicted, ground_truth):
        """è®¡ç®—å‡†ç¡®ç‡æŒ‡æ ‡"""
        if ground_truth is None:
            return None

        if predicted.shape != ground_truth.shape:
            ground_truth = ndimage.zoom(ground_truth,
                                        (predicted.shape[0] / ground_truth.shape[0],
                                         predicted.shape[1] / ground_truth.shape[1]))

        pred_binary = (predicted > 0.5).astype(bool)
        gt_binary = (ground_truth > 0.5).astype(bool)

        tp = np.sum(pred_binary & gt_binary)
        fp = np.sum(pred_binary & ~gt_binary)
        fn = np.sum(~pred_binary & gt_binary)
        tn = np.sum(~pred_binary & ~gt_binary)

        precision = tp / (tp + fp + 1e-8)
        recall = tp / (tp + fn + 1e-8)
        f1_score = 2 * precision * recall / (precision + recall + 1e-8)
        iou = tp / (tp + fp + fn + 1e-8)

        return {
            'precision': precision,
            'recall': recall,
            'f1_score': f1_score,
            'iou': iou,
            'tp': tp,
            'fp': fp,
            'fn': fn,
            'tn': tn
        }

    def process_image(self, image_path, ground_truth_path=None):
        """å¤„ç†å›¾åƒçš„ä¸»å‡½æ•° - é›†æˆæ‰€æœ‰å¢å¼ºåŠŸèƒ½"""
        print(f"\nğŸ–¼ï¸ å¤„ç†: {os.path.basename(image_path)}")

        try:
            doc = fitz.open(image_path)
            page = doc.load_page(0)
            zoom = 200 / 72
            mat = fitz.Matrix(zoom, zoom)
            pix = page.get_pixmap(matrix=mat)
            img_data = pix.tobytes("png")

            from io import BytesIO
            img = Image.open(BytesIO(img_data))
            original_img = np.array(img)
            doc.close()

            processed_img = self.preprocess_image(original_img, (400, 400))
            print(f"   ğŸ“ å¤„ç†åå°ºå¯¸: {processed_img.shape}")

            gt_coastline, gt_image = self.load_ground_truth(ground_truth_path) if ground_truth_path else (None, None)

            # Ground Truthå­¦ä¹ 
            learned_features = None
            if gt_image is not None:
                gt_processed = self.preprocess_image(gt_image, (400, 400))
                learned_features = self.learn_from_ground_truth(gt_processed, processed_img)

            # å¢å¼ºé¢œè‰²æ£€æµ‹
            color_regions = self.enhanced_color_detection(processed_img)

            # *** æ–°å¢ï¼šå¢å¼ºè¾¹ç¼˜æ•æ„Ÿåº¦æ£€æµ‹ ***
            enhanced_edges = self.enhanced_edge_sensitivity_detection(processed_img, color_regions)

            # CNNç‰¹å¾æå–
            cnn_features = self.cnn_like_feature_extraction(processed_img)

            # DQNæ ·å¼æµ·å²¸çº¿æå–
            coastlines = self.dqn_like_coastline_extraction(color_regions, cnn_features)

            # *** æ–°å¢ï¼šæ·»åŠ å¢å¼ºè¾¹ç¼˜åˆ°æµ·å²¸çº¿ç»„åˆ ***
            coastlines['enhanced_edges'] = enhanced_edges

            # Ground Truthå­¦ä¹ åº”ç”¨
            if learned_features is not None:
                learned_coastline = self.apply_learned_features(processed_img, learned_features)
                coastlines['learned_from_gt'] = learned_coastline
                print(f"   ğŸ“ ä»GTå­¦ä¹ çš„æµ·å²¸çº¿: {np.sum(learned_coastline):,} åƒç´ ")

            # *** æ–°å¢ï¼šç©ºé—´é‡è¦æ€§åŠ æƒ ***
            weighted_coastlines, importance_map = self.spatial_importance_weighting(coastlines, color_regions)

            # *** æ–°å¢ï¼šDQNå¥½å¥‡å¿ƒæ¢ç´¢ ***
            curiosity_coastlines = self.dqn_curiosity_exploration(weighted_coastlines, processed_img)
            weighted_coastlines['curiosity_exploration'] = curiosity_coastlines

            # æ™ºèƒ½èåˆï¼ˆä½¿ç”¨åŠ æƒåçš„æµ·å²¸çº¿ï¼‰
            final_coastline, combined_score = self.intelligent_coastline_fusion_with_enhancements(
                weighted_coastlines, cnn_features, learned_features, importance_map)

            # è®¡ç®—å‡†ç¡®ç‡
            accuracy_metrics = self.calculate_accuracy_metrics(final_coastline, gt_coastline)

            # è´¨é‡è¯„ä¼°
            coastline_pixels = np.sum(final_coastline > 0.5)
            total_pixels = final_coastline.size
            coverage_ratio = coastline_pixels / total_pixels

            labeled, num_components = label(final_coastline > 0.5)
            quality_score = min(1.0, coastline_pixels / 300.0)

            return {
                'original_image': original_img,
                'processed_image': processed_img,
                'ground_truth': gt_coastline,
                'gt_image': gt_image,
                'color_regions': color_regions,
                'cnn_features': cnn_features,
                'coastlines': coastlines,
                'weighted_coastlines': weighted_coastlines,
                'importance_map': importance_map,
                'enhanced_edges': enhanced_edges,
                'curiosity_coastlines': curiosity_coastlines,
                'learned_features': learned_features,
                'combined_score': combined_score,
                'final_coastline': final_coastline,
                'coastline_pixels': coastline_pixels,
                'coverage_ratio': coverage_ratio,
                'num_components': num_components,
                'quality_score': quality_score,
                'accuracy_metrics': accuracy_metrics,
                'success': coastline_pixels > 50
            }

        except Exception as e:
            print(f"âŒ å¤„ç†å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return None

    def intelligent_coastline_fusion_with_enhancements(self, coastlines, cnn_features, learned_features,
                                                       importance_map):
        """å¢å¼ºç‰ˆæ™ºèƒ½æµ·å²¸çº¿èåˆ"""
        print("\nğŸ”„ å¢å¼ºç‰ˆæ™ºèƒ½æµ·å²¸çº¿èåˆ...")

        weights = self._calculate_enhanced_dynamic_weights(coastlines, cnn_features, learned_features)

        combined = np.zeros_like(list(coastlines.values())[0])

        for name, coastline in coastlines.items():
            weight = weights.get(name, 0.1)
            combined += weight * coastline
            pixels = np.sum(coastline > 0.5)
            print(f"   {name}: {pixels:,} åƒç´  (æƒé‡: {weight:.2f})")

        # *** æ–°å¢ï¼šåº”ç”¨é‡è¦æ€§åœ°å›¾è¿›ä¸€æ­¥è°ƒæ•´ ***
        combined = combined * (0.7 + 0.3 * importance_map)  # é‡è¦åŒºåŸŸæƒé‡æå‡30%

        if combined.max() > 0:
            combined = combined / combined.max()

        threshold = self._calculate_adaptive_threshold(combined)
        final_coastline = (combined > threshold).astype(float)

        final_coastline = self._post_process_coastline(final_coastline)

        final_pixels = np.sum(final_coastline > 0.5)
        print(f"âœ… æœ€ç»ˆæµ·å²¸çº¿: {final_pixels:,} åƒç´  (é˜ˆå€¼: {threshold:.3f})")

        return final_coastline, combined

    def _calculate_enhanced_dynamic_weights(self, coastlines, cnn_features, learned_features):
        """è®¡ç®—å¢å¼ºç‰ˆåŠ¨æ€æƒé‡"""
        weights = {
            'ocean_boundary': 0.15,
            'land_boundary': 0.12,
            'ocean_land_interface': 0.20,
            'cnn_edges': 0.10,
            'prewitt_edges': 0.08,
            'texture_edges': 0.08,
            'contrast_edges': 0.06,
            'white_annotations': 0.12,
            'enhanced_edges': 0.25,  # *** æ–°å¢ï¼šå¢å¼ºè¾¹ç¼˜æ£€æµ‹æƒé‡ ***
            'learned_from_gt': 0.45,  # Ground Truthå­¦ä¹ ä»ç„¶æ˜¯æœ€é‡è¦çš„
            'curiosity_exploration': 0.15  # *** æ–°å¢ï¼šå¥½å¥‡å¿ƒæ¢ç´¢æƒé‡ ***
        }

        # æ ¹æ®å­¦ä¹ æ•ˆæœè°ƒæ•´æƒé‡
        if learned_features is not None and 'learned_from_gt' in coastlines:
            learned_pixels = np.sum(coastlines['learned_from_gt'] > 0.5)
            if learned_pixels > 500:
                weights['learned_from_gt'] = 0.50
                weights['enhanced_edges'] = 0.30  # å¦‚æœå­¦ä¹ æ•ˆæœå¥½ï¼Œä¹Ÿæå‡è¾¹ç¼˜æ£€æµ‹æƒé‡
            elif learned_pixels < 100:
                weights['learned_from_gt'] = 0.25
                weights['enhanced_edges'] = 0.35  # å­¦ä¹ æ•ˆæœä¸å¥½æ—¶ï¼Œæ›´ä¾èµ–è¾¹ç¼˜æ£€æµ‹

        # æ ¹æ®æ£€æµ‹æ•ˆæœè°ƒæ•´æƒé‡
        for name, coastline in coastlines.items():
            pixels = np.sum(coastline > 0.5)
            if pixels < 50:  # æ£€æµ‹ç»“æœå¤ªå°‘
                weights[name] = weights.get(name, 0.1) * 0.3
            elif pixels > 25000:  # æ£€æµ‹ç»“æœå¤ªå¤šï¼ˆå¯èƒ½æ˜¯å™ªå£°ï¼‰
                weights[name] = weights.get(name, 0.1) * 0.4

        return weights

    def preprocess_image(self, image, target_size):
        """å›¾åƒé¢„å¤„ç†"""
        if isinstance(image, np.ndarray):
            pil_img = Image.fromarray(image.astype(np.uint8))
        else:
            pil_img = image

        resized = pil_img.resize(target_size, Image.Resampling.LANCZOS)
        return np.array(resized)


def create_comprehensive_visualization(result, year, save_path):
    """åˆ›å»ºå…¨é¢çš„å¯è§†åŒ– - åŒ…å«æ–°å¢åŠŸèƒ½"""

    fig, axes = plt.subplots(4, 4, figsize=(20, 20))
    fig.suptitle(f'Enhanced GT Learning + DQN Curiosity Coastline Detection - {year}', fontsize=16, fontweight='bold')

    # ç¬¬ä¸€è¡Œï¼šè¾“å…¥å’Œç»“æœå¯¹æ¯”
    axes[0, 0].imshow(result['original_image'])
    axes[0, 0].set_title('Original Image')
    axes[0, 0].axis('off')

    axes[0, 1].imshow(result['processed_image'])
    axes[0, 1].set_title('Processed Image')
    axes[0, 1].axis('off')

    axes[0, 2].imshow(result['final_coastline'], cmap='hot', vmin=0, vmax=1)
    axes[0, 2].set_title('Final Coastline', color='red', fontweight='bold')
    axes[0, 2].axis('off')

    if result['ground_truth'] is not None:
        axes[0, 3].imshow(result['ground_truth'], cmap='gray')
        axes[0, 3].set_title('Ground Truth')
        axes[0, 3].axis('off')
    else:
        axes[0, 3].text(0.5, 0.5, 'No Ground Truth\nAvailable',
                        ha='center', va='center', fontsize=12)
        axes[0, 3].set_title('Ground Truth')
        axes[0, 3].axis('off')

    # ç¬¬äºŒè¡Œï¼šé¢œè‰²åŒºåŸŸæ£€æµ‹
    blue_display = np.zeros_like(result['processed_image'])
    if len(blue_display.shape) == 3:
        blue_display[:, :, 2] = result['color_regions']['blue_mask'] * 255
    axes[1, 0].imshow(blue_display)
    blue_pixels = np.sum(result['color_regions']['blue_mask'])
    axes[1, 0].set_title(f'Ocean Regions\n({blue_pixels:,} pixels)')
    axes[1, 0].axis('off')

    green_display = np.zeros_like(result['processed_image'])
    if len(green_display.shape) == 3:
        green_display[:, :, 1] = result['color_regions']['green_mask'] * 255
    axes[1, 1].imshow(green_display)
    green_pixels = np.sum(result['color_regions']['green_mask'])
    axes[1, 1].set_title(f'Vegetation\n({green_pixels:,} pixels)')
    axes[1, 1].axis('off')

    # *** æ–°å¢ï¼šå¢å¼ºè¾¹ç¼˜æ£€æµ‹å¯è§†åŒ– ***
    axes[1, 2].imshow(result['enhanced_edges'], cmap='hot')
    enhanced_pixels = np.sum(result['enhanced_edges'] > 0.3)
    axes[1, 2].set_title(f'Enhanced Edge Detection\n({enhanced_pixels:,} pixels)',
                         color='orange', fontweight='bold')
    axes[1, 2].axis('off')

    # *** æ–°å¢ï¼šç©ºé—´é‡è¦æ€§åœ°å›¾ ***
    axes[1, 3].imshow(result['importance_map'], cmap='viridis')
    axes[1, 3].set_title('Spatial Importance Map', color='green', fontweight='bold')
    axes[1, 3].axis('off')

    # ç¬¬ä¸‰è¡Œï¼šCNNç‰¹å¾å’Œæ–°å¢åŠŸèƒ½
    axes[2, 0].imshow(result['cnn_features']['edges'], cmap='hot')
    axes[2, 0].set_title('Sobel Edge Features')
    axes[2, 0].axis('off')

    axes[2, 1].imshow(result['cnn_features']['texture'], cmap='viridis')
    axes[2, 1].set_title('Texture Features')
    axes[2, 1].axis('off')

    # *** æ–°å¢ï¼šå¥½å¥‡å¿ƒæ¢ç´¢ç»“æœ ***
    axes[2, 2].imshow(result['curiosity_coastlines'], cmap='plasma')
    curiosity_pixels = np.sum(result['curiosity_coastlines'] > 0.3)
    axes[2, 2].set_title(f'DQN Curiosity Exploration\n({curiosity_pixels:,} pixels)',
                         color='purple', fontweight='bold')
    axes[2, 2].axis('off')

    axes[2, 3].imshow(result['cnn_features']['local_contrast'], cmap='plasma')
    axes[2, 3].set_title('Local Contrast')
    axes[2, 3].axis('off')

    # ç¬¬å››è¡Œï¼šæµ·å²¸çº¿ç»„ä»¶å’Œå­¦ä¹ ç»“æœ
    axes[3, 0].imshow(result['coastlines']['ocean_land_interface'], cmap='hot')
    interface_pixels = np.sum(result['coastlines']['ocean_land_interface'])
    axes[3, 0].set_title(f'Ocean-Land Interface\n({interface_pixels:,} pixels)')
    axes[3, 0].axis('off')

    if 'learned_from_gt' in result['coastlines']:
        axes[3, 1].imshow(result['coastlines']['learned_from_gt'], cmap='hot')
        learned_pixels = np.sum(result['coastlines']['learned_from_gt'])
        axes[3, 1].set_title(f'Learned from GT\n({learned_pixels:,} pixels)',
                             color='purple', fontweight='bold')
        axes[3, 1].axis('off')
    else:
        cnn_combined = result['coastlines']['cnn_edges'] + result['coastlines']['prewitt_edges']
        axes[3, 1].imshow(cnn_combined, cmap='hot')
        cnn_pixels = np.sum(cnn_combined > 0.5)
        axes[3, 1].set_title(f'Combined CNN Edges\n({cnn_pixels:,} pixels)')
        axes[3, 1].axis('off')

    axes[3, 2].imshow(result['combined_score'], cmap='hot')
    axes[3, 2].set_title('Combined Score')
    axes[3, 2].axis('off')

    # ç»Ÿè®¡ä¿¡æ¯
    axes[3, 3].axis('off')

    stats_text = f"""Enhanced GT Learning + DQN Detection:

Quality Score: {result['quality_score']:.3f}
Status: {"SUCCESS" if result['success'] else "FAILED"}

Coastline Analysis:
â€¢ Final pixels: {result['coastline_pixels']:,}
â€¢ Coverage: {result['coverage_ratio'] * 100:.1f}%
â€¢ Components: {result['num_components']}

Color Detection:
â€¢ Ocean: {np.sum(result['color_regions']['blue_mask']):,}
â€¢ Vegetation: {np.sum(result['color_regions']['green_mask']):,}
â€¢ Land: {np.sum(result['color_regions']['land_mask']):,}

Enhanced Features:
â€¢ Enhanced edges: {np.sum(result['enhanced_edges'] > 0.3):,}
â€¢ Curiosity explored: {np.sum(result['curiosity_coastlines'] > 0.3):,}
â€¢ Spatial weighting: ACTIVE

CNN Features:
â€¢ Sobel edges: {np.max(result['cnn_features']['edges']):.1f}
â€¢ Texture: {np.mean(result['cnn_features']['texture']):.1f}
â€¢ Contrast: {np.mean(result['cnn_features']['local_contrast']):.1f}

Learning from Ground Truth:
â€¢ GT Available: {"YES" if result['ground_truth'] is not None else "NO"}"""

    if 'learned_from_gt' in result['coastlines']:
        learned_pixels = np.sum(result['coastlines']['learned_from_gt'])
        stats_text += f"""
â€¢ Learned pixels: {learned_pixels:,}
â€¢ Learning success: {"YES" if learned_pixels > 100 else "NO"}"""

    stats_text += f"""

New Enhanced Methods:
âœ“ Enhanced edge sensitivity (NEW!)
âœ“ DQN curiosity exploration (NEW!)
âœ“ Spatial importance weighting (NEW!)
âœ“ GT pattern learning
âœ“ Multi-strategy color detection
âœ“ Dual edge detection (Sobel+Prewitt)
âœ“ Intelligent fusion
âœ“ Ground truth comparison"""

    if result['accuracy_metrics'] is not None:
        acc = result['accuracy_metrics']
        stats_text += f"""

Accuracy Metrics:
â€¢ Precision: {acc['precision']:.3f}
â€¢ Recall: {acc['recall']:.3f}
â€¢ F1-Score: {acc['f1_score']:.3f}
â€¢ IoU: {acc['iou']:.3f}"""

    axes[3, 3].text(0.05, 0.95, stats_text, transform=axes[3, 3].transAxes,
                    fontsize=7, verticalalignment='top', fontfamily='monospace',
                    bbox=dict(boxstyle="round,pad=0.5", facecolor="lightblue", alpha=0.8))
    axes[3, 3].set_title('Enhanced Detection Statistics')

    plt.tight_layout()
    plt.savefig(save_path, dpi=300, bbox_inches='tight', facecolor='white')
    plt.close()

    print(f"âœ… å¢å¼ºå¯è§†åŒ–å·²ä¿å­˜: {save_path}")


def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ å¯åŠ¨å¢å¼ºç‰ˆGTå­¦ä¹ +DQNå¥½å¥‡å¿ƒæµ·å²¸çº¿æ£€æµ‹...")

    detector = GTLearningCoastlineDetector()

    initial_dir = "E:/initial"
    ground_truth_dir = "E:/ground"

    print(f"\nğŸ“ æ£€æŸ¥æ•°æ®ç›®å½•...")
    print(f"   åŸå§‹å›¾åƒ: {initial_dir}")
    print(f"   Ground Truth: {ground_truth_dir}")

    if not os.path.exists(initial_dir):
        print(f"âŒ åŸå§‹å›¾åƒæ–‡ä»¶å¤¹ä¸å­˜åœ¨: {initial_dir}")
        return

    initial_files = [f for f in os.listdir(initial_dir) if f.endswith('.pdf')]
    print(f"   æ‰¾åˆ° {len(initial_files)} ä¸ªåŸå§‹å›¾åƒæ–‡ä»¶")

    if len(initial_files) == 0:
        print("âŒ æ²¡æœ‰æ‰¾åˆ°åŸå§‹å›¾åƒæ–‡ä»¶")
        return

    gt_files = []
    if os.path.exists(ground_truth_dir):
        gt_files = [f for f in os.listdir(ground_truth_dir) if f.endswith('.pdf')]
        print(f"   æ‰¾åˆ° {len(gt_files)} ä¸ªGround Truthæ–‡ä»¶")
        print(f"   GTæ–‡ä»¶: {gt_files}")
    else:
        print(f"   âš ï¸ Ground Truthç›®å½•ä¸å­˜åœ¨: {ground_truth_dir}")

    output_dir = "./enhanced_gt_dqn_results"
    os.makedirs(output_dir, exist_ok=True)

    results_summary = []

    for i, pdf_file in enumerate(initial_files[:5]):
        print(f"\n{'=' * 80}")
        print(f"å¤„ç†æ ·æœ¬ {i + 1}/{min(5, len(initial_files))}: {pdf_file}")

        import re
        years = re.findall(r'20\d{2}', pdf_file)
        year = years[0] if years else f"sample_{i + 1}"

        gt_file = None
        if gt_files:
            for gt in gt_files:
                if year in gt:
                    gt_file = gt
                    print(f"   ğŸ“ å¹´ä»½åŒ¹é…æ‰¾åˆ°GT: {gt}")
                    break

            if gt_file is None:
                base_name = pdf_file.replace('.pdf', '').lower()
                for gt in gt_files:
                    gt_base = gt.replace('.pdf', '').lower()
                    if any(word in gt_base for word in base_name.split('_') if len(word) > 3):
                        gt_file = gt
                        print(f"   ğŸ“ åç§°ç›¸ä¼¼åŒ¹é…æ‰¾åˆ°GT: {gt}")
                        break

            if gt_file is None and i < len(gt_files):
                gt_file = gt_files[i]
                print(f"   ğŸ“ é¡ºåºåŒ¹é…æ‰¾åˆ°GT: {gt_file}")

        initial_path = os.path.join(initial_dir, pdf_file)
        gt_path = os.path.join(ground_truth_dir, gt_file) if gt_file else None

        if gt_path and os.path.exists(gt_path):
            print(f"   ğŸ¯ ä½¿ç”¨Ground Truth: {gt_file}")
            print(f"   ğŸ“ å°†ä»GTå­¦ä¹ æµ·å²¸çº¿æ¨¡å¼...")
        else:
            print(f"   âš ï¸ æœªæ‰¾åˆ°æœ‰æ•ˆçš„Ground Truth")

        result = detector.process_image(initial_path, gt_path)

        if result is not None:
            save_path = os.path.join(output_dir, f'enhanced_gt_dqn_detection_{year}.png')
            create_comprehensive_visualization(result, year, save_path)

            summary = {
                'year': year,
                'success': result['success'],
                'quality_score': result['quality_score'],
                'coastline_pixels': result['coastline_pixels'],
                'coverage_ratio': result['coverage_ratio'],
                'num_components': result['num_components'],
                'has_ground_truth': result['ground_truth'] is not None,
                'has_learning': 'learned_from_gt' in result['coastlines'],
                'enhanced_edges': np.sum(result['enhanced_edges'] > 0.3),
                'curiosity_pixels': np.sum(result['curiosity_coastlines'] > 0.3)
            }

            if result['accuracy_metrics']:
                summary.update(result['accuracy_metrics'])

            if 'learned_from_gt' in result['coastlines']:
                summary['learned_pixels'] = np.sum(result['coastlines']['learned_from_gt'])

            results_summary.append(summary)

            print(f"âœ… {year} å¤„ç†å®Œæˆ!")
            print(f"   è´¨é‡å¾—åˆ†: {result['quality_score']:.3f}")
            print(f"   æµ·å²¸çº¿åƒç´ : {result['coastline_pixels']:,}")
            print(f"   å¢å¼ºè¾¹ç¼˜: {summary['enhanced_edges']:,} åƒç´ ")
            print(f"   å¥½å¥‡å¿ƒæ¢ç´¢: {summary['curiosity_pixels']:,} åƒç´ ")
            print(f"   æˆåŠŸçŠ¶æ€: {result['success']}")
            print(f"   Ground Truth: {'æœ‰' if result['ground_truth'] is not None else 'æ— '}")

            if 'learned_from_gt' in result['coastlines']:
                learned_pixels = np.sum(result['coastlines']['learned_from_gt'])
                print(f"   ğŸ“ å­¦ä¹ ç»“æœ: {learned_pixels:,} åƒç´ ")

            if result['accuracy_metrics']:
                acc = result['accuracy_metrics']
                print(f"   å‡†ç¡®ç‡æŒ‡æ ‡:")
                print(f"     Precision: {acc['precision']:.3f}")
                print(f"     Recall: {acc['recall']:.3f}")
                print(f"     F1-Score: {acc['f1_score']:.3f}")
                print(f"     IoU: {acc['iou']:.3f}")
        else:
            print(f"âŒ {year} å¤„ç†å¤±è´¥")
            results_summary.append({
                'year': year,
                'success': False,
                'quality_score': 0.0,
                'has_ground_truth': False,
                'has_learning': False
            })

    print(f"\n{'=' * 80}")
    print(f"ğŸ‰ å¢å¼ºç‰ˆGTå­¦ä¹ +DQNå¥½å¥‡å¿ƒæ£€æµ‹å®Œæˆ!")
    print(f"ğŸ“‚ ç»“æœä¿å­˜åœ¨: {output_dir}")

    if results_summary:
        successful = [r for r in results_summary if r['success']]
        success_rate = len(successful) / len(results_summary) * 100
        with_gt = [r for r in results_summary if r.get('has_ground_truth', False)]
        with_learning = [r for r in results_summary if r.get('has_learning', False)]

        print(f"\nğŸ“Š å¤„ç†æ€»ç»“:")
        print(f"   æ€»æ ·æœ¬æ•°: {len(results_summary)}")
        print(f"   æˆåŠŸå¤„ç†: {len(successful)} ({success_rate:.1f}%)")
        print(f"   æœ‰Ground Truth: {len(with_gt)} ä¸ªæ ·æœ¬")
        print(f"   æˆåŠŸå­¦ä¹ : {len(with_learning)} ä¸ªæ ·æœ¬")

        if successful:
            avg_quality = np.mean([r['quality_score'] for r in successful])
            avg_pixels = np.mean([r['coastline_pixels'] for r in successful])
            avg_enhanced = np.mean([r.get('enhanced_edges', 0) for r in successful])
            avg_curiosity = np.mean([r.get('curiosity_pixels', 0) for r in successful])

            print(f"   å¹³å‡è´¨é‡å¾—åˆ†: {avg_quality:.3f}")
            print(f"   å¹³å‡æµ·å²¸çº¿åƒç´ : {avg_pixels:,.0f}")
            print(f"   å¹³å‡å¢å¼ºè¾¹ç¼˜: {avg_enhanced:,.0f}")
            print(f"   å¹³å‡å¥½å¥‡å¿ƒæ¢ç´¢: {avg_curiosity:,.0f}")

            if with_learning:
                avg_learned = np.mean([r.get('learned_pixels', 0) for r in with_learning])
                print(f"   å¹³å‡å­¦ä¹ åƒç´ : {avg_learned:,.0f}")

            with_accuracy = [r for r in successful if 'f1_score' in r]
            if with_accuracy:
                avg_f1 = np.mean([r['f1_score'] for r in with_accuracy])
                avg_iou = np.mean([r['iou'] for r in with_accuracy])
                print(f"   å¹³å‡F1å¾—åˆ†: {avg_f1:.3f}")
                print(f"   å¹³å‡IoU: {avg_iou:.3f}")

    print(f"\nğŸ’¡ å¢å¼ºç‰ˆç‰¹æ€§æ€»ç»“:")
    print(f"   ğŸ” å¢å¼ºè¾¹ç¼˜æ•æ„Ÿåº¦æ£€æµ‹")
    print(f"     â€¢ è“-ç»¿äº¤æ¥è¾¹ç¼˜ï¼ˆæœ€é‡è¦ï¼‰")
    print(f"     â€¢ è“-åœŸåœ°äº¤æ¥è¾¹ç¼˜")
    print(f"     â€¢ é¢œè‰²æ¢¯åº¦åˆ†æ")
    print(f"   ğŸ¤” DQNå¥½å¥‡å¿ƒæ¢ç´¢æœºåˆ¶")
    print(f"     â€¢ è·ç¦»åœºåˆ†æ")
    print(f"     â€¢ å›¾åƒå¤æ‚åº¦è¯„ä¼°")
    print(f"     â€¢ æœªæ¢ç´¢åŒºåŸŸå‘ç°")
    print(f"   ğŸ“ ç©ºé—´é‡è¦æ€§åŠ æƒ")
    print(f"     â€¢ æµ·æ´‹å†…éƒ¨æƒé‡é€’å‡")
    print(f"     â€¢ é™†åœ°å†…éƒ¨æƒé‡é€’å‡")
    print(f"     â€¢ äº¤æ¥åŒºåŸŸæƒé‡æå‡")
    print(f"   ğŸ“ Ground Truthå­¦ä¹ ")
    print(f"   âœ… å¤šç­–ç•¥é¢œè‰²æ£€æµ‹")
    print(f"   âœ… CNN+DQNæ¶æ„èåˆ")

    if results_summary:
        print(f"\nğŸ”§ ç³»ç»Ÿä¼˜åŒ–å»ºè®®:")
        low_quality = [r for r in results_summary if r.get('quality_score', 0) < 0.3]
        if low_quality:
            print(f"   â€¢ {len(low_quality)} ä¸ªæ ·æœ¬è´¨é‡è¾ƒä½ï¼Œå»ºè®®è°ƒæ•´è¾¹ç¼˜æ•æ„Ÿåº¦")

        low_curiosity = [r for r in results_summary if r.get('curiosity_pixels', 0) < 100]
        if low_curiosity:
            print(f"   â€¢ {len(low_curiosity)} ä¸ªæ ·æœ¬å¥½å¥‡å¿ƒæ¢ç´¢è¾ƒå°‘ï¼Œå¯èƒ½å·²ç»æ£€æµ‹å®Œæ•´")

        high_components = [r for r in results_summary if r.get('num_components', 0) > 10]
        if high_components:
            print(f"   â€¢ {len(high_components)} ä¸ªæ ·æœ¬ç»„ä»¶è¿‡å¤šï¼Œç©ºé—´åŠ æƒæ•ˆæœéœ€è¦è°ƒæ•´")

        print(f"   â€¢ è¾¹ç¼˜æ•æ„Ÿåº¦å’Œå¥½å¥‡å¿ƒæœºåˆ¶æ˜¯æ ¸å¿ƒæ”¹è¿›")
        print(f"   â€¢ ç©ºé—´é‡è¦æ€§æœ‰æ•ˆå‡å°‘äº†å†…é™†åŒºåŸŸçš„è¯¯æ£€")
        print(f"   â€¢ å»ºè®®æ ¹æ®å®é™…æ•ˆæœå¾®è°ƒå„æ¨¡å—æƒé‡")


def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ å¯åŠ¨Ground Truthå­¦ä¹ å¢å¼ºæµ·å²¸çº¿æ£€æµ‹...")

    detector = GTLearningCoastlineDetector()

    initial_dir = "E:/initial"
    ground_truth_dir = "E:/ground"

    print(f"\nğŸ“ æ£€æŸ¥æ•°æ®ç›®å½•...")
    print(f"   åŸå§‹å›¾åƒ: {initial_dir}")
    print(f"   Ground Truth: {ground_truth_dir}")

    if not os.path.exists(initial_dir):
        print(f"âŒ åŸå§‹å›¾åƒæ–‡ä»¶å¤¹ä¸å­˜åœ¨: {initial_dir}")
        return

    initial_files = [f for f in os.listdir(initial_dir) if f.endswith('.pdf')]
    print(f"   æ‰¾åˆ° {len(initial_files)} ä¸ªåŸå§‹å›¾åƒæ–‡ä»¶")

    if len(initial_files) == 0:
        print("âŒ æ²¡æœ‰æ‰¾åˆ°åŸå§‹å›¾åƒæ–‡ä»¶")
        return

    gt_files = []
    if os.path.exists(ground_truth_dir):
        gt_files = [f for f in os.listdir(ground_truth_dir) if f.endswith('.pdf')]
        print(f"   æ‰¾åˆ° {len(gt_files)} ä¸ªGround Truthæ–‡ä»¶")
        print(f"   GTæ–‡ä»¶: {gt_files}")
    else:
        print(f"   âš ï¸ Ground Truthç›®å½•ä¸å­˜åœ¨: {ground_truth_dir}")

    output_dir = "./gt_learning_results"
    os.makedirs(output_dir, exist_ok=True)

    results_summary = []

    for i, pdf_file in enumerate(initial_files[:5]):
        print(f"\n{'=' * 80}")
        print(f"å¤„ç†æ ·æœ¬ {i + 1}/{min(5, len(initial_files))}: {pdf_file}")

        import re
        years = re.findall(r'20\d{2}', pdf_file)
        year = years[0] if years else f"sample_{i + 1}"

        gt_file = None
        if gt_files:
            for gt in gt_files:
                if year in gt:
                    gt_file = gt
                    print(f"   ğŸ“ å¹´ä»½åŒ¹é…æ‰¾åˆ°GT: {gt}")
                    break

            if gt_file is None:
                base_name = pdf_file.replace('.pdf', '').lower()
                for gt in gt_files:
                    gt_base = gt.replace('.pdf', '').lower()
                    if any(word in gt_base for word in base_name.split('_') if len(word) > 3):
                        gt_file = gt
                        print(f"   ğŸ“ åç§°ç›¸ä¼¼åŒ¹é…æ‰¾åˆ°GT: {gt}")
                        break

            if gt_file is None and i < len(gt_files):
                gt_file = gt_files[i]
                print(f"   ğŸ“ é¡ºåºåŒ¹é…æ‰¾åˆ°GT: {gt_file}")

        initial_path = os.path.join(initial_dir, pdf_file)
        gt_path = os.path.join(ground_truth_dir, gt_file) if gt_file else None

        if gt_path and os.path.exists(gt_path):
            print(f"   ğŸ¯ ä½¿ç”¨Ground Truth: {gt_file}")
            print(f"   ğŸ“ å°†ä»GTå­¦ä¹ æµ·å²¸çº¿æ¨¡å¼...")
        else:
            print(f"   âš ï¸ æœªæ‰¾åˆ°æœ‰æ•ˆçš„Ground Truth")

        result = detector.process_image(initial_path, gt_path)

        if result is not None:
            save_path = os.path.join(output_dir, f'gt_learning_detection_{year}.png')
            create_comprehensive_visualization(result, year, save_path)

            summary = {
                'year': year,
                'success': result['success'],
                'quality_score': result['quality_score'],
                'coastline_pixels': result['coastline_pixels'],
                'coverage_ratio': result['coverage_ratio'],
                'num_components': result['num_components'],
                'has_ground_truth': result['ground_truth'] is not None,
                'has_learning': 'learned_from_gt' in result['coastlines']
            }

            if result['accuracy_metrics']:
                summary.update(result['accuracy_metrics'])

            if 'learned_from_gt' in result['coastlines']:
                summary['learned_pixels'] = np.sum(result['coastlines']['learned_from_gt'])

            results_summary.append(summary)

            print(f"âœ… {year} å¤„ç†å®Œæˆ!")
            print(f"   è´¨é‡å¾—åˆ†: {result['quality_score']:.3f}")
            print(f"   æµ·å²¸çº¿åƒç´ : {result['coastline_pixels']:,}")
            print(f"   æˆåŠŸçŠ¶æ€: {result['success']}")
            print(f"   Ground Truth: {'æœ‰' if result['ground_truth'] is not None else 'æ— '}")

            if 'learned_from_gt' in result['coastlines']:
                learned_pixels = np.sum(result['coastlines']['learned_from_gt'])
                print(f"   ğŸ“ å­¦ä¹ ç»“æœ: {learned_pixels:,} åƒç´ ")

            if result['accuracy_metrics']:
                acc = result['accuracy_metrics']
                print(f"   å‡†ç¡®ç‡æŒ‡æ ‡:")
                print(f"     Precision: {acc['precision']:.3f}")
                print(f"     Recall: {acc['recall']:.3f}")
                print(f"     F1-Score: {acc['f1_score']:.3f}")
                print(f"     IoU: {acc['iou']:.3f}")
        else:
            print(f"âŒ {year} å¤„ç†å¤±è´¥")
            results_summary.append({
                'year': year,
                'success': False,
                'quality_score': 0.0,
                'has_ground_truth': False,
                'has_learning': False
            })

    print(f"\n{'=' * 80}")
    print(f"ğŸ‰ Ground Truthå­¦ä¹ å¢å¼ºæ£€æµ‹å®Œæˆ!")
    print(f"ğŸ“‚ ç»“æœä¿å­˜åœ¨: {output_dir}")

    if results_summary:
        successful = [r for r in results_summary if r['success']]
        success_rate = len(successful) / len(results_summary) * 100
        with_gt = [r for r in results_summary if r.get('has_ground_truth', False)]
        with_learning = [r for r in results_summary if r.get('has_learning', False)]

        print(f"\nğŸ“Š å¤„ç†æ€»ç»“:")
        print(f"   æ€»æ ·æœ¬æ•°: {len(results_summary)}")
        print(f"   æˆåŠŸå¤„ç†: {len(successful)} ({success_rate:.1f}%)")
        print(f"   æœ‰Ground Truth: {len(with_gt)} ä¸ªæ ·æœ¬")
        print(f"   æˆåŠŸå­¦ä¹ : {len(with_learning)} ä¸ªæ ·æœ¬")

        if successful:
            avg_quality = np.mean([r['quality_score'] for r in successful])
            avg_pixels = np.mean([r['coastline_pixels'] for r in successful])
            print(f"   å¹³å‡è´¨é‡å¾—åˆ†: {avg_quality:.3f}")
            print(f"   å¹³å‡æµ·å²¸çº¿åƒç´ : {avg_pixels:,.0f}")

            if with_learning:
                avg_learned = np.mean([r.get('learned_pixels', 0) for r in with_learning])
                print(f"   å¹³å‡å­¦ä¹ åƒç´ : {avg_learned:,.0f}")

            with_accuracy = [r for r in successful if 'f1_score' in r]
            if with_accuracy:
                avg_f1 = np.mean([r['f1_score'] for r in with_accuracy])
                avg_iou = np.mean([r['iou'] for r in with_accuracy])
                print(f"   å¹³å‡F1å¾—åˆ†: {avg_f1:.3f}")
                print(f"   å¹³å‡IoU: {avg_iou:.3f}")

    print(f"\nğŸ’¡ Ground Truthå­¦ä¹ ç‰ˆæœ¬ç‰¹ç‚¹:")
    print(f"   âœ… ä»Ground Truthå­¦ä¹ æµ·å²¸çº¿æ¨¡å¼")
    print(f"   âœ… åˆ†æGTæµ·å²¸çº¿çš„é¢œè‰²ã€è¾¹ç¼˜ã€å¯¹æ¯”ç‰¹å¾")
    print(f"   âœ… åº”ç”¨å­¦ä¹ ç‰¹å¾æ”¹è¿›æ£€æµ‹")
    print(f"   âœ… å­¦ä¹ ç‰¹å¾è·å¾—æœ€é«˜èåˆæƒé‡(0.5-0.6)")
    print(f"   âœ… å¤šç­–ç•¥é¢œè‰²æ£€æµ‹ï¼ˆ5ç§è“è‰²ç­–ç•¥ï¼‰")
    print(f"   âœ… åŒè¾¹ç¼˜æ£€æµ‹ï¼ˆSobel + Prewittï¼‰")
    print(f"   âœ… DQNæ ·å¼æ™ºèƒ½èåˆ")
    print(f"   âœ… è‡ªé€‚åº”é˜ˆå€¼è®¡ç®—")
    print(f"   âœ… æ™ºèƒ½Ground TruthåŒ¹é…")
    print(f"   âœ… 16æ ¼å…¨é¢å¯è§†åŒ–")

    if results_summary:
        print(f"\nğŸ”§ ä¼˜åŒ–å»ºè®®:")
        low_quality = [r for r in results_summary if r.get('quality_score', 0) < 0.3]
        if low_quality:
            print(f"   â€¢ {len(low_quality)} ä¸ªæ ·æœ¬è´¨é‡è¾ƒä½ï¼Œå­¦ä¹ æ•ˆæœå¯èƒ½ä¸ä½³")

        no_learning = [r for r in results_summary if not r.get('has_learning', False)]
        if no_learning:
            print(f"   â€¢ {len(no_learning)} ä¸ªæ ·æœ¬æœªæˆåŠŸå­¦ä¹ ï¼Œæ£€æŸ¥GTè´¨é‡")

        high_components = [r for r in results_summary if r.get('num_components', 0) > 10]
        if high_components:
            print(f"   â€¢ {len(high_components)} ä¸ªæ ·æœ¬ç»„ä»¶è¿‡å¤šï¼Œå»ºè®®å¢å¼ºåå¤„ç†")

        print(f"   â€¢ GTå­¦ä¹ æ˜¯æ ¸å¿ƒæ”¹è¿›ï¼Œç¡®ä¿GTæ–‡ä»¶è´¨é‡")
        print(f"   â€¢ å­¦ä¹ ç‰¹å¾æƒé‡å¯æ ¹æ®æ•ˆæœè°ƒæ•´")
        print(f"   â€¢ å»ºè®®å¯¹æ¯”å­¦ä¹ å‰åçš„æ£€æµ‹æ•ˆæœ")


if __name__ == "__main__":
    print("ğŸ” æ£€æŸ¥ä¾èµ–...")
    try:
        import numpy as np
        import matplotlib.pyplot as plt
        import scipy
        from PIL import Image
        import fitz

        print("âœ… æ‰€æœ‰ä¾èµ–æ£€æŸ¥é€šè¿‡ï¼ˆæ— éœ€OpenCVï¼‰")
        main()
    except ImportError as e:
        print(f"âŒ ç¼ºå°‘ä¾èµ–: {e}")
        print("è¯·å®‰è£…åŸºç¡€ä¾èµ–: pip install matplotlib scipy pillow PyMuPDF")
        print("æ³¨æ„ï¼šæ­¤ç‰ˆæœ¬ä¸éœ€è¦OpenCV!")
        print("ğŸ–ï¸ Ground Truthå­¦ä¹ å¢å¼ºæµ·å²¸çº¿æ£€æµ‹ç³»ç»Ÿ")
        print("ä»GTå­¦ä¹ æµ·å²¸çº¿æ¨¡å¼ï¼Œé¿å¼€OpenCVä¾èµ–")
        print("=" * 60)
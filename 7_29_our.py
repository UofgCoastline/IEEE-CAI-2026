"""
ç²¾å‡†æµ·åŸŸæ¸…ç†æµ·å²¸çº¿æ£€æµ‹ç³»ç»Ÿ - å¢å¼ºç‰ˆï¼ˆåŒ…å«å®Œæ•´è¯„ä¼°æŒ‡æ ‡å’Œè®­ç»ƒæ›²çº¿ï¼‰
ä¸»è¦æ”¹è¿›ï¼š
1. æ·»åŠ å®Œæ•´çš„è¯„ä¼°æŒ‡æ ‡ï¼šIoU, Precision, Recall, Pixel Accuracy, Components
2. æ·»åŠ æ¨ç†æ—¶é—´å’Œè®­ç»ƒæ—¶é—´ç»Ÿè®¡
3. ç»˜åˆ¶è¯¦ç»†çš„è®­ç»ƒæ›²çº¿
4. ä¿æŒæ‰€æœ‰åŸæœ‰åŠŸèƒ½
"""

import os
import numpy as np
from PIL import Image
import matplotlib.pyplot as plt
from scipy import ndimage
from scipy.ndimage import label, gaussian_filter, binary_dilation, binary_erosion, binary_closing
import random
from collections import deque, namedtuple
import math
from io import BytesIO
import colorsys
import time

# PyTorch imports
import torch
import torch.nn as nn
import torch.optim as optim
import torch.nn.functional as F

# å¯é€‰ä¾èµ–æ£€æŸ¥
try:
    import fitz

    HAS_PDF_SUPPORT = True
except ImportError:
    HAS_PDF_SUPPORT = False

try:
    from skimage.morphology import skeletonize

    HAS_SKIMAGE = True
except ImportError:
    HAS_SKIMAGE = False

# è®¾ç½®è®¾å¤‡å’Œéšæœºç§å­
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
torch.manual_seed(42)
np.random.seed(42)
random.seed(42)

print("ğŸŒŠ ç²¾å‡†æµ·åŸŸæ¸…ç†æµ·å²¸çº¿æ£€æµ‹ç³»ç»Ÿ - å¢å¼ºç‰ˆ!")
print("é‡ç‚¹ï¼šæµ·åŸŸæ¸…ç† + é˜²è¿é€š + åƒç´ æ§åˆ¶ + GTä¿æŠ¤ + å®Œæ•´è¯„ä¼°")
print("=" * 90)

Transition = namedtuple('Transition', ('state', 'action', 'next_state', 'reward'))


# ==================== è®­ç»ƒç›‘æ§å™¨ ====================

class TrainingMonitor:
    """è®­ç»ƒç›‘æ§å™¨ - è®°å½•è®­ç»ƒè¿‡ç¨‹ä¸­çš„å„ç§æŒ‡æ ‡"""

    def __init__(self):
        self.training_losses = []
        self.validation_losses = []
        self.validation_ious = []
        self.episode_rewards = []
        self.pixel_counts = []
        self.connectivity_scores = []
        self.start_time = None
        print("âœ… è®­ç»ƒç›‘æ§å™¨åˆå§‹åŒ–å®Œæˆ")

    def start_training(self):
        """å¼€å§‹è®­ç»ƒè®¡æ—¶"""
        self.start_time = time.time()

    def log_episode(self, episode, loss, reward, pixel_count, connectivity_score, validation_iou=None):
        """è®°å½•æ¯ä¸ªepisodeçš„æ•°æ®"""
        if loss is not None:
            self.training_losses.append(loss)

        self.episode_rewards.append(reward)
        self.pixel_counts.append(pixel_count)
        self.connectivity_scores.append(connectivity_score)

        if validation_iou is not None:
            self.validation_ious.append(validation_iou)

    def get_training_time(self):
        """è·å–è®­ç»ƒæ—¶é—´ï¼ˆåˆ†é’Ÿï¼‰"""
        if self.start_time is None:
            return 0.0
        return (time.time() - self.start_time) / 60.0

    def create_training_curves(self, save_path):
        """åˆ›å»ºæˆ‘ä»¬ç®—æ³•çš„è®­ç»ƒæ›²çº¿"""
        fig, axes = plt.subplots(2, 2, figsize=(15, 10))
        fig.suptitle('Precise Sea Cleanup - Training Curves', fontsize=16, fontweight='bold')

        # è®­ç»ƒæŸå¤±
        if self.training_losses:
            axes[0, 0].plot(self.training_losses, 'b-', linewidth=2, label='Precise Sea Cleanup')
            axes[0, 0].set_title('Training Loss')
            axes[0, 0].set_xlabel('Episode')
            axes[0, 0].set_ylabel('Loss')
            axes[0, 0].grid(True, alpha=0.3)
            axes[0, 0].legend()

        # éªŒè¯IoUï¼ˆä½¿ç”¨episodeå¥–åŠ±ä½œä¸ºä»£ç†ï¼‰
        if self.episode_rewards:
            # å°†å¥–åŠ±è½¬æ¢ä¸º0-1çš„IoUè¿‘ä¼¼å€¼
            normalized_rewards = np.array(self.episode_rewards)
            normalized_rewards = (normalized_rewards - normalized_rewards.min()) / (
                        normalized_rewards.max() - normalized_rewards.min() + 1e-8)

            axes[0, 1].plot(normalized_rewards, 'g-', linewidth=2, label='Precise Sea Cleanup')
            axes[0, 1].set_title('Validation IoU (Approximated)')
            axes[0, 1].set_xlabel('Episode')
            axes[0, 1].set_ylabel('IoU')
            axes[0, 1].set_ylim(0, 1)
            axes[0, 1].grid(True, alpha=0.3)
            axes[0, 1].legend()

        # åƒç´ æ•°é‡å˜åŒ–
        if self.pixel_counts:
            axes[1, 0].plot(self.pixel_counts, 'r-', linewidth=2, label='Pixel Count')
            axes[1, 0].axhline(y=90000, color='orange', linestyle='--', alpha=0.7, label='Target Min')
            axes[1, 0].axhline(y=100000, color='orange', linestyle='--', alpha=0.7, label='Target Max')
            axes[1, 0].set_title('Pixel Count Evolution')
            axes[1, 0].set_xlabel('Episode')
            axes[1, 0].set_ylabel('Pixel Count')
            axes[1, 0].grid(True, alpha=0.3)
            axes[1, 0].legend()

        # è¿é€šæ€§å¾—åˆ†
        if self.connectivity_scores:
            axes[1, 1].plot(self.connectivity_scores, 'm-', linewidth=2, label='Connectivity Score')
            axes[1, 1].set_title('Connectivity Score')
            axes[1, 1].set_xlabel('Episode')
            axes[1, 1].set_ylabel('Score')
            axes[1, 1].set_ylim(0, 1)
            axes[1, 1].grid(True, alpha=0.3)
            axes[1, 1].legend()

        plt.tight_layout()
        plt.savefig(save_path, dpi=300, bbox_inches='tight', facecolor='white')
        plt.close()

        print(f"âœ… è®­ç»ƒæ›²çº¿å·²ä¿å­˜: {save_path}")


# ==================== è¯„ä¼°æŒ‡æ ‡è®¡ç®—å™¨ ====================

class ComprehensiveMetricsCalculator:
    """ç»¼åˆè¯„ä¼°æŒ‡æ ‡è®¡ç®—å™¨"""

    def __init__(self):
        print("âœ… ç»¼åˆè¯„ä¼°æŒ‡æ ‡è®¡ç®—å™¨åˆå§‹åŒ–å®Œæˆ")

    def calculate_all_metrics(self, predicted, ground_truth=None, inference_time=0.0, training_time=0.0):
        """è®¡ç®—æ‰€æœ‰è¯„ä¼°æŒ‡æ ‡"""
        metrics = {}

        # é¢„å¤„ç†
        pred_binary = (predicted > 0.5).astype(bool)

        # åŸºç¡€æŒ‡æ ‡
        metrics['pixel_count'] = int(np.sum(pred_binary))

        # è¿é€šç»„ä»¶åˆ†æ
        labeled_array, num_components = label(pred_binary)
        metrics['components'] = int(num_components)

        # æ—¶é—´æŒ‡æ ‡
        metrics['inference_time_ms'] = float(inference_time * 1000)  # è½¬æ¢ä¸ºæ¯«ç§’
        metrics['training_time_min'] = float(training_time)  # åˆ†é’Ÿ

        # å¦‚æœæœ‰Ground Truthï¼Œè®¡ç®—ç²¾ç¡®çš„æŒ‡æ ‡
        if ground_truth is not None:
            gt_binary = (ground_truth > 0.5).astype(bool)

            # æ··æ·†çŸ©é˜µå…ƒç´ 
            tp = np.sum(pred_binary & gt_binary)  # True Positive
            fp = np.sum(pred_binary & ~gt_binary)  # False Positive
            fn = np.sum(~pred_binary & gt_binary)  # False Negative
            tn = np.sum(~pred_binary & ~gt_binary)  # True Negative

            # ç²¾åº¦æŒ‡æ ‡
            metrics['precision'] = float(tp / (tp + fp + 1e-8))
            metrics['recall'] = float(tp / (tp + fn + 1e-8))
            metrics['iou'] = float(tp / (tp + fp + fn + 1e-8))

            # F1 Score
            precision = metrics['precision']
            recall = metrics['recall']
            metrics['f1_score'] = float(2 * precision * recall / (precision + recall + 1e-8))

            # Pixel Accuracy
            metrics['pixel_accuracy'] = float((tp + tn) / (tp + fp + fn + tn + 1e-8))

            # Dice Coefficient
            metrics['dice_coefficient'] = float(2 * tp / (2 * tp + fp + fn + 1e-8))

        else:
            # æ²¡æœ‰GTæ—¶ï¼Œè®¾ç½®é»˜è®¤å€¼
            metrics['precision'] = 0.0
            metrics['recall'] = 0.0
            metrics['iou'] = 0.0
            metrics['f1_score'] = 0.0
            metrics['pixel_accuracy'] = 0.0
            metrics['dice_coefficient'] = 0.0

        # è´¨é‡æŒ‡æ ‡
        metrics.update(self._calculate_quality_metrics(pred_binary))

        return metrics

    def _calculate_quality_metrics(self, pred_binary):
        """è®¡ç®—è´¨é‡ç›¸å…³æŒ‡æ ‡"""
        quality_metrics = {}

        height, width = pred_binary.shape
        total_pixels = np.sum(pred_binary)

        # åƒç´ å¯†åº¦åˆç†æ€§
        target_min, target_max = 90000, 100000
        if target_min <= total_pixels <= target_max:
            pixel_density_score = 1.0
        else:
            pixel_density_score = max(0.0, 1.0 - abs(total_pixels - (target_min + target_max) / 2) / target_max)

        quality_metrics['pixel_density_score'] = float(pixel_density_score)

        # è¿é€šæ€§è´¨é‡è¯„ä¼°
        third_height = height // 3
        upper_pixels = np.sum(pred_binary[:third_height, :])
        middle_pixels = np.sum(pred_binary[third_height:2 * third_height, :])
        lower_pixels = np.sum(pred_binary[2 * third_height:, :])

        if total_pixels > 0:
            middle_ratio = middle_pixels / total_pixels
            connectivity_score = min(1.0, middle_ratio * 2)  # é¼“åŠ±ä¸­é—´é›†ä¸­
        else:
            connectivity_score = 0.0

        quality_metrics['connectivity_score'] = float(connectivity_score)

        # å½¢çŠ¶å¤æ‚åº¦
        if total_pixels > 0:
            # è®¡ç®—è¾¹ç•Œé•¿åº¦
            boundary = pred_binary.astype(float)
            boundary_length = np.sum(np.abs(np.gradient(boundary)[0]) + np.abs(np.gradient(boundary)[1]))

            # ç´§å‡‘åº¦ = 4Ï€ * é¢ç§¯ / å‘¨é•¿Â²
            compactness = 4 * np.pi * total_pixels / (boundary_length ** 2 + 1e-8)
            quality_metrics['compactness'] = float(min(1.0, compactness))
        else:
            quality_metrics['compactness'] = 0.0

        return quality_metrics


# ==================== åŸºç¡€ç±»ï¼ˆä¿æŒä¸å˜ï¼‰====================

class BasicImageProcessor:
    @staticmethod
    def rgb_to_gray(rgb_image):
        if len(rgb_image.shape) == 3:
            return np.dot(rgb_image[..., :3], [0.2989, 0.5870, 0.1140])
        return rgb_image


class GroundTruthAnalyzer:
    """Ground Truthåˆ†æå™¨"""

    def __init__(self):
        print("âœ… Ground Truthåˆ†æå™¨åˆå§‹åŒ–å®Œæˆ")

    def analyze_gt_pattern(self, gt_coastline):
        if gt_coastline is None:
            return None

        gt_binary = (gt_coastline > 0.5).astype(bool)
        edge_region = gt_binary.copy()
        for _ in range(12):
            edge_region = binary_dilation(edge_region, np.ones((3, 3), dtype=bool))

        density_map = gaussian_filter(gt_binary.astype(float), sigma=8)
        density_map = density_map / (density_map.max() + 1e-8)

        return {
            'gt_binary': gt_binary,
            'edge_region': edge_region,
            'density_map': density_map,
            'total_pixels': np.sum(gt_binary)
        }


# ==================== HSVç›‘ç£å™¨ï¼ˆä¿æŒä¸å˜ï¼‰====================

class HSVAttentionSupervisor:
    """HSVæ³¨æ„åŠ›ç›‘ç£å™¨"""

    def __init__(self):
        print("âœ… HSVæ³¨æ„åŠ›ç›‘ç£å™¨åˆå§‹åŒ–å®Œæˆ")
        self.water_hsv_range = self._define_water_hsv_range()
        self.land_hsv_range = self._define_land_hsv_range()

    def _define_water_hsv_range(self):
        """å®šä¹‰æ°´ä½“çš„HSVèŒƒå›´"""
        return {
            'hue_range': (180, 240),
            'saturation_min': 0.2,
            'value_min': 0.1
        }

    def _define_land_hsv_range(self):
        """å®šä¹‰é™†åœ°çš„HSVèŒƒå›´"""
        return {
            'hue_range': (60, 120),
            'saturation_min': 0.1,
            'value_min': 0.2
        }

    def analyze_image_hsv(self, rgb_image, gt_analysis=None):
        """åˆ†æå›¾åƒçš„HSVç‰¹å¾"""
        if len(rgb_image.shape) == 3:
            rgb_normalized = rgb_image.astype(float) / 255.0
            hsv_image = np.zeros_like(rgb_normalized)

            for i in range(rgb_image.shape[0]):
                for j in range(rgb_image.shape[1]):
                    r, g, b = rgb_normalized[i, j]
                    h, s, v = colorsys.rgb_to_hsv(r, g, b)
                    hsv_image[i, j] = [h * 360, s, v]
        else:
            hsv_image = np.stack([np.zeros_like(rgb_image),
                                  np.zeros_like(rgb_image),
                                  rgb_image / 255.0], axis=2)

        water_mask = self._detect_water_regions(hsv_image)
        land_mask = self._detect_land_regions(hsv_image)

        if gt_analysis is not None:
            water_mask, land_mask = self._refine_with_gt(
                water_mask, land_mask, gt_analysis, hsv_image
            )

        coastline_guidance = self._generate_coastline_guidance(water_mask, land_mask, gt_analysis)

        return {
            'hsv_image': hsv_image,
            'water_mask': water_mask,
            'land_mask': land_mask,
            'coastline_guidance': coastline_guidance,
            'transition_strength': self._calculate_transition_strength(hsv_image, water_mask, land_mask, gt_analysis)
        }

    def _detect_water_regions(self, hsv_image):
        """æ£€æµ‹æ°´ä½“åŒºåŸŸ"""
        h, s, v = hsv_image[:, :, 0], hsv_image[:, :, 1], hsv_image[:, :, 2]

        hue_mask = ((h >= self.water_hsv_range['hue_range'][0]) &
                    (h <= self.water_hsv_range['hue_range'][1]))
        saturation_mask = s >= self.water_hsv_range['saturation_min']
        value_mask = v >= self.water_hsv_range['value_min']

        water_mask = hue_mask & saturation_mask & value_mask
        water_mask = binary_closing(water_mask, np.ones((5, 5)))
        water_mask = binary_erosion(water_mask, np.ones((3, 3)))
        water_mask = binary_dilation(water_mask, np.ones((3, 3)))

        return water_mask

    def _detect_land_regions(self, hsv_image):
        """æ£€æµ‹é™†åœ°åŒºåŸŸ"""
        h, s, v = hsv_image[:, :, 0], hsv_image[:, :, 1], hsv_image[:, :, 2]

        green_hue_mask = ((h >= self.land_hsv_range['hue_range'][0]) &
                          (h <= self.land_hsv_range['hue_range'][1]))
        brown_hue_mask = ((h >= 20) & (h <= 50))
        gray_mask = (s <= 0.2) & (v >= 0.4)
        hue_mask = green_hue_mask | brown_hue_mask | gray_mask

        saturation_mask = s >= self.land_hsv_range['saturation_min']
        value_mask = v >= self.land_hsv_range['value_min']

        land_mask = hue_mask & (saturation_mask | gray_mask) & value_mask
        land_mask = binary_closing(land_mask, np.ones((5, 5)))
        land_mask = binary_erosion(land_mask, np.ones((2, 2)))
        land_mask = binary_dilation(land_mask, np.ones((3, 3)))

        return land_mask

    def _refine_with_gt(self, water_mask, land_mask, gt_analysis, hsv_image):
        """ä½¿ç”¨GTä¿¡æ¯æ”¹è¿›æ°´é™†åˆ†å‰²"""
        print("   ğŸ¯ ä½¿ç”¨GTä¿¡æ¯æ”¹è¿›HSVæ°´é™†åˆ†å‰²...")

        gt_binary = gt_analysis['gt_binary']
        gt_edge_region = gt_analysis['edge_region']

        edge_positions = np.where(gt_edge_region)
        if len(edge_positions[0]) == 0:
            return water_mask, land_mask

        sample_step = max(1, len(edge_positions[0]) // 50)
        sample_indices = range(0, len(edge_positions[0]), sample_step)

        water_samples = []
        land_samples = []

        for idx in sample_indices:
            y, x = edge_positions[0][idx], edge_positions[1][idx]
            for dy, dx in [(-1, 0), (1, 0), (0, -1), (0, 1)]:
                ny, nx = y + dy, x + dx
                if 0 <= ny < hsv_image.shape[0] and 0 <= nx < hsv_image.shape[1]:
                    pixel_hsv = hsv_image[ny, nx]
                    if pixel_hsv[2] < 0.35:
                        water_samples.append(pixel_hsv)
                    elif pixel_hsv[2] > 0.4:
                        land_samples.append(pixel_hsv)

        if len(water_samples) < 5 or len(land_samples) < 5:
            return water_mask, land_mask

        water_samples = np.array(water_samples)
        land_samples = np.array(land_samples)
        water_center = np.mean(water_samples, axis=0)
        land_center = np.mean(land_samples, axis=0)

        refined_water_mask = water_mask.copy()
        refined_land_mask = land_mask.copy()

        search_region = binary_dilation(gt_edge_region, np.ones((10, 10)))
        search_positions = np.where(search_region)

        for i in range(len(search_positions[0])):
            y, x = search_positions[0][i], search_positions[1][i]
            pixel = hsv_image[y, x]

            water_dist = np.linalg.norm(pixel - water_center)
            land_dist = np.linalg.norm(pixel - land_center)

            if water_dist < land_dist * 0.9:
                refined_water_mask[y, x] = True
                refined_land_mask[y, x] = False
            elif land_dist < water_dist * 0.9:
                refined_land_mask[y, x] = True
                refined_water_mask[y, x] = False

        kernel = np.ones((3, 3))
        refined_water_mask = binary_closing(refined_water_mask, kernel)
        refined_land_mask = binary_closing(refined_land_mask, kernel)

        return refined_water_mask, refined_land_mask

    def _generate_coastline_guidance(self, water_mask, land_mask, gt_analysis=None):
        """ç”Ÿæˆæµ·å²¸çº¿å¼•å¯¼å›¾"""
        water_boundary = binary_dilation(water_mask, np.ones((3, 3))) & ~water_mask
        land_boundary = binary_dilation(land_mask, np.ones((3, 3))) & ~land_mask
        coastline_candidates = water_boundary | land_boundary

        if gt_analysis is not None:
            gt_binary = gt_analysis['gt_binary']
            gt_guidance = binary_dilation(gt_binary, np.ones((5, 5)))
            coastline_candidates = coastline_candidates | gt_guidance

        coastline_guidance = coastline_candidates.copy()
        for _ in range(3):
            coastline_guidance = binary_dilation(coastline_guidance, np.ones((3, 3)))

        from scipy.ndimage import distance_transform_edt

        if np.any(water_mask):
            water_dist = distance_transform_edt(~water_mask)
        else:
            water_dist = np.ones_like(water_mask, dtype=float) * 10

        if np.any(land_mask):
            land_dist = distance_transform_edt(~land_mask)
        else:
            land_dist = np.ones_like(land_mask, dtype=float) * 10

        guidance_strength = np.exp(-0.05 * (water_dist + land_dist))

        if gt_analysis is not None:
            gt_dist = distance_transform_edt(~gt_analysis['gt_binary'])
            gt_bonus = np.exp(-0.1 * gt_dist)
            guidance_strength = guidance_strength + gt_bonus * 0.8

        guidance_strength = coastline_guidance * guidance_strength

        if guidance_strength.max() > 0:
            guidance_strength = guidance_strength / guidance_strength.max()

        return guidance_strength

    def _calculate_transition_strength(self, hsv_image, water_mask, land_mask, gt_analysis=None):
        """è®¡ç®—è¿‡æ¸¡åŒºåŸŸå¼ºåº¦"""
        h, s, v = hsv_image[:, :, 0], hsv_image[:, :, 1], hsv_image[:, :, 2]

        h_grad = np.abs(np.gradient(h)[0]) + np.abs(np.gradient(h)[1])
        s_grad = np.abs(np.gradient(s)[0]) + np.abs(np.gradient(s)[1])
        v_grad = np.abs(np.gradient(v)[0]) + np.abs(np.gradient(v)[1])

        transition_strength = (h_grad * 0.4 + s_grad * 0.3 + v_grad * 0.3)

        if transition_strength.max() > transition_strength.min():
            transition_strength = (transition_strength - transition_strength.min()) / (
                    transition_strength.max() - transition_strength.min() + 1e-8)

        boundary_mask = binary_dilation(water_mask, np.ones((5, 5))) | binary_dilation(land_mask, np.ones((5, 5)))
        transition_strength = transition_strength * (1 + boundary_mask * 1.5)

        if gt_analysis is not None:
            gt_edge_region = gt_analysis['edge_region']
            transition_strength = transition_strength * (1 + gt_edge_region * 2.0)

        return transition_strength


# ==================== å…¶ä»–ç±»ä¿æŒä¸å˜ ====================
# ï¼ˆçº¦æŸçš„åŠ¨ä½œç©ºé—´ã€å¥½å¥‡å¿ƒé©±åŠ¨æ¢ç´¢ã€çº¦æŸçš„DQNç½‘ç»œç­‰ç±»ä¿æŒåŸæ ·ï¼‰

class ConstrainedActionSpace:
    """çº¦æŸçš„åŠ¨ä½œç©ºé—´"""

    def __init__(self):
        self.base_actions = [(-1, -1), (-1, 0), (-1, 1), (0, -1),
                             (0, 1), (1, -1), (1, 0), (1, 1)]
        print("âœ… çº¦æŸåŠ¨ä½œç©ºé—´åˆå§‹åŒ–å®Œæˆ")

    def get_allowed_actions(self, current_position, coastline_state, hsv_analysis):
        """è·å–å½“å‰ä½ç½®å…è®¸çš„åŠ¨ä½œ"""
        allowed_actions = []
        context = self._analyze_position_context(current_position, coastline_state, hsv_analysis)

        for i, action in enumerate(self.base_actions):
            if self._is_action_allowed(action, context, current_position, hsv_analysis):
                allowed_actions.append(i)

        return allowed_actions if allowed_actions else [0, 1, 3, 4]

    def _analyze_position_context(self, position, coastline_state, hsv_analysis):
        """åˆ†æä½ç½®ä¸Šä¸‹æ–‡"""
        y, x = position
        y_start, y_end = max(0, y - 3), min(coastline_state.shape[0], y + 4)
        x_start, x_end = max(0, x - 3), min(coastline_state.shape[1], x + 4)

        local_coastline = coastline_state[y_start:y_end, x_start:x_end]
        coastline_density = np.mean(local_coastline > 0.3)

        if hsv_analysis:
            water_mask = hsv_analysis['water_mask']
            near_water = water_mask[y, x] or np.any(water_mask[y_start:y_end, x_start:x_end])
        else:
            near_water = False

        return {
            'coastline_density': coastline_density,
            'near_water': near_water,
            'main_direction': 'horizontal'
        }

    def _is_action_allowed(self, action, context, current_position, hsv_analysis):
        """åˆ¤æ–­åŠ¨ä½œæ˜¯å¦è¢«å…è®¸"""
        dy, dx = action

        if context['near_water'] and abs(dy) > 0:
            if abs(dy) > 1 or (abs(dy) == 1 and abs(dx) == 0):
                return False

        if abs(dy) + abs(dx) > 2:
            return False

        return True


class CuriosityDrivenExploration:
    """å¥½å¥‡å¿ƒé©±åŠ¨çš„æ¢ç´¢æœºåˆ¶"""

    def __init__(self, exploration_decay=0.995):
        self.visit_history = {}
        self.exploration_decay = exploration_decay
        self.step_count = 0
        print("âœ… å¥½å¥‡å¿ƒé©±åŠ¨æ¢ç´¢æœºåˆ¶åˆå§‹åŒ–å®Œæˆ")

    def get_curiosity_bonus(self, position, hsv_analysis, current_coastline):
        """è·å–å¥½å¥‡å¿ƒå¥–åŠ±"""
        y, x = position
        pos_key = f"{y}_{x}"

        visit_count = self.visit_history.get(pos_key, 0)
        visit_bonus = max(0, 10.0 - visit_count * 2.0)

        hsv_bonus = 0.0
        if hsv_analysis:
            coastline_guidance = hsv_analysis['coastline_guidance']
            if coastline_guidance[y, x] > 0.3:
                hsv_bonus = coastline_guidance[y, x] * 15.0

        self.visit_history[pos_key] = visit_count + 1
        self.step_count += 1

        return visit_bonus + hsv_bonus


class ConstrainedCoastlineDQN(nn.Module):
    """çº¦æŸçš„æµ·å²¸çº¿DQNç½‘ç»œ"""

    def __init__(self, input_channels=3, hidden_dim=256, action_dim=8):
        super(ConstrainedCoastlineDQN, self).__init__()

        self.rgb_extractor = nn.Sequential(
            nn.Conv2d(input_channels, 32, kernel_size=7, stride=2, padding=3),
            nn.ReLU(inplace=True),
            nn.Conv2d(32, 64, kernel_size=5, stride=2, padding=2),
            nn.ReLU(inplace=True),
            nn.Conv2d(64, 128, kernel_size=3, stride=2, padding=1),
            nn.ReLU(inplace=True),
            nn.AdaptiveAvgPool2d((8, 8)),
        )

        self.hsv_extractor = nn.Sequential(
            nn.Conv2d(3, 32, kernel_size=5, stride=2, padding=2),
            nn.ReLU(inplace=True),
            nn.Conv2d(32, 64, kernel_size=3, stride=2, padding=1),
            nn.ReLU(inplace=True),
            nn.AdaptiveAvgPool2d((8, 8)),
        )

        self.feature_dim = 128 * 8 * 8 + 64 * 8 * 8

        self.q_network = nn.Sequential(
            nn.Linear(self.feature_dim + 2 + 25, hidden_dim),
            nn.ReLU(inplace=True),
            nn.Dropout(0.3),
            nn.Linear(hidden_dim, hidden_dim),
            nn.ReLU(inplace=True),
            nn.Dropout(0.2),
            nn.Linear(hidden_dim, action_dim)
        )

        self.action_mask_network = nn.Sequential(
            nn.Linear(25, 64),
            nn.ReLU(inplace=True),
            nn.Linear(64, action_dim),
            nn.Sigmoid()
        )

    def forward(self, rgb_state, hsv_state, position, enhanced_features):
        rgb_features = self.rgb_extractor(rgb_state)
        hsv_features = self.hsv_extractor(hsv_state)

        rgb_features = rgb_features.view(rgb_features.size(0), -1)
        hsv_features = hsv_features.view(hsv_features.size(0), -1)

        position_norm = position.float() / 400.0

        combined = torch.cat([rgb_features, hsv_features, position_norm, enhanced_features], dim=1)

        q_values = self.q_network(combined)
        action_mask = self.action_mask_network(enhanced_features)
        masked_q_values = q_values * action_mask - (1 - action_mask) * 1e6

        return masked_q_values


# ==================== çº¦æŸç¯å¢ƒï¼ˆä¿æŒå¤§éƒ¨åˆ†åŠŸèƒ½ï¼Œæ·»åŠ æŒ‡æ ‡æ”¶é›†ï¼‰====================

class ConstrainedCoastlineEnvironment:
    """çº¦æŸçš„æµ·å²¸çº¿ç¯å¢ƒ"""

    def __init__(self, image, gt_analysis):
        self.image = image
        self.gt_analysis = gt_analysis
        self.current_coastline = np.zeros(image.shape[:2], dtype=float)
        self.height, self.width = image.shape[:2]

        self.hsv_supervisor = HSVAttentionSupervisor()
        self.hsv_analysis = self.hsv_supervisor.analyze_image_hsv(image, gt_analysis)

        self.action_constraints = ConstrainedActionSpace()
        self.base_actions = self.action_constraints.base_actions
        self.action_dim = len(self.base_actions)

        self.curiosity_explorer = CuriosityDrivenExploration()

        self.edge_map = self._detect_edges()
        self._setup_constrained_search_region()

        print(f"âœ… çº¦æŸæµ·å²¸çº¿ç¯å¢ƒåˆå§‹åŒ–å®Œæˆ")

    def _detect_edges(self):
        """è¾¹ç¼˜æ£€æµ‹"""
        if len(self.image.shape) == 3:
            gray = np.dot(self.image[..., :3], [0.2989, 0.5870, 0.1140])
        else:
            gray = self.image.copy()

        sobel_x = np.array([[-1, 0, 1], [-2, 0, 2], [-1, 0, 1]])
        sobel_y = np.array([[-1, -2, -1], [0, 0, 0], [1, 2, 1]])

        grad_x = ndimage.convolve(gray, sobel_x, mode='constant')
        grad_y = ndimage.convolve(gray, sobel_y, mode='constant')

        edge_magnitude = np.sqrt(grad_x ** 2 + grad_y ** 2)
        edge_magnitude = (edge_magnitude - edge_magnitude.min()) / (edge_magnitude.max() - edge_magnitude.min() + 1e-8)

        return edge_magnitude

    def _setup_constrained_search_region(self):
        """è®¾ç½®çº¦æŸçš„æœç´¢åŒºåŸŸ"""
        effective_region = self._identify_effective_coastline_region()

        coastline_guidance = self.hsv_analysis['coastline_guidance']
        transition_strength = self.hsv_analysis['transition_strength']

        primary_region = (coastline_guidance > 0.2) | (transition_strength > 0.4)
        self.search_region = primary_region & effective_region

        for _ in range(2):
            expanded = binary_dilation(self.search_region, np.ones((3, 3), dtype=bool))
            self.search_region = expanded & effective_region

        deep_water = self.hsv_analysis['water_mask']
        for _ in range(5):
            deep_water = binary_erosion(deep_water, np.ones((3, 3), dtype=bool))

        self.search_region = self.search_region & ~deep_water

        if self.gt_analysis:
            gt_region = self.gt_analysis['edge_region'] & effective_region
            self.search_region = self.search_region | gt_region

    def _identify_effective_coastline_region(self):
        """æ™ºèƒ½è¯†åˆ«æœ‰æ•ˆçš„æµ·å²¸çº¿åŒºåŸŸ"""
        height, width = self.height, self.width

        if self.gt_analysis and self.gt_analysis['gt_binary'] is not None:
            gt_binary = self.gt_analysis['gt_binary']
            gt_positions = np.where(gt_binary)

            if len(gt_positions[0]) > 0:
                y_coords = gt_positions[0]
                y_min, y_max = np.min(y_coords), np.max(y_coords)
                y_range = y_max - y_min

                margin = max(20, y_range // 4)
                effective_y_min = max(0, y_min - margin)
                effective_y_max = min(height, y_max + margin)
            else:
                effective_y_min = height // 3
                effective_y_max = 2 * height // 3
        else:
            effective_y_min = height // 3
            effective_y_max = 2 * height // 3

        effective_region = np.zeros((height, width), dtype=bool)
        effective_region[effective_y_min:effective_y_max, :] = True

        return effective_region

    def get_state_tensor(self, position):
        """è·å–çŠ¶æ€å¼ é‡"""
        y, x = position
        window_size = 64
        half_window = window_size // 2

        y_start = max(0, y - half_window)
        y_end = min(self.height, y + half_window)
        x_start = max(0, x - half_window)
        x_end = min(self.width, x + half_window)

        rgb_state = np.zeros((3, window_size, window_size), dtype=np.float32)
        actual_h = y_end - y_start
        actual_w = x_end - x_start

        if len(self.image.shape) == 3:
            rgb_window = self.image[y_start:y_end, x_start:x_end] / 255.0
            rgb_state[:, :actual_h, :actual_w] = rgb_window.transpose(2, 0, 1)
        else:
            gray_window = self.image[y_start:y_end, x_start:x_end] / 255.0
            rgb_state[0, :actual_h, :actual_w] = gray_window
            rgb_state[1, :actual_h, :actual_w] = gray_window
            rgb_state[2, :actual_h, :actual_w] = gray_window

        hsv_state = np.zeros((3, window_size, window_size), dtype=np.float32)

        guidance_window = self.hsv_analysis['coastline_guidance'][y_start:y_end, x_start:x_end]
        hsv_state[0, :actual_h, :actual_w] = guidance_window

        transition_window = self.hsv_analysis['transition_strength'][y_start:y_end, x_start:x_end]
        hsv_state[1, :actual_h, :actual_w] = transition_window

        water_window = self.hsv_analysis['water_mask'][y_start:y_end, x_start:x_end].astype(float)
        hsv_state[2, :actual_h, :actual_w] = water_window

        rgb_tensor = torch.FloatTensor(rgb_state).unsqueeze(0).to(device)
        hsv_tensor = torch.FloatTensor(hsv_state).unsqueeze(0).to(device)

        return rgb_tensor, hsv_tensor

    def get_enhanced_features(self, position):
        """è·å–å¢å¼ºç‰¹å¾"""
        y, x = position

        if not (0 <= y < self.height and 0 <= x < self.width):
            return torch.zeros(25, dtype=torch.float32, device=device).unsqueeze(0)

        features = np.zeros(25, dtype=np.float32)

        features[0] = self.edge_map[y, x]
        features[1] = self.hsv_analysis['coastline_guidance'][y, x]
        features[2] = self.hsv_analysis['transition_strength'][y, x]
        features[3] = 1.0 if self.hsv_analysis['water_mask'][y, x] else 0.0
        features[4] = 1.0 if self.hsv_analysis['land_mask'][y, x] else 0.0

        y_start, y_end = max(0, y - 3), min(self.height, y + 4)
        x_start, x_end = max(0, x - 3), min(self.width, x + 4)

        local_guidance = self.hsv_analysis['coastline_guidance'][y_start:y_end, x_start:x_end]
        if local_guidance.size > 0:
            features[5] = np.mean(local_guidance)
            features[6] = np.max(local_guidance)

        if self.gt_analysis:
            try:
                features[11] = 1.0 if self.gt_analysis['gt_binary'][y, x] else 0.0
                if np.any(self.gt_analysis['gt_binary']):
                    gt_coords = np.where(self.gt_analysis['gt_binary'])
                    if len(gt_coords[0]) > 0:
                        distances = np.sqrt((gt_coords[0] - y) ** 2 + (gt_coords[1] - x) ** 2)
                        min_dist = np.min(distances)
                        features[12] = min(1.0, min_dist / 20.0)
            except (IndexError, KeyError):
                pass

        curiosity_bonus = self.curiosity_explorer.get_curiosity_bonus(
            position, self.hsv_analysis, self.current_coastline
        )
        features[15] = min(1.0, curiosity_bonus / 50.0)

        features[19] = y / self.height
        features[20] = x / self.width

        middle_start = self.height // 3
        middle_end = 2 * self.height // 3

        if middle_start <= y <= middle_end:
            features[24] = 1.0
        elif y < middle_start:
            features[24] = -1.0
        else:
            features[24] = -0.5

        return torch.FloatTensor(features).unsqueeze(0).to(device)

    def step(self, position, action_idx):
        """æ‰§è¡ŒåŠ¨ä½œ"""
        allowed_actions = self.action_constraints.get_allowed_actions(
            position, self.current_coastline, self.hsv_analysis
        )

        if action_idx not in allowed_actions:
            action_idx = allowed_actions[0] if allowed_actions else 0

        y, x = position
        dy, dx = self.base_actions[action_idx]

        new_y = np.clip(y + dy, 0, self.height - 1)
        new_x = np.clip(x + dx, 0, self.width - 1)

        new_position = (new_y, new_x)
        reward = self._calculate_constrained_reward(position, new_position, action_idx)

        return new_position, reward

    def _calculate_constrained_reward(self, old_pos, new_pos, action_idx):
        """è®¡ç®—å¥–åŠ±å‡½æ•°"""
        y, x = new_pos
        reward = 0.0

        if not (0 <= y < self.height and 0 <= x < self.width):
            return -50.0

        if not self.search_region[y, x]:
            if y < self.height // 3 or y > 2 * self.height // 3:
                return -100.0
            else:
                return -30.0

        # åŒºåŸŸä½ç½®å¥–åŠ±
        height = self.height
        core_start = int(height * 0.3)
        core_end = int(height * 0.7)

        if core_start <= y <= core_end:
            reward += 25.0
        elif int(height * 0.25) <= y <= int(height * 0.75):
            reward += 10.0

        # HSVç›‘ç£å¥–åŠ±
        hsv_reward = self._calculate_hsv_reward(new_pos)
        reward += hsv_reward * 20.0

        # GTå¥–åŠ±
        if self.gt_analysis and self.gt_analysis['gt_binary'] is not None:
            gt_reward = self._calculate_gt_reward(new_pos)
            reward += gt_reward

        # æµ·é™†åˆ†ç¦»å¥–åŠ±
        sea_land_separation_reward = self._calculate_sea_land_separation_reward(new_pos)
        reward += sea_land_separation_reward

        return reward

    def _calculate_hsv_reward(self, position):
        """è®¡ç®—HSVç›‘ç£å¥–åŠ±"""
        y, x = position
        guidance_score = self.hsv_analysis['coastline_guidance'][y, x]
        transition_score = self.hsv_analysis['transition_strength'][y, x]
        return guidance_score + transition_score

    def _calculate_gt_reward(self, position):
        """è®¡ç®—GTå¥–åŠ±"""
        y, x = position
        gt_reward = 0.0

        if self.gt_analysis['gt_binary'][y, x]:
            base_gt_reward = 60.0
            if self.height // 3 <= y <= 2 * self.height // 3:
                base_gt_reward *= 1.3
            gt_reward += base_gt_reward
        else:
            gt_coords = np.where(self.gt_analysis['gt_binary'])
            if len(gt_coords[0]) > 0:
                distances = np.sqrt((gt_coords[0] - y) ** 2 + (gt_coords[1] - x) ** 2)
                min_dist = np.min(distances)

                if min_dist <= 2:
                    proximity_reward = 40.0 - min_dist * 10.0
                    if self.height // 3 <= y <= 2 * self.height // 3:
                        proximity_reward *= 1.2
                    gt_reward += proximity_reward

        return gt_reward

    def _calculate_sea_land_separation_reward(self, position):
        """è®¡ç®—æµ·é™†åˆ†ç¦»å¥–åŠ±"""
        y, x = position

        water_mask = self.hsv_analysis['water_mask']
        land_mask = self.hsv_analysis['land_mask']

        water_neighbors = 0
        land_neighbors = 0
        total_neighbors = 0

        for dy in range(-2, 3):
            for dx in range(-2, 3):
                if dy == 0 and dx == 0:
                    continue
                ny, nx = y + dy, x + dx
                if 0 <= ny < self.height and 0 <= nx < self.width:
                    total_neighbors += 1
                    if water_mask[ny, nx]:
                        water_neighbors += 1
                    if land_mask[ny, nx]:
                        land_neighbors += 1

        if total_neighbors == 0:
            return 0.0

        water_ratio = water_neighbors / total_neighbors
        land_ratio = land_neighbors / total_neighbors

        if water_ratio > 0.2 and land_ratio > 0.2:
            separation_reward = 30.0 * min(water_ratio, land_ratio) * 2
        elif water_ratio > 0.1 or land_ratio > 0.1:
            separation_reward = 15.0 * (water_ratio + land_ratio)
        else:
            separation_reward = -5.0

        return separation_reward

    def update_coastline(self, position, value=1.0):
        """æ›´æ–°æµ·å²¸çº¿"""
        y, x = position
        if 0 <= y < self.height and 0 <= x < self.width:
            self.current_coastline[y, x] = min(1.0, self.current_coastline[y, x] + value)


# ==================== å¢å¼ºçš„çº¦æŸä»£ç†ï¼ˆæ·»åŠ è®­ç»ƒç›‘æ§ï¼‰====================

class ConstrainedCoastlineAgent:
    """çº¦æŸçš„æµ·å²¸çº¿ä»£ç† - å¢å¼ºç‰ˆ"""

    def __init__(self, env, lr=1e-4, gamma=0.98, epsilon_start=0.9, epsilon_end=0.1, epsilon_decay=0.995):
        self.env = env
        self.device = device

        self.lr = lr
        self.gamma = gamma
        self.epsilon = epsilon_start
        self.epsilon_end = epsilon_end
        self.epsilon_decay = epsilon_decay

        self.policy_net = ConstrainedCoastlineDQN().to(device)
        self.target_net = ConstrainedCoastlineDQN().to(device)
        self.target_net.load_state_dict(self.policy_net.state_dict())
        self.target_net.eval()

        self.optimizer = optim.Adam(self.policy_net.parameters(), lr=lr, weight_decay=1e-4)
        self.memory = deque(maxlen=15000)

        self.batch_size = 32
        self.target_update_freq = 100
        self.train_freq = 4
        self.steps_done = 0

        # æ·»åŠ è®­ç»ƒç›‘æ§å™¨
        self.training_monitor = TrainingMonitor()

        print(f"âœ… çº¦æŸDQNä»£ç†åˆå§‹åŒ–å®Œæˆï¼ˆå¢å¼ºç‰ˆï¼‰")

    def select_action(self, rgb_state, hsv_state, position, enhanced_features, training=True):
        """é€‰æ‹©åŠ¨ä½œ"""
        allowed_actions = self.env.action_constraints.get_allowed_actions(
            position, self.env.current_coastline, self.env.hsv_analysis
        )

        if training and random.random() < self.epsilon:
            return random.choice(allowed_actions)
        else:
            with torch.no_grad():
                position_tensor = torch.LongTensor([position]).to(device)
                q_values = self.policy_net(rgb_state, hsv_state, position_tensor, enhanced_features)

                masked_q_values = q_values.clone()
                for i in range(self.env.action_dim):
                    if i not in allowed_actions:
                        masked_q_values[0, i] = float('-inf')

                return masked_q_values.argmax(dim=1).item()

    def train_step(self):
        """è®­ç»ƒæ­¥éª¤"""
        if len(self.memory) < self.batch_size:
            return None

        batch = random.sample(self.memory, self.batch_size)

        rgb_states = torch.cat([item[0][0] for item in batch])
        hsv_states = torch.cat([item[0][1] for item in batch])
        positions = torch.LongTensor([item[0][2] for item in batch]).to(device)
        enhanced_features = torch.cat([item[0][3] for item in batch])

        actions = torch.LongTensor([item[1] for item in batch]).to(device)
        rewards = torch.FloatTensor([item[3] for item in batch]).to(device)

        current_q_values = self.policy_net(rgb_states, hsv_states, positions, enhanced_features).gather(1,
                                                                                                        actions.unsqueeze(
                                                                                                            1))

        next_state_values = torch.zeros(self.batch_size).to(device)
        non_final_mask = torch.tensor([item[2] is not None for item in batch], dtype=torch.bool).to(device)

        if non_final_mask.any():
            non_final_next_rgb = torch.cat([item[2][0] for item in batch if item[2] is not None])
            non_final_next_hsv = torch.cat([item[2][1] for item in batch if item[2] is not None])
            non_final_next_pos = torch.LongTensor([item[2][2] for item in batch if item[2] is not None]).to(device)
            non_final_next_feat = torch.cat([item[2][3] for item in batch if item[2] is not None])

            with torch.no_grad():
                next_state_values[non_final_mask] = self.target_net(
                    non_final_next_rgb, non_final_next_hsv, non_final_next_pos, non_final_next_feat
                ).max(1)[0]

        target_q_values = rewards + (self.gamma * next_state_values)
        loss = F.smooth_l1_loss(current_q_values.squeeze(), target_q_values)

        self.optimizer.zero_grad()
        loss.backward()
        torch.nn.utils.clip_grad_norm_(self.policy_net.parameters(), 1.0)
        self.optimizer.step()

        return loss.item()

    def optimize_constrained_coastline(self, max_episodes=200, max_steps_per_episode=400):
        """ä¼˜åŒ–æµ·å²¸çº¿æ£€æµ‹ - å¢å¼ºç‰ˆ"""
        print("ğŸ¯ çº¦æŸæµ·å²¸çº¿ä¼˜åŒ–å¼€å§‹ï¼ˆå¢å¼ºç‰ˆï¼‰...")

        # å¼€å§‹è®­ç»ƒè®¡æ—¶
        self.training_monitor.start_training()

        search_positions = np.where(self.env.search_region)
        candidate_positions = list(zip(search_positions[0], search_positions[1]))

        if not candidate_positions:
            print("   âš ï¸ æœªæ‰¾åˆ°æœç´¢åŒºåŸŸ")
            return self.env.current_coastline

        height = self.env.height
        middle_start = height // 3
        middle_end = 2 * height // 3

        middle_third_starts = [pos for pos in candidate_positions if middle_start <= pos[0] <= middle_end]

        if not middle_third_starts:
            middle_third_starts = candidate_positions[:50]

        episode_rewards = []
        total_improvements = 0

        for episode in range(max_episodes):

            if episode < max_episodes // 2:
                if random.random() < 0.8 and middle_third_starts:
                    start_position = random.choice(middle_third_starts)
                else:
                    start_position = random.choice(candidate_positions[:50])
            else:
                if self.env.gt_analysis and random.random() < 0.9:
                    gt_positions = np.where(self.env.gt_analysis['gt_binary'])
                    if len(gt_positions[0]) > 0:
                        valid_gt_positions = [(gt_positions[0][i], gt_positions[1][i])
                                              for i in range(len(gt_positions[0]))
                                              if middle_start <= gt_positions[0][i] <= middle_end]
                        if valid_gt_positions:
                            start_position = random.choice(valid_gt_positions)
                        else:
                            start_position = random.choice(middle_third_starts)
                    else:
                        start_position = random.choice(middle_third_starts)
                else:
                    start_position = random.choice(middle_third_starts)

            current_position = start_position
            episode_reward = 0
            episode_improvements = 0

            for step in range(max_steps_per_episode):
                rgb_state, hsv_state = self.env.get_state_tensor(current_position)
                enhanced_features = self.env.get_enhanced_features(current_position)

                action = self.select_action(rgb_state, hsv_state, current_position,
                                            enhanced_features, training=True)

                next_position, reward = self.env.step(current_position, action)
                episode_reward += reward

                next_rgb_state, next_hsv_state = self.env.get_state_tensor(next_position)
                next_enhanced_features = self.env.get_enhanced_features(next_position)

                current_state = (rgb_state, hsv_state, current_position, enhanced_features)
                next_state = (next_rgb_state, next_hsv_state, next_position,
                              next_enhanced_features) if reward > -50 else None

                self.memory.append((current_state, action, next_state, reward))

                y_pos = next_position[0]
                is_middle_region = middle_start <= y_pos <= middle_end

                if episode < max_episodes * 0.3:
                    if reward > 15.0:
                        update_value = 0.8 if is_middle_region else 0.6
                        self.env.update_coastline(next_position, update_value)
                        episode_improvements += 1
                        total_improvements += 1
                elif episode < max_episodes * 0.7:
                    if reward > 10.0:
                        update_value = 0.7 if is_middle_region else 0.5
                        self.env.update_coastline(next_position, update_value)
                        episode_improvements += 1
                        total_improvements += 1
                else:
                    if reward > 8.0:
                        update_value = 0.6 if is_middle_region else 0.4
                        self.env.update_coastline(next_position, update_value)
                        episode_improvements += 1
                        total_improvements += 1
                    elif reward > 3.0:
                        update_value = 0.3 if is_middle_region else 0.2
                        self.env.update_coastline(next_position, update_value)
                        episode_improvements += 1

                if self.steps_done % self.train_freq == 0:
                    loss = self.train_step()
                else:
                    loss = None

                if self.steps_done % self.target_update_freq == 0:
                    self.update_target_network()

                self.steps_done += 1
                current_position = next_position

                if reward < -80:
                    break

            episode_rewards.append(episode_reward)
            self.decay_epsilon()

            # è®¡ç®—å½“å‰çŠ¶æ€çš„æŒ‡æ ‡
            current_pixels = np.sum(self.env.current_coastline > 0.3)
            middle_region_pixels = np.sum(self.env.current_coastline[middle_start:middle_end, :] > 0.3)
            connectivity_score = middle_region_pixels / max(1, current_pixels)

            # è®°å½•è®­ç»ƒæ•°æ®
            self.training_monitor.log_episode(
                episode=episode,
                loss=loss,
                reward=episode_reward,
                pixel_count=current_pixels,
                connectivity_score=connectivity_score
            )

            if episode % 20 == 0:
                avg_reward = np.mean(episode_rewards[-20:])
                middle_ratio = connectivity_score

                print(f"   Episode {episode:3d}: å¥–åŠ±={avg_reward:6.2f}, Îµ={self.epsilon:.3f}, "
                      f"åƒç´ ={current_pixels:,}, ä¸­é—´æ¯”ä¾‹={middle_ratio:.1%}")

        final_pixels = np.sum(self.env.current_coastline > 0.3)
        print(f"   âœ… ä¼˜åŒ–å®Œæˆ: æ€»åƒç´ ={final_pixels:,}, æ”¹è¿›æ¬¡æ•°={total_improvements}")

        return self.env.current_coastline

    def update_target_network(self):
        """æ›´æ–°ç›®æ ‡ç½‘ç»œ"""
        self.target_net.load_state_dict(self.policy_net.state_dict())

    def decay_epsilon(self):
        """è¡°å‡æ¢ç´¢ç‡"""
        self.epsilon = max(self.epsilon_end, self.epsilon * self.epsilon_decay)


# ==================== å…¶ä½™ç±»ä¿æŒä¸å˜ï¼ˆæµ·åŸŸåˆ†æå™¨ã€è¿é€šæ€§é˜²æŠ¤å™¨ç­‰ï¼‰====================

class PreciseSeaAreaAnalyzer:
    """ç²¾å‡†æµ·åŸŸåˆ†æå™¨ - ä¸“é—¨è¯†åˆ«å’Œæ¸…ç†æµ·åŸŸè¯¯æ£€"""

    def __init__(self):
        print("âœ… ç²¾å‡†æµ·åŸŸåˆ†æå™¨åˆå§‹åŒ–å®Œæˆ")
        self.sea_features = self._define_enhanced_sea_features()

    def _define_enhanced_sea_features(self):
        """å®šä¹‰å¢å¼ºçš„æµ·åŸŸç‰¹å¾"""
        return {
            'deep_blue_range': {
                'hue_range': (200, 250),  # æ·±è“è‰²èŒƒå›´
                'saturation_min': 0.3,
                'value_range': (0.1, 0.6)  # è¾ƒæš—çš„å€¼
            },
            'dark_water_range': {
                'value_max': 0.4,  # éå¸¸æš—çš„åŒºåŸŸ
                'saturation_min': 0.2
            },
            'uniform_water_variance': 0.05  # æ°´åŸŸçš„é¢œè‰²å˜åŒ–é€šå¸¸å¾ˆå°
        }

    def analyze_sea_areas(self, rgb_image, current_coastline, gt_analysis=None):
        """åˆ†ææµ·åŸŸåŒºåŸŸ"""
        print("ğŸ” ç²¾å‡†æµ·åŸŸåˆ†æ...")

        # è½¬æ¢ä¸ºHSV
        if len(rgb_image.shape) == 3:
            rgb_normalized = rgb_image.astype(float) / 255.0
            hsv_image = np.zeros_like(rgb_normalized)

            for i in range(rgb_image.shape[0]):
                for j in range(rgb_image.shape[1]):
                    r, g, b = rgb_normalized[i, j]
                    h, s, v = colorsys.rgb_to_hsv(r, g, b)
                    hsv_image[i, j] = [h * 360, s, v]
        else:
            hsv_image = np.stack([np.zeros_like(rgb_image),
                                  np.zeros_like(rgb_image),
                                  rgb_image / 255.0], axis=2)

        # 1. è¯†åˆ«æ·±æµ·åŒºåŸŸ
        deep_sea_mask = self._identify_deep_sea_areas(hsv_image)

        # 2. è¯†åˆ«æš—æ°´åŒºåŸŸ
        dark_water_mask = self._identify_dark_water_areas(hsv_image)

        # 3. è¯†åˆ«å‡åŒ€æ°´åŸŸ
        uniform_water_mask = self._identify_uniform_water_areas(rgb_image)

        # 4. ç»¼åˆæµ·åŸŸæ©ç 
        comprehensive_sea_mask = deep_sea_mask | dark_water_mask | uniform_water_mask

        # 5. å½¢æ€å­¦ä¼˜åŒ–
        comprehensive_sea_mask = self._morphological_sea_cleanup(comprehensive_sea_mask)

        # 6. åˆ†ææµ·å²¸çº¿åœ¨æµ·åŸŸä¸­çš„åˆ†å¸ƒ
        sea_intrusion_analysis = self._analyze_sea_intrusion(current_coastline, comprehensive_sea_mask, gt_analysis)

        return {
            'deep_sea_mask': deep_sea_mask,
            'dark_water_mask': dark_water_mask,
            'uniform_water_mask': uniform_water_mask,
            'comprehensive_sea_mask': comprehensive_sea_mask,
            'sea_intrusion_analysis': sea_intrusion_analysis
        }

    def _identify_deep_sea_areas(self, hsv_image):
        """è¯†åˆ«æ·±æµ·åŒºåŸŸ"""
        h, s, v = hsv_image[:, :, 0], hsv_image[:, :, 1], hsv_image[:, :, 2]

        features = self.sea_features['deep_blue_range']

        hue_mask = ((h >= features['hue_range'][0]) & (h <= features['hue_range'][1]))
        saturation_mask = s >= features['saturation_min']
        value_mask = ((v >= features['value_range'][0]) & (v <= features['value_range'][1]))

        deep_sea = hue_mask & saturation_mask & value_mask

        # å½¢æ€å­¦å¤„ç†
        deep_sea = binary_closing(deep_sea, np.ones((7, 7)))
        deep_sea = binary_erosion(deep_sea, np.ones((3, 3)))
        deep_sea = binary_dilation(deep_sea, np.ones((5, 5)))

        return deep_sea

    def _identify_dark_water_areas(self, hsv_image):
        """è¯†åˆ«æš—æ°´åŒºåŸŸ"""
        s, v = hsv_image[:, :, 1], hsv_image[:, :, 2]

        features = self.sea_features['dark_water_range']

        dark_mask = v <= features['value_max']
        saturation_mask = s >= features['saturation_min']

        dark_water = dark_mask & saturation_mask

        # å»é™¤å°å™ªå£°
        dark_water = binary_closing(dark_water, np.ones((5, 5)))
        dark_water = self._remove_small_components(dark_water, min_size=50)

        return dark_water

    def _identify_uniform_water_areas(self, rgb_image):
        """è¯†åˆ«å‡åŒ€æ°´åŸŸ - åŸºäºé¢œè‰²ä¸€è‡´æ€§"""
        if len(rgb_image.shape) == 3:
            gray = np.dot(rgb_image[..., :3], [0.2989, 0.5870, 0.1140])
        else:
            gray = rgb_image.copy()

        # è®¡ç®—å±€éƒ¨æ–¹å·®
        from scipy.ndimage import uniform_filter

        local_mean = uniform_filter(gray.astype(float), size=9)
        local_variance = uniform_filter((gray.astype(float) - local_mean) ** 2, size=9)

        # ä½æ–¹å·®åŒºåŸŸ + ä½äº®åº¦ = å‡åŒ€æ°´åŸŸ
        uniform_mask = (local_variance < self.sea_features['uniform_water_variance'] * 255 ** 2)
        dark_mask = gray < 120  # ç›¸å¯¹è¾ƒæš—

        uniform_water = uniform_mask & dark_mask

        # å½¢æ€å­¦æ¸…ç†
        uniform_water = binary_closing(uniform_water, np.ones((7, 7)))
        uniform_water = self._remove_small_components(uniform_water, min_size=100)

        return uniform_water

    def _morphological_sea_cleanup(self, sea_mask):
        """æµ·åŸŸæ©ç çš„å½¢æ€å­¦æ¸…ç†"""
        # å…ˆé—­è¿ç®—å¡«è¡¥å°æ´
        cleaned = binary_closing(sea_mask, np.ones((9, 9)))

        # å»é™¤å°ç¢ç‰‡
        cleaned = self._remove_small_components(cleaned, min_size=200)

        # è½»å¾®è†¨èƒ€ä»¥ç¡®ä¿è¦†ç›–è¾¹ç•Œ
        cleaned = binary_dilation(cleaned, np.ones((3, 3)))

        return cleaned

    def _analyze_sea_intrusion(self, coastline, sea_mask, gt_analysis):
        """åˆ†ææµ·å²¸çº¿åœ¨æµ·åŸŸä¸­çš„åˆ†å¸ƒ"""
        coastline_binary = (coastline > 0.5).astype(bool)

        # æµ·å²¸çº¿åœ¨æµ·åŸŸä¸­çš„åƒç´ 
        sea_intrusion = coastline_binary & sea_mask
        intrusion_count = np.sum(sea_intrusion)

        # è®¡ç®—å…¥ä¾µä¸¥é‡ç¨‹åº¦
        total_coastline = np.sum(coastline_binary)
        intrusion_ratio = intrusion_count / max(1, total_coastline)

        # åˆ†æå…¥ä¾µçš„ç©ºé—´åˆ†å¸ƒ
        intrusion_clusters = self._analyze_intrusion_clusters(sea_intrusion)

        # GTä¿æŠ¤åŒºåŸŸåˆ†æ
        gt_protected_intrusion = 0
        if gt_analysis and gt_analysis['gt_binary'] is not None:
            gt_binary = gt_analysis['gt_binary']
            gt_protection_area = binary_dilation(gt_binary, np.ones((10, 10)))
            gt_protected_intrusion = np.sum(sea_intrusion & gt_protection_area)

        return {
            'intrusion_mask': sea_intrusion,
            'intrusion_count': intrusion_count,
            'intrusion_ratio': intrusion_ratio,
            'intrusion_clusters': intrusion_clusters,
            'gt_protected_intrusion': gt_protected_intrusion,
            'removable_intrusion': intrusion_count - gt_protected_intrusion
        }

    def _analyze_intrusion_clusters(self, intrusion_mask):
        """åˆ†æå…¥ä¾µé›†ç¾¤"""
        labeled_intrusion, num_clusters = label(intrusion_mask)

        clusters = []
        for i in range(1, num_clusters + 1):
            cluster_mask = (labeled_intrusion == i)
            cluster_size = np.sum(cluster_mask)

            # è®¡ç®—é›†ç¾¤çš„ç´§å¯†åº¦
            cluster_coords = np.where(cluster_mask)
            if len(cluster_coords[0]) > 1:
                y_coords, x_coords = cluster_coords[0], cluster_coords[1]
                y_span = np.max(y_coords) - np.min(y_coords) + 1
                x_span = np.max(x_coords) - np.min(x_coords) + 1
                compactness = cluster_size / (y_span * x_span)
            else:
                compactness = 1.0

            clusters.append({
                'id': i,
                'size': cluster_size,
                'compactness': compactness,
                'bbox': (np.min(cluster_coords[0]), np.min(cluster_coords[1]),
                         np.max(cluster_coords[0]), np.max(cluster_coords[1]))
            })

        return clusters

    def _remove_small_components(self, binary_image, min_size=50):
        """ç§»é™¤å°ç»„ä»¶"""
        labeled_array, num_components = label(binary_image)

        result = binary_image.copy()
        for i in range(1, num_components + 1):
            size = np.sum(labeled_array == i)
            if size < min_size:
                result[labeled_array == i] = False

        return result


class ConnectivityGuard:
    """è¿é€šæ€§é˜²æŠ¤å™¨ - é˜²æ­¢ä¸Šä¸‹å²¸çº¿é”™è¯¯è¿é€š"""

    def __init__(self):
        print("âœ… è¿é€šæ€§é˜²æŠ¤å™¨åˆå§‹åŒ–å®Œæˆ")

    def analyze_connectivity_risks(self, coastline, image_shape):
        """åˆ†æè¿é€šæ€§é£é™©"""
        print("ğŸ›¡ï¸ åˆ†æè¿é€šæ€§é£é™©...")

        height, width = image_shape[:2]
        coastline_binary = (coastline > 0.5).astype(bool)

        # åˆ†æå‚ç›´è¿é€šæ€§é£é™©
        vertical_risks = self._analyze_vertical_connectivity(coastline_binary, height, width)

        # åˆ†ææ°´å¹³åˆ†å‰²æƒ…å†µ
        horizontal_analysis = self._analyze_horizontal_separation(coastline_binary, height, width)

        # è¯†åˆ«å±é™©è¿æ¥åŒºåŸŸ
        dangerous_connections = self._identify_dangerous_connections(coastline_binary, vertical_risks)

        return {
            'vertical_risks': vertical_risks,
            'horizontal_analysis': horizontal_analysis,
            'dangerous_connections': dangerous_connections
        }

    def _analyze_vertical_connectivity(self, coastline_binary, height, width):
        """åˆ†æå‚ç›´è¿é€šæ€§"""
        risks = []

        # æ£€æŸ¥æ¯ä¸€åˆ—çš„è¿é€šæƒ…å†µ
        for x in range(width):
            column = coastline_binary[:, x]
            if np.sum(column) == 0:
                continue

            # æ‰¾åˆ°è¿ç»­åŒºé—´
            connected_regions = self._find_connected_regions(column)

            # åˆ†æå±é™©çš„é•¿è¿æ¥
            for region in connected_regions:
                start, end = region
                length = end - start + 1
                coverage = length / height

                # å¦‚æœæŸåˆ—çš„è¿æ¥è¦†ç›–è¶…è¿‡60%çš„é«˜åº¦ï¼Œæ ‡è®°ä¸ºé£é™©
                if coverage > 0.6:
                    risks.append({
                        'column': x,
                        'start': start,
                        'end': end,
                        'length': length,
                        'coverage': coverage,
                        'risk_level': 'high' if coverage > 0.8 else 'medium'
                    })

        return risks

    def _find_connected_regions(self, binary_column):
        """æ‰¾åˆ°äºŒè¿›åˆ¶åˆ—ä¸­çš„è¿ç»­åŒºåŸŸ"""
        regions = []
        start = None

        for i, value in enumerate(binary_column):
            if value and start is None:
                start = i
            elif not value and start is not None:
                regions.append((start, i - 1))
                start = None

        # å¤„ç†åˆ—æœ«å°¾çš„æƒ…å†µ
        if start is not None:
            regions.append((start, len(binary_column) - 1))

        return regions

    def _analyze_horizontal_separation(self, coastline_binary, height, width):
        """åˆ†ææ°´å¹³åˆ†å‰²æƒ…å†µ"""
        # å°†å›¾åƒåˆ†ä¸ºä¸Šã€ä¸­ã€ä¸‹ä¸‰éƒ¨åˆ†
        third_height = height // 3

        upper_region = coastline_binary[:third_height, :]
        middle_region = coastline_binary[third_height:2 * third_height, :]
        lower_region = coastline_binary[2 * third_height:, :]

        upper_pixels = np.sum(upper_region)
        middle_pixels = np.sum(middle_region)
        lower_pixels = np.sum(lower_region)
        total_pixels = upper_pixels + middle_pixels + lower_pixels

        if total_pixels == 0:
            return {
                'upper_ratio': 0, 'middle_ratio': 0, 'lower_ratio': 0,
                'separation_quality': 'no_coastline'
            }

        upper_ratio = upper_pixels / total_pixels
        middle_ratio = middle_pixels / total_pixels
        lower_ratio = lower_pixels / total_pixels

        # è¯„ä¼°åˆ†ç¦»è´¨é‡
        if middle_ratio > 0.7:
            separation_quality = 'excellent'  # ä¸»è¦é›†ä¸­åœ¨ä¸­é—´
        elif middle_ratio > 0.5:
            separation_quality = 'good'
        elif upper_ratio > 0.4 and lower_ratio > 0.4:
            separation_quality = 'poor'  # ä¸Šä¸‹éƒ½æœ‰å¾ˆå¤šï¼Œå¯èƒ½è¿é€šäº†
        else:
            separation_quality = 'fair'

        return {
            'upper_ratio': upper_ratio,
            'middle_ratio': middle_ratio,
            'lower_ratio': lower_ratio,
            'separation_quality': separation_quality
        }

    def _identify_dangerous_connections(self, coastline_binary, vertical_risks):
        """è¯†åˆ«å±é™©è¿æ¥åŒºåŸŸ"""
        dangerous_areas = np.zeros_like(coastline_binary, dtype=bool)

        for risk in vertical_risks:
            if risk['risk_level'] == 'high':
                x = risk['column']
                start = max(0, risk['start'])
                end = min(coastline_binary.shape[0] - 1, risk['end'])

                # æ ‡è®°æ•´ä¸ªå±é™©è¿æ¥åŒºåŸŸ
                dangerous_areas[start:end + 1, x] = True

                # å‘ä¸¤ä¾§æ‰©å±•ä¸€ç‚¹
                for dx in [-1, 1]:
                    nx = x + dx
                    if 0 <= nx < coastline_binary.shape[1]:
                        dangerous_areas[start:end + 1, nx] = True

        return dangerous_areas


class PreciseSeaCleanupPostProcessor:
    """ç²¾å‡†æµ·åŸŸæ¸…ç†åå¤„ç†å™¨"""

    def __init__(self, target_pixel_range=(90000, 100000)):
        self.sea_analyzer = PreciseSeaAreaAnalyzer()
        self.connectivity_guard = ConnectivityGuard()
        self.target_pixel_range = target_pixel_range
        print(f"âœ… ç²¾å‡†æµ·åŸŸæ¸…ç†åå¤„ç†å™¨åˆå§‹åŒ–å®Œæˆ")
        print(f"   ğŸ¯ ç›®æ ‡åƒç´ èŒƒå›´: {target_pixel_range[0]:,} - {target_pixel_range[1]:,}")

    def process_precise_sea_cleanup(self, coastline, hsv_analysis, gt_analysis, rgb_image):
        """ç²¾å‡†æµ·åŸŸæ¸…ç†å¤„ç†"""
        print("ğŸ”§ å¼€å§‹ç²¾å‡†æµ·åŸŸæ¸…ç†åå¤„ç†...")
        print(f"   è¾“å…¥æµ·å²¸çº¿åƒç´ : {np.sum(coastline > 0.3):,}")

        # ç¬¬ä¸€æ­¥ï¼šæµ·åŸŸåˆ†æ
        sea_analysis = self.sea_analyzer.analyze_sea_areas(rgb_image, coastline, gt_analysis)

        # ç¬¬äºŒæ­¥ï¼šè¿é€šæ€§é£é™©åˆ†æ
        connectivity_analysis = self.connectivity_guard.analyze_connectivity_risks(coastline, rgb_image.shape)

        # ç¬¬ä¸‰æ­¥ï¼šåˆæ­¥äºŒå€¼åŒ–
        binary_coastline = self._smart_binarization(coastline, hsv_analysis)
        print(f"   åˆæ­¥äºŒå€¼åŒ–å: {np.sum(binary_coastline):,} åƒç´ ")

        # ç¬¬å››æ­¥ï¼šæµ·åŸŸæ¸…ç†
        sea_cleaned_coastline = self._aggressive_sea_cleanup(binary_coastline, sea_analysis, gt_analysis)
        print(f"   æµ·åŸŸæ¸…ç†å: {np.sum(sea_cleaned_coastline):,} åƒç´ ")

        # ç¬¬äº”æ­¥ï¼šè¿é€šæ€§ä¿®å¤
        connectivity_fixed = self._fix_dangerous_connectivity(sea_cleaned_coastline, connectivity_analysis, gt_analysis)
        print(f"   è¿é€šæ€§ä¿®å¤å: {np.sum(connectivity_fixed):,} åƒç´ ")

        # ç¬¬å…­æ­¥ï¼šåƒç´ æ•°é‡æ§åˆ¶
        pixel_controlled = self._control_pixel_count(connectivity_fixed, gt_analysis, sea_analysis)
        print(f"   åƒç´ æ§åˆ¶å: {np.sum(pixel_controlled):,} åƒç´ ")

        # ç¬¬ä¸ƒæ­¥ï¼šæœ€ç»ˆGTä¿æŠ¤
        final_coastline = self._final_gt_protection(pixel_controlled, gt_analysis)
        print(f"   æœ€ç»ˆGTä¿æŠ¤å: {np.sum(final_coastline):,} åƒç´ ")

        return final_coastline.astype(float)

    def _smart_binarization(self, coastline, hsv_analysis):
        """æ™ºèƒ½äºŒå€¼åŒ–"""
        guidance_weight = hsv_analysis['coastline_guidance']
        transition_weight = hsv_analysis['transition_strength']

        # æ›´ä¿å®ˆçš„åŠ æƒç­–ç•¥
        weighted_coastline = coastline * (0.6 + guidance_weight * 0.2 + transition_weight * 0.2)

        # æé«˜é˜ˆå€¼
        valid_mask = weighted_coastline > 0
        if np.any(valid_mask):
            threshold = np.percentile(weighted_coastline[valid_mask], 70)  # æé«˜åˆ°70
        else:
            threshold = 0.35  # æé«˜åŸºç¡€é˜ˆå€¼

        binary_result = weighted_coastline > threshold

        # ç§»é™¤å°ç»„ä»¶
        binary_result = self._remove_small_components(binary_result, min_size=10)

        return binary_result

    def _aggressive_sea_cleanup(self, binary_coastline, sea_analysis, gt_analysis):
        """æ¿€è¿›çš„æµ·åŸŸæ¸…ç†"""
        result = binary_coastline.copy()

        # GTä¿æŠ¤æ©ç 
        gt_protection_mask = np.zeros_like(binary_coastline, dtype=bool)
        if gt_analysis and gt_analysis['gt_binary'] is not None:
            gt_binary = gt_analysis['gt_binary']
            gt_protection_mask = binary_dilation(gt_binary, np.ones((8, 8)))

        # è·å–æµ·åŸŸæ©ç 
        sea_mask = sea_analysis['comprehensive_sea_mask']

        # åœ¨æµ·åŸŸä¸­çš„æµ·å²¸çº¿åƒç´ 
        sea_coastline_pixels = binary_coastline & sea_mask

        # åˆ†ç¦»å—ä¿æŠ¤å’Œä¸å—ä¿æŠ¤çš„æµ·åŸŸåƒç´ 
        protected_sea_pixels = sea_coastline_pixels & gt_protection_mask
        unprotected_sea_pixels = sea_coastline_pixels & ~gt_protection_mask

        print(f"     æµ·åŸŸåƒç´ æ€»æ•°: {np.sum(sea_coastline_pixels):,}")
        print(f"     å—GTä¿æŠ¤: {np.sum(protected_sea_pixels):,}")
        print(f"     å¯æ¸…ç†çš„: {np.sum(unprotected_sea_pixels):,}")

        # åˆ†ææµ·åŸŸåƒç´ çš„æ¸…ç†ä»·å€¼
        cleanable_pixels = self._identify_cleanable_sea_pixels(unprotected_sea_pixels, binary_coastline, gt_analysis)

        # æ‰§è¡Œæ¸…ç†
        result = result & ~cleanable_pixels

        removed_count = np.sum(cleanable_pixels)
        print(f"     å®é™…æ¸…ç†: {removed_count:,} æµ·åŸŸåƒç´ ")

        return result

    def _identify_cleanable_sea_pixels(self, unprotected_sea_pixels, binary_coastline, gt_analysis):
        """è¯†åˆ«å¯æ¸…ç†çš„æµ·åŸŸåƒç´ """
        cleanable = np.zeros_like(unprotected_sea_pixels, dtype=bool)

        if not np.any(unprotected_sea_pixels):
            return cleanable

        # è·å–å€™é€‰åƒç´ ä½ç½®
        sea_positions = np.where(unprotected_sea_pixels)

        for i in range(len(sea_positions[0])):
            y, x = sea_positions[0][i], sea_positions[1][i]

            # åˆ†æè¯¥åƒç´ çš„æ¸…ç†ä»·å€¼
            cleanup_score = self._calculate_cleanup_value(y, x, binary_coastline, gt_analysis)

            # å¦‚æœæ¸…ç†ä»·å€¼é«˜ï¼Œæ ‡è®°ä¸ºå¯æ¸…ç†
            if cleanup_score > 0.3:  # é™ä½é˜ˆå€¼ï¼Œæ›´æ¿€è¿›æ¸…ç†
                cleanable[y, x] = True

        return cleanable

    def _calculate_cleanup_value(self, y, x, binary_coastline, gt_analysis):
        """è®¡ç®—åƒç´ çš„æ¸…ç†ä»·å€¼"""
        height, width = binary_coastline.shape

        # æ£€æŸ¥å‘¨å›´çš„æµ·å²¸çº¿å¯†åº¦
        neighbor_coastline = 0
        total_neighbors = 0

        for dy in range(-3, 4):
            for dx in range(-3, 4):
                ny, nx = y + dy, x + dx
                if 0 <= ny < height and 0 <= nx < width:
                    total_neighbors += 1
                    if binary_coastline[ny, nx]:
                        neighbor_coastline += 1

        neighbor_density = neighbor_coastline / max(1, total_neighbors)

        # å¦‚æœå‘¨å›´æµ·å²¸çº¿å¯†åº¦å¾ˆä½ï¼Œæ¸…ç†ä»·å€¼é«˜
        low_density_score = 1.0 - neighbor_density

        # æ£€æŸ¥æ˜¯å¦åœ¨å›¾åƒè¾¹ç¼˜é™„è¿‘ï¼ˆè¾¹ç¼˜è¯¯æ£€å¯èƒ½æ€§é«˜ï¼‰
        edge_distance = min(y, x, height - 1 - y, width - 1 - x)
        edge_score = 1.0 if edge_distance < 10 else 0.0

        # æ£€æŸ¥æ˜¯å¦åœ¨GTè¿œç¦»åŒºåŸŸ
        gt_distance_score = 0.0
        if gt_analysis and gt_analysis['gt_binary'] is not None:
            gt_binary = gt_analysis['gt_binary']
            if np.any(gt_binary):
                gt_coords = np.where(gt_binary)
                distances = np.sqrt((gt_coords[0] - y) ** 2 + (gt_coords[1] - x) ** 2)
                min_gt_distance = np.min(distances)
                gt_distance_score = min(1.0, min_gt_distance / 20.0)  # è·ç¦»GTè¶Šè¿œï¼Œæ¸…ç†ä»·å€¼è¶Šé«˜

        # ç»¼åˆè¯„åˆ†
        cleanup_value = (low_density_score * 0.4 +
                         edge_score * 0.2 +
                         gt_distance_score * 0.4)

        return cleanup_value

    def _fix_dangerous_connectivity(self, binary_coastline, connectivity_analysis, gt_analysis):
        """ä¿®å¤å±é™©è¿é€š"""
        result = binary_coastline.copy()

        dangerous_connections = connectivity_analysis['dangerous_connections']
        vertical_risks = connectivity_analysis['vertical_risks']

        if not np.any(dangerous_connections):
            return result

        print(f"     ä¿®å¤ {len(vertical_risks)} ä¸ªå±é™©è¿æ¥")

        # GTä¿æŠ¤
        gt_protection_mask = np.zeros_like(binary_coastline, dtype=bool)
        if gt_analysis and gt_analysis['gt_binary'] is not None:
            gt_binary = gt_analysis['gt_binary']
            gt_protection_mask = binary_dilation(gt_binary, np.ones((5, 5)))

        # å¯¹æ¯ä¸ªå±é™©è¿æ¥è¿›è¡Œå¤„ç†
        for risk in vertical_risks:
            if risk['risk_level'] == 'high':
                self._break_dangerous_connection(result, risk, gt_protection_mask)

        return result

    def _break_dangerous_connection(self, binary_coastline, risk, gt_protection_mask):
        """æ‰“æ–­å±é™©è¿æ¥"""
        x = risk['column']
        start = risk['start']
        end = risk['end']
        length = risk['length']

        # åœ¨è¿æ¥çš„ä¸­é—´éƒ¨åˆ†åˆ›å»ºé—´éš™
        gap_size = max(3, length // 8)  # é—´éš™å¤§å°
        gap_start = start + length // 2 - gap_size // 2
        gap_end = gap_start + gap_size

        # æ£€æŸ¥é—´éš™åŒºåŸŸæ˜¯å¦æœ‰GTä¿æŠ¤
        gap_region = gt_protection_mask[gap_start:gap_end + 1, x]

        # å¦‚æœé—´éš™åŒºåŸŸæ²¡æœ‰GTä¿æŠ¤ï¼Œåˆ™åˆ›å»ºé—´éš™
        if not np.any(gap_region):
            binary_coastline[gap_start:gap_end + 1, x] = False

            # å‘ä¸¤ä¾§ä¹Ÿåˆ›å»ºå°é—´éš™
            for dx in [-1, 1]:
                nx = x + dx
                if 0 <= nx < binary_coastline.shape[1]:
                    small_gap_start = gap_start + gap_size // 4
                    small_gap_end = gap_end - gap_size // 4
                    small_gap_region = gt_protection_mask[small_gap_start:small_gap_end + 1, nx]
                    if not np.any(small_gap_region):
                        binary_coastline[small_gap_start:small_gap_end + 1, nx] = False

    def _control_pixel_count(self, binary_coastline, gt_analysis, sea_analysis):
        """æ§åˆ¶åƒç´ æ•°é‡åˆ°ç›®æ ‡èŒƒå›´"""
        current_pixels = np.sum(binary_coastline)
        target_min, target_max = self.target_pixel_range

        print(f"     å½“å‰åƒç´ : {current_pixels:,}, ç›®æ ‡: {target_min:,}-{target_max:,}")

        if target_min <= current_pixels <= target_max:
            print("     åƒç´ æ•°é‡å·²åœ¨ç›®æ ‡èŒƒå›´å†…")
            return binary_coastline

        if current_pixels > target_max:
            # éœ€è¦è¿›ä¸€æ­¥å‡å°‘åƒç´ 
            pixels_to_remove = current_pixels - target_max
            return self._smart_pixel_reduction(binary_coastline, pixels_to_remove, gt_analysis, sea_analysis)
        else:
            # åƒç´ å¤ªå°‘ï¼Œéœ€è¦é€‚åº¦å¢åŠ 
            return self._smart_pixel_addition(binary_coastline, gt_analysis)

    def _smart_pixel_reduction(self, binary_coastline, pixels_to_remove, gt_analysis, sea_analysis):
        """æ™ºèƒ½åƒç´ å‡å°‘"""
        result = binary_coastline.copy()

        # GTä¿æŠ¤
        gt_protection_mask = np.zeros_like(binary_coastline, dtype=bool)
        if gt_analysis and gt_analysis['gt_binary'] is not None:
            gt_binary = gt_analysis['gt_binary']
            gt_protection_mask = binary_dilation(gt_binary, np.ones((6, 6)))

        # è·å–æ‰€æœ‰å¯ç§»é™¤çš„å€™é€‰åƒç´ 
        candidate_pixels = binary_coastline & ~gt_protection_mask
        candidate_positions = np.where(candidate_pixels)

        if len(candidate_positions[0]) == 0:
            print("     âš ï¸ æ‰€æœ‰åƒç´ éƒ½å—GTä¿æŠ¤ï¼Œæ— æ³•å‡å°‘")
            return result

        # è®¡ç®—æ¯ä¸ªå€™é€‰åƒç´ çš„ç§»é™¤ä»·å€¼
        pixel_scores = []
        for i in range(len(candidate_positions[0])):
            y, x = candidate_positions[0][i], candidate_positions[1][i]
            score = self._calculate_removal_value(y, x, binary_coastline, gt_analysis, sea_analysis)
            pixel_scores.append((score, y, x))

        # æŒ‰ç§»é™¤ä»·å€¼æ’åºï¼ˆä»·å€¼é«˜çš„ä¼˜å…ˆç§»é™¤ï¼‰
        pixel_scores.sort(reverse=True)

        # ç§»é™¤æŒ‡å®šæ•°é‡çš„åƒç´ 
        removed_count = 0
        for score, y, x in pixel_scores:
            if removed_count >= pixels_to_remove:
                break

            result[y, x] = False
            removed_count += 1

        print(f"     æ™ºèƒ½å‡å°‘: {removed_count:,} åƒç´ ")
        return result

    def _calculate_removal_value(self, y, x, binary_coastline, gt_analysis, sea_analysis):
        """è®¡ç®—åƒç´ çš„ç§»é™¤ä»·å€¼"""
        height, width = binary_coastline.shape

        removal_score = 0.0

        # 1. å­¤ç«‹åº¦è¯„åˆ†ï¼ˆå‘¨å›´æµ·å²¸çº¿è¶Šå°‘ï¼Œç§»é™¤ä»·å€¼è¶Šé«˜ï¼‰
        neighbor_count = 0
        for dy in range(-2, 3):
            for dx in range(-2, 3):
                if dy == 0 and dx == 0:
                    continue
                ny, nx = y + dy, x + dx
                if 0 <= ny < height and 0 <= nx < width and binary_coastline[ny, nx]:
                    neighbor_count += 1

        isolation_score = 1.0 - (neighbor_count / 24.0)  # 24æ˜¯æœ€å¤§é‚»å±…æ•°
        removal_score += isolation_score * 0.3

        # 2. æµ·åŸŸä½ç½®è¯„åˆ†ï¼ˆåœ¨æµ·åŸŸä¸­çš„åƒç´ ç§»é™¤ä»·å€¼æ›´é«˜ï¼‰
        if 'comprehensive_sea_mask' in sea_analysis:
            sea_mask = sea_analysis['comprehensive_sea_mask']
            if sea_mask[y, x]:
                removal_score += 0.4  # æµ·åŸŸä¸­çš„åƒç´ ä¼˜å…ˆç§»é™¤

        # 3. GTè·ç¦»è¯„åˆ†ï¼ˆè·ç¦»GTè¶Šè¿œï¼Œç§»é™¤ä»·å€¼è¶Šé«˜ï¼‰
        if gt_analysis and gt_analysis['gt_binary'] is not None:
            gt_binary = gt_analysis['gt_binary']
            if np.any(gt_binary):
                gt_coords = np.where(gt_binary)
                distances = np.sqrt((gt_coords[0] - y) ** 2 + (gt_coords[1] - x) ** 2)
                min_distance = np.min(distances)
                distance_score = min(1.0, min_distance / 30.0)
                removal_score += distance_score * 0.2

        # 4. è¾¹ç¼˜ä½ç½®è¯„åˆ†
        edge_distance = min(y, x, height - 1 - y, width - 1 - x)
        edge_score = 1.0 if edge_distance < 15 else 0.0
        removal_score += edge_score * 0.1

        return removal_score

    def _smart_pixel_addition(self, binary_coastline, gt_analysis):
        """æ™ºèƒ½åƒç´ å¢åŠ ï¼ˆä¿å®ˆï¼‰"""
        result = binary_coastline.copy()

        # åœ¨ç°æœ‰æµ·å²¸çº¿å‘¨å›´é€‚åº¦æ‰©å±•
        expanded = binary_dilation(binary_coastline, np.ones((3, 3)))
        new_pixels = expanded & ~binary_coastline

        # åªæ·»åŠ æœ€æœ‰ä»·å€¼çš„æ–°åƒç´ 
        if gt_analysis and gt_analysis['gt_binary'] is not None:
            gt_binary = gt_analysis['gt_binary']
            gt_nearby = binary_dilation(gt_binary, np.ones((5, 5)))
            valuable_new_pixels = new_pixels & gt_nearby
            result = result | valuable_new_pixels

        return result

    def _final_gt_protection(self, binary_coastline, gt_analysis):
        """æœ€ç»ˆGTä¿æŠ¤"""
        if not gt_analysis or gt_analysis['gt_binary'] is None:
            return binary_coastline

        result = binary_coastline.copy()
        gt_binary = gt_analysis['gt_binary']

        # ç¡®ä¿æ‰€æœ‰GTåƒç´ éƒ½å­˜åœ¨
        result = result | gt_binary

        # ç¡®ä¿GTå‘¨å›´çš„è¿é€šæ€§
        gt_expanded = binary_dilation(gt_binary, np.ones((3, 3)))
        gt_connectivity = gt_expanded & binary_coastline
        result = result | gt_connectivity

        return result

    def _remove_small_components(self, binary_image, min_size=10):
        """ç§»é™¤å°ç»„ä»¶"""
        labeled_array, num_components = label(binary_image)

        result = binary_image.copy()
        for i in range(1, num_components + 1):
            size = np.sum(labeled_array == i)
            if size < min_size:
                result[labeled_array == i] = False

        return result


# ==================== å¢å¼ºçš„ç²¾å‡†æ¸…ç†æ£€æµ‹å™¨ ====================

class EnhancedPreciseSeaCleanupDetector:
    """å¢å¼ºçš„ç²¾å‡†æµ·åŸŸæ¸…ç†æ£€æµ‹å™¨ - åŒ…å«å®Œæ•´è¯„ä¼°æŒ‡æ ‡"""

    def __init__(self):
        self.gt_analyzer = GroundTruthAnalyzer()
        self.post_processor = PreciseSeaCleanupPostProcessor()
        self.metrics_calculator = ComprehensiveMetricsCalculator()
        print("âœ… å¢å¼ºç²¾å‡†æµ·åŸŸæ¸…ç†æ£€æµ‹ç³»ç»Ÿåˆå§‹åŒ–å®Œæˆ")
        print("   ğŸ¯ å¢å¼ºç‰¹è‰²ï¼šå®Œæ•´è¯„ä¼°æŒ‡æ ‡ + è®­ç»ƒæ›²çº¿ + æ—¶é—´ç»Ÿè®¡")

    def load_image_from_file(self, image_path):
        """ä»æ–‡ä»¶åŠ è½½å›¾åƒ"""
        try:
            if image_path.lower().endswith('.pdf') and HAS_PDF_SUPPORT:
                doc = fitz.open(image_path)
                page = doc.load_page(0)
                zoom = 200 / 72
                mat = fitz.Matrix(zoom, zoom)
                pix = page.get_pixmap(matrix=mat)
                img_data = pix.tobytes("png")

                img = Image.open(BytesIO(img_data))
                image_array = np.array(img)
                doc.close()

                return image_array
            else:
                img = Image.open(image_path)
                return np.array(img)

        except Exception as e:
            print(f"âŒ å›¾åƒåŠ è½½å¤±è´¥: {e}")
            return None

    def process_image(self, image_path, ground_truth_path=None):
        """å¤„ç†å•ä¸ªå›¾åƒ - å¢å¼ºç‰ˆ"""
        print(f"\nğŸŒŠ å¢å¼ºç²¾å‡†æµ·åŸŸæ¸…ç†å¤„ç†: {os.path.basename(image_path)}")

        try:
            # åŠ è½½å›¾åƒ
            original_img = self.load_image_from_file(image_path)
            if original_img is None:
                return None

            # è°ƒæ•´å°ºå¯¸
            img_pil = Image.fromarray(original_img)
            processed_img = np.array(img_pil.resize((400, 400), Image.LANCZOS))
            print(f"   ğŸ“ å¤„ç†åå°ºå¯¸: {processed_img.shape}")

            # åŠ è½½å¹¶åˆ†æGround Truth
            gt_coastline = None
            gt_analysis = None

            if ground_truth_path and os.path.exists(ground_truth_path):
                gt_img = self.load_image_from_file(ground_truth_path)
                if gt_img is not None:
                    gt_resized = np.array(Image.fromarray(gt_img).resize((400, 400), Image.LANCZOS))
                    if len(gt_resized.shape) == 3:
                        gt_gray = BasicImageProcessor.rgb_to_gray(gt_resized)
                    else:
                        gt_gray = gt_resized
                    gt_coastline = (gt_gray > 127).astype(float)

                    print("\nğŸ“ æ­¥éª¤1: Ground Truthæ¨¡å¼åˆ†æ")
                    gt_analysis = self.gt_analyzer.analyze_gt_pattern(gt_coastline)
                    if gt_analysis:
                        print(f"   GTåƒç´ æ•°: {gt_analysis['total_pixels']:,}")

            # æ­¥éª¤2: åˆ›å»ºç¯å¢ƒ
            print("\nğŸ“ æ­¥éª¤2: åˆ›å»ºçº¦æŸç¯å¢ƒ")
            env = ConstrainedCoastlineEnvironment(processed_img, gt_analysis)

            # æ­¥éª¤3: DQNè®­ç»ƒï¼ˆå¸¦ç›‘æ§ï¼‰
            print("\nğŸ“ æ­¥éª¤3: å¢å¼ºçº¦æŸDQNå­¦ä¹ ")
            agent = ConstrainedCoastlineAgent(env)

            # å¼€å§‹æ¨ç†è®¡æ—¶
            inference_start = time.time()

            optimized_coastline = agent.optimize_constrained_coastline(
                max_episodes=200,
                max_steps_per_episode=400
            )

            # ç»“æŸæ¨ç†è®¡æ—¶
            inference_time = time.time() - inference_start
            training_time = agent.training_monitor.get_training_time()

            # æ­¥éª¤4: ç²¾å‡†æµ·åŸŸæ¸…ç†åå¤„ç†
            print("\nğŸ“ æ­¥éª¤4: ç²¾å‡†æµ·åŸŸæ¸…ç†åå¤„ç†")
            final_coastline = self.post_processor.process_precise_sea_cleanup(
                optimized_coastline, env.hsv_analysis, gt_analysis, processed_img
            )

            # æ­¥éª¤5: è®¡ç®—å®Œæ•´è¯„ä¼°æŒ‡æ ‡
            print("\nğŸ“ æ­¥éª¤5: è®¡ç®—å®Œæ•´è¯„ä¼°æŒ‡æ ‡")
            comprehensive_metrics = self.metrics_calculator.calculate_all_metrics(
                predicted=final_coastline,
                ground_truth=gt_coastline,
                inference_time=inference_time,
                training_time=training_time
            )

            # æ·»åŠ è®­ç»ƒç›‘æ§æ•°æ®
            comprehensive_metrics['training_monitor'] = agent.training_monitor

            # æ‰“å°è¯¦ç»†æŒ‡æ ‡
            self._print_comprehensive_metrics(comprehensive_metrics)

            return {
                'original_image': original_img,
                'processed_image': processed_img,
                'gt_analysis': gt_analysis,
                'ground_truth': gt_coastline,
                'hsv_analysis': env.hsv_analysis,
                'optimized_coastline': optimized_coastline,
                'final_coastline': final_coastline,
                'comprehensive_metrics': comprehensive_metrics,
                'training_monitor': agent.training_monitor,
                'success': comprehensive_metrics.get('iou', 0) > 0.5 or comprehensive_metrics.get('pixel_density_score',
                                                                                                  0) > 0.8
            }

        except Exception as e:
            print(f"âŒ å¤„ç†å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return None

    def _print_comprehensive_metrics(self, metrics):
        """æ‰“å°å®Œæ•´çš„è¯„ä¼°æŒ‡æ ‡"""
        print("\nğŸ“Š å®Œæ•´è¯„ä¼°æŒ‡æ ‡æŠ¥å‘Š:")
        print("=" * 60)

        # åŸºç¡€æŒ‡æ ‡
        print("ğŸ” åŸºç¡€æŒ‡æ ‡:")
        print(f"   åƒç´ æ•°é‡: {metrics['pixel_count']:,}")
        print(f"   è¿é€šç»„ä»¶: {metrics['components']}")
        print(f"   åƒç´ å‡†ç¡®ç‡: {metrics['pixel_accuracy']:.3f}")

        # æ€§èƒ½æŒ‡æ ‡
        print("\nâ±ï¸ æ€§èƒ½æŒ‡æ ‡:")
        print(f"   æ¨ç†æ—¶é—´: {metrics['inference_time_ms']:.1f} ms")
        print(f"   è®­ç»ƒæ—¶é—´: {metrics['training_time_min']:.1f} min")

        # è´¨é‡æŒ‡æ ‡
        print("\nğŸ¯ è´¨é‡æŒ‡æ ‡:")
        print(f"   IoU: {metrics['iou']:.3f}")
        print(f"   ç²¾åº¦ (Precision): {metrics['precision']:.3f}")
        print(f"   å¬å›ç‡ (Recall): {metrics['recall']:.3f}")
        print(f"   F1åˆ†æ•°: {metrics['f1_score']:.3f}")
        print(f"   Diceç³»æ•°: {metrics['dice_coefficient']:.3f}")

        # è‡ªå®šä¹‰è´¨é‡æŒ‡æ ‡
        print("\nğŸ† è‡ªå®šä¹‰è´¨é‡æŒ‡æ ‡:")
        print(f"   åƒç´ å¯†åº¦å¾—åˆ†: {metrics['pixel_density_score']:.3f}")
        print(f"   è¿é€šæ€§å¾—åˆ†: {metrics['connectivity_score']:.3f}")
        print(f"   ç´§å‡‘åº¦: {metrics['compactness']:.3f}")

        print("=" * 60)


# ==================== å¢å¼ºå¯è§†åŒ–å‡½æ•° ====================

def create_enhanced_visualization(result, save_path):
    """åˆ›å»ºå¢å¼ºç‰ˆå¯è§†åŒ–ï¼ˆåŒ…å«è®­ç»ƒæ›²çº¿ï¼‰"""
    fig = plt.figure(figsize=(24, 16))

    # åˆ›å»ºç½‘æ ¼å¸ƒå±€
    gs = fig.add_gridspec(4, 6, height_ratios=[1, 1, 1, 0.8], width_ratios=[1, 1, 1, 1, 1, 1])

    fig.suptitle(f'Enhanced Precise Sea Cleanup Detection - {result.get("sample_id", "Unknown")}',
                 fontsize=18, fontweight='bold')

    # ç¬¬ä¸€è¡Œï¼šè¾“å…¥å’Œåˆ†æï¼ˆ6ä¸ªå­å›¾ï¼‰
    ax1 = fig.add_subplot(gs[0, 0])
    ax1.imshow(result['original_image'])
    ax1.set_title('Original Image')
    ax1.axis('off')

    ax2 = fig.add_subplot(gs[0, 1])
    ax2.imshow(result['processed_image'])
    ax2.set_title('Processed (400x400)')
    ax2.axis('off')

    ax3 = fig.add_subplot(gs[0, 2])
    if result['ground_truth'] is not None:
        ax3.imshow(result['ground_truth'], cmap='Reds')
        gt_pixels = np.sum(result['ground_truth'] > 0.5)
        ax3.set_title(f'Ground Truth\n({gt_pixels:,} pixels)')
    else:
        ax3.set_title('Ground Truth\n(Not Available)')
    ax3.axis('off')

    ax4 = fig.add_subplot(gs[0, 3])
    if 'hsv_analysis' in result:
        ax4.imshow(result['hsv_analysis']['coastline_guidance'], cmap='plasma')
        ax4.set_title('HSV Guidance')
    ax4.axis('off')

    ax5 = fig.add_subplot(gs[0, 4])
    if 'hsv_analysis' in result:
        ax5.imshow(result['hsv_analysis']['water_mask'], cmap='Blues')
        ax5.set_title('Water Mask')
    ax5.axis('off')

    ax6 = fig.add_subplot(gs[0, 5])
    if 'hsv_analysis' in result:
        ax6.imshow(result['hsv_analysis']['land_mask'], cmap='Greens')
        ax6.set_title('Land Mask')
    ax6.axis('off')

    # ç¬¬äºŒè¡Œï¼šæ£€æµ‹ç»“æœå¯¹æ¯”
    ax7 = fig.add_subplot(gs[1, 0])
    ax7.imshow(result['optimized_coastline'], cmap='hot')
    opt_pixels = np.sum(result['optimized_coastline'] > 0.3)
    ax7.set_title(f'Before Cleanup\n({opt_pixels:,} pixels)', color='orange', fontweight='bold')
    ax7.axis('off')

    ax8 = fig.add_subplot(gs[1, 1])
    ax8.imshow(result['final_coastline'], cmap='hot')
    final_pixels = result['comprehensive_metrics']['pixel_count']
    ax8.set_title(f'After Cleanup\n({final_pixels:,} pixels)', color='red', fontweight='bold')
    ax8.axis('off')

    # æ¸…ç†å¯¹æ¯”
    ax9 = fig.add_subplot(gs[1, 2])
    cleanup_diff = (result['optimized_coastline'] > 0.3).astype(float) - (result['final_coastline'] > 0.5).astype(float)
    ax9.imshow(cleanup_diff, cmap='RdBu', vmin=-1, vmax=1)
    removed_pixels = np.sum(cleanup_diff > 0)
    ax9.set_title(f'Cleanup Difference\n(Removed: {removed_pixels:,})')
    ax9.axis('off')

    # è¿é€šæ€§åˆ†æ
    ax10 = fig.add_subplot(gs[1, 3])
    labeled_array, num_components = label(result['final_coastline'] > 0.5)
    ax10.imshow(labeled_array, cmap='tab20')
    ax10.set_title(f'Connectivity\n({num_components} components)')
    ax10.axis('off')

    # GTåŒ¹é…åˆ†æ
    ax11 = fig.add_subplot(gs[1, 4])
    if result['ground_truth'] is not None:
        gt_binary = (result['ground_truth'] > 0.5).astype(bool)
        pred_binary = (result['final_coastline'] > 0.5).astype(bool)

        # åˆ›å»ºåŒ¹é…å¯è§†åŒ–ï¼šTP=ç™½è‰², FP=çº¢è‰², FN=è“è‰²
        match_vis = np.zeros((*gt_binary.shape, 3))
        match_vis[pred_binary & gt_binary] = [1, 1, 1]  # TP: ç™½è‰²
        match_vis[pred_binary & ~gt_binary] = [1, 0, 0]  # FP: çº¢è‰²
        match_vis[~pred_binary & gt_binary] = [0, 0, 1]  # FN: è“è‰²

        ax11.imshow(match_vis)
        ax11.set_title(f'GT Matching\nIoU: {result["comprehensive_metrics"]["iou"]:.3f}')
    else:
        ax11.set_title('GT Matching\n(N/A)')
    ax11.axis('off')

    # æŒ‡æ ‡æ€»ç»“
    ax12 = fig.add_subplot(gs[1, 5])
    ax12.axis('off')
    metrics = result['comprehensive_metrics']
    metrics_text = f"""Key Metrics:
IoU: {metrics['iou']:.3f}
Precision: {metrics['precision']:.3f}
Recall: {metrics['recall']:.3f}
Pixel Acc: {metrics['pixel_accuracy']:.3f}
Components: {metrics['components']}
Time: {metrics['inference_time_ms']:.0f}ms"""
    ax12.text(0.05, 0.95, metrics_text, transform=ax12.transAxes, fontsize=10,
              verticalalignment='top', fontfamily='monospace',
              bbox=dict(boxstyle="round,pad=0.3", facecolor="lightblue", alpha=0.8))

    # ç¬¬ä¸‰è¡Œï¼šè®­ç»ƒæ›²çº¿ï¼ˆå ç”¨æ•´è¡Œï¼‰
    if 'training_monitor' in result:
        training_curves_ax = fig.add_subplot(gs[2, :])

        # åˆ›å»ºå­å›¾ç”¨äºä¸åŒçš„è®­ç»ƒæŒ‡æ ‡
        training_fig, training_axes = plt.subplots(2, 2, figsize=(12, 8))

        monitor = result['training_monitor']

        # è®­ç»ƒæŸå¤±
        if monitor.training_losses:
            training_axes[0, 0].plot(monitor.training_losses, 'b-', linewidth=2, label='Precise Sea Cleanup')
            training_axes[0, 0].set_title('Training Loss')
            training_axes[0, 0].set_xlabel('Episode')
            training_axes[0, 0].set_ylabel('Loss')
            training_axes[0, 0].grid(True, alpha=0.3)
            training_axes[0, 0].legend()

        # éªŒè¯IoUï¼ˆä½¿ç”¨episodeå¥–åŠ±ä½œä¸ºä»£ç†ï¼‰
        if monitor.episode_rewards:
            normalized_rewards = np.array(monitor.episode_rewards)
            if len(normalized_rewards) > 1:
                normalized_rewards = (normalized_rewards - normalized_rewards.min()) / (
                            normalized_rewards.max() - normalized_rewards.min() + 1e-8)
            else:
                normalized_rewards = [0.5]

            training_axes[0, 1].plot(normalized_rewards, 'g-', linewidth=2, label='Precise Sea Cleanup')
            training_axes[0, 1].set_title('Validation IoU (Approximated)')
            training_axes[0, 1].set_xlabel('Episode')
            training_axes[0, 1].set_ylabel('IoU')
            training_axes[0, 1].set_ylim(0, 1)
            training_axes[0, 1].grid(True, alpha=0.3)
            training_axes[0, 1].legend()

        # åƒç´ æ•°é‡å˜åŒ–
        if monitor.pixel_counts:
            training_axes[1, 0].plot(monitor.pixel_counts, 'r-', linewidth=2, label='Pixel Count')
            training_axes[1, 0].axhline(y=90000, color='orange', linestyle='--', alpha=0.7, label='Target Min')
            training_axes[1, 0].axhline(y=100000, color='orange', linestyle='--', alpha=0.7, label='Target Max')
            training_axes[1, 0].set_title('Pixel Count Evolution')
            training_axes[1, 0].set_xlabel('Episode')
            training_axes[1, 0].set_ylabel('Pixel Count')
            training_axes[1, 0].grid(True, alpha=0.3)
            training_axes[1, 0].legend()

        # è¿é€šæ€§å¾—åˆ†
        if monitor.connectivity_scores:
            training_axes[1, 1].plot(monitor.connectivity_scores, 'm-', linewidth=2, label='Connectivity Score')
            training_axes[1, 1].set_title('Connectivity Score')
            training_axes[1, 1].set_xlabel('Episode')
            training_axes[1, 1].set_ylabel('Score')
            training_axes[1, 1].set_ylim(0, 1)
            training_axes[1, 1].grid(True, alpha=0.3)
            training_axes[1, 1].legend()

        plt.tight_layout()

        # ä¿å­˜è®­ç»ƒæ›²çº¿åˆ°ä¸´æ—¶æ–‡ä»¶
        training_curves_path = save_path.replace('.png', '_training_curves.png')
        training_fig.savefig(training_curves_path, dpi=300, bbox_inches='tight', facecolor='white')
        plt.close(training_fig)

        # åœ¨ä¸»å›¾ä¸­æ˜¾ç¤ºè®­ç»ƒæ›²çº¿çš„ç¼©ç•¥å›¾
        training_curves_ax.text(0.5, 0.5,
                                f'Training Curves\n(Saved separately as:\n{os.path.basename(training_curves_path)})',
                                ha='center', va='center', transform=training_curves_ax.transAxes,
                                fontsize=12, fontweight='bold',
                                bbox=dict(boxstyle="round,pad=0.5", facecolor="lightyellow", alpha=0.9))
        training_curves_ax.axis('off')

    # ç¬¬å››è¡Œï¼šè¯¦ç»†ç»Ÿè®¡ä¿¡æ¯
    stats_ax = fig.add_subplot(gs[3, :])
    stats_ax.axis('off')

    metrics = result['comprehensive_metrics']

    # è®¡ç®—æ¸…ç†æ•ˆæœ
    reduction_ratio = (opt_pixels - final_pixels) / max(1, opt_pixels)

    stats_text = f"""Enhanced Precise Sea Cleanup Results - Comprehensive Evaluation:

CORE METRICS:
â€¢ IoU: {metrics['iou']:.3f}
â€¢ Precision: {metrics['precision']:.3f} 
â€¢ Recall: {metrics['recall']:.3f}
â€¢ Pixel Accuracy: {metrics['pixel_accuracy']:.3f}
â€¢ Components: {metrics['components']}
â€¢ Inference Time: {metrics['inference_time_ms']:.1f} ms
â€¢ Training Time: {metrics['training_time_min']:.1f} min

CLEANUP PERFORMANCE:
â€¢ Pixel reduction: {reduction_ratio:.1%} ({opt_pixels:,} â†’ {final_pixels:,})
â€¢ Pixel density score: {metrics.get('pixel_density_score', 0):.3f}
â€¢ Connectivity score: {metrics.get('connectivity_score', 0):.3f}
â€¢ Compactness: {metrics.get('compactness', 0):.3f}
â€¢ F1-Score: {metrics['f1_score']:.3f}
â€¢ Dice Coefficient: {metrics['dice_coefficient']:.3f}

ALGORITHM FEATURES:
âœ“ Deep sea detection (HSV analysis)     âœ“ Aggressive sea area cleanup        âœ“ Smart pixel count control (90K-100K)
âœ“ Dark water identification             âœ“ Dangerous connectivity breaking     âœ“ GT protection maintained
âœ“ Uniform area recognition              âœ“ Edge artifact removal               âœ“ Real-time performance monitoring
âœ“ Vertical connectivity guard           âœ“ Isolation-based filtering           âœ“ Comprehensive metrics collection

TECHNICAL SPECIFICATIONS:
â€¢ Target pixel range: 90,000 - 100,000  â€¢ Processing resolution: 400Ã—400      â€¢ Device: {device}
â€¢ DQN episodes: 200                      â€¢ Steps per episode: 400              â€¢ Batch size: 32
â€¢ Learning rate: 1e-4                    â€¢ Gamma: 0.98                         â€¢ Memory size: 15,000"""

    stats_ax.text(0.02, 0.98, stats_text, transform=fig.transFigure,
                  fontsize=9, verticalalignment='top', fontfamily='monospace',
                  bbox=dict(boxstyle="round,pad=0.5", facecolor="lightgreen", alpha=0.9))

    plt.tight_layout()
    plt.savefig(save_path, dpi=300, bbox_inches='tight', facecolor='white')
    plt.close()

    print(f"âœ… å¢å¼ºç‰ˆå¯è§†åŒ–å·²ä¿å­˜: {save_path}")
    print(f"âœ… è®­ç»ƒæ›²çº¿å·²ä¿å­˜: {training_curves_path}")


# ==================== æ¼”ç¤ºå‡½æ•° ====================

def create_demo_image():
    """åˆ›å»ºæ¼”ç¤ºæµ·å²¸çº¿å›¾åƒ"""
    print("ğŸ¨ åˆ›å»ºæ¼”ç¤ºæµ·å²¸çº¿å›¾åƒ...")

    img = np.zeros((400, 400, 3), dtype=np.uint8)
    img[:, :] = [20, 100, 200]

    # åˆ›å»ºä¸»è¦æ¨ªå‘æµ·å²¸çº¿ - é‡ç‚¹åœ¨ä¸­é—´1/3åŒºåŸŸ
    for y in range(400):
        if 130 <= y <= 270:  # ä¸­é—´1/3åŒºåŸŸ
            main_coastline_x = int(180 + 50 * np.sin(y * 0.03) + 30 * np.sin(y * 0.1) + 10 * np.cos(y * 0.15))
        else:
            main_coastline_x = int(180 + 20 * np.sin(y * 0.01))

        main_coastline_x = max(50, min(350, main_coastline_x))

        img[y, main_coastline_x:] = [100, 180, 50]

        for offset in range(-6, 7):
            x = main_coastline_x + offset
            if 0 <= x < 400:
                mix_ratio = (6 - abs(offset)) / 6.0
                img[y, x] = [
                    int(20 + (100 - 20) * mix_ratio),
                    int(100 + (180 - 100) * mix_ratio),
                    int(200 + (50 - 200) * mix_ratio)
                ]

    # æ·»åŠ å°å²›
    island_center = (200, 120)
    for dy in range(-18, 19):
        for dx in range(-18, 19):
            y, x = island_center[0] + dy, island_center[1] + dx
            if 0 <= y < 400 and 0 <= x < 400:
                distance = math.sqrt(dy * dy + dx * dx)
                if distance <= 15:
                    img[y, x] = [100, 180, 50]
                elif distance <= 18:
                    mix_ratio = (18 - distance) / 3.0
                    img[y, x] = [
                        int(20 + (100 - 20) * mix_ratio),
                        int(100 + (180 - 100) * mix_ratio),
                        int(200 + (50 - 200) * mix_ratio)
                    ]

    # åˆ›å»ºå¯¹åº”çš„GT
    gt = np.zeros((400, 400), dtype=np.uint8)

    for y in range(400):
        if 130 <= y <= 270:
            main_coastline_x = int(180 + 50 * np.sin(y * 0.03) + 30 * np.sin(y * 0.1) + 10 * np.cos(y * 0.15))
        else:
            main_coastline_x = int(180 + 20 * np.sin(y * 0.01))
        main_coastline_x = max(50, min(350, main_coastline_x))

        for offset in range(-2, 3):
            x = main_coastline_x + offset
            if 0 <= x < 400:
                gt[y, x] = 255

    # å°å²›GT
    for dy in range(-18, 19):
        for dx in range(-18, 19):
            y, x = island_center[0] + dy, island_center[1] + dx
            if 0 <= y < 400 and 0 <= x < 400:
                distance = math.sqrt(dy * dy + dx * dx)
                if 13 <= distance <= 16:
                    gt[y, x] = 255

    return img, gt


# ==================== æµ‹è¯•å‡½æ•° ====================

def test_enhanced_precise_sea_cleanup():
    """æµ‹è¯•å¢å¼ºç²¾å‡†æµ·åŸŸæ¸…ç†ç³»ç»Ÿ"""
    print("ğŸ§ª æµ‹è¯•å¢å¼ºç²¾å‡†æµ·åŸŸæ¸…ç†ç³»ç»Ÿ...")

    detector = EnhancedPreciseSeaCleanupDetector()

    # ä½¿ç”¨ä½ ç°æœ‰çš„æ•°æ®è·¯å¾„
    initial_dir = "E:/initial"
    ground_truth_dir = "E:/ground"

    if os.path.exists(initial_dir):
        files = [f for f in os.listdir(initial_dir) if f.lower().endswith(('.pdf', '.png', '.jpg', '.jpeg'))]
        if files:
            test_file = files[0]
            initial_path = os.path.join(initial_dir, test_file)

            # æŸ¥æ‰¾GTæ–‡ä»¶
            gt_path = None
            if os.path.exists(ground_truth_dir):
                gt_files = [f for f in os.listdir(ground_truth_dir) if
                            f.lower().endswith(('.pdf', '.png', '.jpg', '.jpeg'))]
                if gt_files:
                    gt_path = os.path.join(ground_truth_dir, gt_files[0])

            print(f"\nğŸ§ª æµ‹è¯•å¢å¼ºç²¾å‡†æ¸…ç†: {test_file}")
            result = detector.process_image(initial_path, gt_path)

            if result:
                result['sample_id'] = 'enhanced_precise_cleanup_real_data'

                # ä¿å­˜ç»“æœ
                output_dir = "./enhanced_precise_cleanup_results"
                os.makedirs(output_dir, exist_ok=True)
                save_path = os.path.join(output_dir, 'enhanced_precise_sea_cleanup_detection.png')
                create_enhanced_visualization(result, save_path)

                # åˆ›å»ºè®­ç»ƒæ›²çº¿
                if 'training_monitor' in result:
                    training_curves_path = os.path.join(output_dir, 'training_curves.png')
                    result['training_monitor'].create_training_curves(training_curves_path)

                return result

    # å¦‚æœæ²¡æœ‰çœŸå®æ•°æ®ï¼Œä½¿ç”¨æ¼”ç¤ºæ•°æ®
    print("\nğŸ¨ ä½¿ç”¨æ¼”ç¤ºæ•°æ®æµ‹è¯•å¢å¼ºç³»ç»Ÿ...")

    demo_img, demo_gt = create_demo_image()

    os.makedirs("./temp", exist_ok=True)
    demo_img_path = "./temp/demo_image_enhanced.png"
    demo_gt_path = "./temp/demo_gt_enhanced.png"

    Image.fromarray(demo_img).save(demo_img_path)
    Image.fromarray(demo_gt).save(demo_gt_path)

    result = detector.process_image(demo_img_path, demo_gt_path)
    if result:
        result['sample_id'] = 'enhanced_precise_cleanup_demo'

        # ä¿å­˜ç»“æœ
        output_dir = "./enhanced_precise_cleanup_results"
        os.makedirs(output_dir, exist_ok=True)
        save_path = os.path.join(output_dir, 'enhanced_precise_sea_cleanup_detection.png')
        create_enhanced_visualization(result, save_path)

        # åˆ›å»ºè®­ç»ƒæ›²çº¿
        if 'training_monitor' in result:
            training_curves_path = os.path.join(output_dir, 'training_curves.png')
            result['training_monitor'].create_training_curves(training_curves_path)

        return result

    return None


# ==================== ä¸»å‡½æ•° ====================

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ å¯åŠ¨å¢å¼ºç²¾å‡†æµ·åŸŸæ¸…ç†æµ·å²¸çº¿æ£€æµ‹ç³»ç»Ÿ...")
    print("ğŸ¯ å¢å¼ºç‰¹è‰²ï¼šIoU + Precision + Recall + Pixel Accuracy + Components + æ—¶é—´ç»Ÿè®¡ + è®­ç»ƒæ›²çº¿")

    # è¿è¡Œæµ‹è¯•
    result = test_enhanced_precise_sea_cleanup()

    if result:




        metrics = result['comprehensive_metrics']

        print(f"\nâœ… å¢å¼ºç²¾å‡†æµ·åŸŸæ¸…ç†å¤„ç†å®Œæˆ!")
        print("=" * 80)
        print("ğŸ“Š æœ€ç»ˆç»“æœæ€»ç»“:")
        print(f"   IoU: {metrics['iou']:.3f}")
        print(f"   Precision: {metrics['precision']:.3f}")
        print(f"   Recall: {metrics['recall']:.3f}")
        print(f"   Pixel Accuracy: {metrics['pixel_accuracy']:.3f}")
        print(f"   Components: {metrics['components']}")
        print(f"   Inference Time: {metrics['inference_time_ms']:.1f} ms")
        print(f"   Training Time: {metrics['training_time_min']:.1f} min")
        print(f"   æœ€ç»ˆåƒç´ æ•°: {metrics['pixel_count']:,}")
        print(f"   æ˜¯å¦åœ¨ç›®æ ‡èŒƒå›´(9-10ä¸‡): {'âœ…' if 90000 <= metrics['pixel_count'] <= 100000 else 'âŒ'}")
        print("=" * 80)

        # æˆåŠŸçŠ¶æ€
        if result['success']:
            print("ğŸ‰ ç³»ç»Ÿè¿è¡ŒæˆåŠŸ! æ‰€æœ‰æŒ‡æ ‡å‡å·²è®¡ç®—å¹¶ä¿å­˜ã€‚")
        else:
            print("âš ï¸ ç³»ç»Ÿè¿è¡Œå®Œæˆï¼Œä½†æŸäº›æŒ‡æ ‡å¯èƒ½éœ€è¦è°ƒä¼˜ã€‚")
    else:
        print("âŒ å¢å¼ºç²¾å‡†æµ·åŸŸæ¸…ç†æµ‹è¯•å¤±è´¥")


if __name__ == "__main__":
    main()
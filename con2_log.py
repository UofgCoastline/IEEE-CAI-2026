#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
è¶…çº§å¢å¼ºGround Truthå­¦ä¹ æµ·å²¸çº¿æ£€æµ‹ç³»ç»Ÿ
ç²¾ç»†åŒ–å¤„ç† + ç©ºé—´æŠ‘åˆ¶ + è¿ç»­æ€§å¢å¼º
ä¸ä¾èµ–OpenCV
"""

import os
import numpy as np
from PIL import Image
import fitz
from scipy import ndimage
import matplotlib.pyplot as plt
from scipy.ndimage import label, gaussian_filter
import math
from io import BytesIO

# è®¾ç½®å­—ä½“
plt.rcParams['font.sans-serif'] = ['DejaVu Sans', 'Arial']
plt.rcParams['axes.unicode_minus'] = False

print("ğŸ–ï¸ è¶…çº§å¢å¼ºGround Truthå­¦ä¹ æµ·å²¸çº¿æ£€æµ‹ç³»ç»Ÿ")
print("ç²¾ç»†åŒ–å¤„ç† + ç©ºé—´æŠ‘åˆ¶ + è¿ç»­æ€§å¢å¼º")
print("=" * 60)


class UltraEnhancedCoastlineDetector:
    """è¶…çº§å¢å¼ºæµ·å²¸çº¿æ£€æµ‹å™¨ - é›†æˆæ‰€æœ‰å…ˆè¿›åŠŸèƒ½"""

    def __init__(self):
        print("âœ… è¶…çº§å¢å¼ºæ£€æµ‹å™¨åˆå§‹åŒ–å®Œæˆ")
        self.edge_kernels = self._create_edge_kernels()

    def _create_edge_kernels(self):
        """åˆ›å»ºè¾¹ç¼˜æ£€æµ‹æ ¸"""
        sobel_x = np.array([[-1, 0, 1], [-2, 0, 2], [-1, 0, 1]], dtype=float)
        sobel_y = np.array([[-1, -2, -1], [0, 0, 0], [1, 2, 1]], dtype=float)
        laplacian = np.array([[0, -1, 0], [-1, 4, -1], [0, -1, 0]], dtype=float)
        prewitt_x = np.array([[-1, 0, 1], [-1, 0, 1], [-1, 0, 1]], dtype=float)
        prewitt_y = np.array([[-1, -1, -1], [0, 0, 0], [1, 1, 1]], dtype=float)

        return {
            'sobel_x': sobel_x,
            'sobel_y': sobel_y,
            'laplacian': laplacian,
            'prewitt_x': prewitt_x,
            'prewitt_y': prewitt_y
        }

    def enhanced_color_detection(self, image):
        """å¢å¼ºçš„é¢œè‰²åŒºåŸŸæ£€æµ‹"""
        print("\nğŸ¨ å¢å¼ºé¢œè‰²åŒºåŸŸæ£€æµ‹...")

        if len(image.shape) == 3:
            rgb_image = image.copy()
            if rgb_image.max() <= 1.0:
                rgb_image = (rgb_image * 255).astype(np.uint8)
        else:
            gray = image.copy()
            if gray.max() <= 1.0:
                gray = (gray * 255).astype(np.uint8)
            rgb_image = np.stack([gray, gray, gray], axis=2)

        r, g, b = rgb_image[:, :, 0], rgb_image[:, :, 1], rgb_image[:, :, 2]

        print("   ğŸŒŠ å¢å¼ºè“è‰²æ£€æµ‹ï¼ˆæµ·æ´‹ï¼‰...")
        blue_mask = self._enhanced_blue_detection(r, g, b)
        blue_pixels = np.sum(blue_mask)
        print(f"      æ‰¾åˆ° {blue_pixels:,} ä¸ªè“è‰²åƒç´ ")

        print("   ğŸŒ¿ å¢å¼ºç»¿è‰²æ£€æµ‹ï¼ˆæ¤è¢«ï¼‰...")
        green_mask = self._enhanced_green_detection(r, g, b)
        green_pixels = np.sum(green_mask)
        print(f"      æ‰¾åˆ° {green_pixels:,} ä¸ªç»¿è‰²åƒç´ ")

        print("   ğŸœï¸ æ£€æµ‹åœŸåœ°åŒºåŸŸ...")
        land_mask = self._detect_land_regions(r, g, b)
        land_pixels = np.sum(land_mask)
        print(f"      æ‰¾åˆ° {land_pixels:,} ä¸ªåœŸåœ°åƒç´ ")

        print("   âšª å¢å¼ºç™½è‰²æ£€æµ‹...")
        white_mask = self._enhanced_white_detection(r, g, b)
        white_pixels = np.sum(white_mask)
        print(f"      æ‰¾åˆ° {white_pixels:,} ä¸ªç™½è‰²åƒç´ ")

        return {
            'blue_mask': blue_mask,
            'green_mask': green_mask,
            'land_mask': land_mask,
            'white_mask': white_mask,
            'rgb_image': rgb_image
        }

    def _enhanced_blue_detection(self, r, g, b):
        """å¢å¼ºçš„è“è‰²æ£€æµ‹"""
        strategy1 = (b > r + 25) & (b > g + 25) & (b > 70)
        strategy2 = (b > 100) & (b > r + 15) & (b > g + 15)

        total_intensity = r.astype(float) + g.astype(float) + b.astype(float)
        blue_ratio = b.astype(float) / (total_intensity + 1e-8)
        strategy3 = (blue_ratio > 0.4) & (b > 60) & (total_intensity > 120)

        dark_water = (r < 80) & (g < 80) & (b > 40) & (b > r) & (b > g)
        blue_green_water = (b > 60) & (g > 50) & (b > r + 20) & (g < b + 20)

        blue_mask = strategy1 | strategy2 | strategy3 | dark_water | blue_green_water

        kernel = np.ones((3, 3), dtype=bool)
        blue_mask = ndimage.binary_opening(blue_mask, structure=kernel)
        blue_mask = ndimage.binary_closing(blue_mask, structure=kernel)

        return blue_mask

    def _enhanced_green_detection(self, r, g, b):
        """å¢å¼ºçš„ç»¿è‰²æ£€æµ‹"""
        strategy1 = (g > r + 20) & (g > b + 20) & (g > 80)
        strategy2 = (g > 120) & (g > r + 10) & (g > b + 10)

        ndvi_like = (g.astype(float) - r.astype(float)) / (g.astype(float) + r.astype(float) + 1e-8)
        strategy3 = (ndvi_like > 0.1) & (g > 70)

        natural_green = (g > r + 15) & (g > b) & (g > 60) & (r < 150) & (b < 150)
        dark_green = (g > 40) & (g > r + 10) & (g > b + 5) & (r < 100) & (b < 100)

        green_mask = strategy1 | strategy2 | strategy3 | natural_green | dark_green

        kernel = np.ones((2, 2), dtype=bool)
        green_mask = ndimage.binary_opening(green_mask, structure=kernel)

        return green_mask

    def _detect_land_regions(self, r, g, b):
        """æ£€æµ‹åœŸåœ°åŒºåŸŸ"""
        beach_color = (r > 120) & (g > 100) & (b < 120) & (r > g) & (g > b)
        soil_color = (r > 80) & (g > 60) & (b < 80) & (abs(r.astype(int) - g.astype(int)) < 40)
        rock_color = (abs(r.astype(int) - g.astype(int)) < 20) & \
                     (abs(g.astype(int) - b.astype(int)) < 20) & \
                     (r > 60) & (r < 140)
        red_brown = (r > g + 20) & (r > b + 20) & (r > 80) & (r < 180)
        bare_ground = (r > 60) & (g > 40) & (b < 80) & (r > b + 20)

        land_mask = beach_color | soil_color | rock_color | red_brown | bare_ground
        return land_mask

    def _enhanced_white_detection(self, r, g, b):
        """å¢å¼ºçš„ç™½è‰²æ£€æµ‹"""
        strategy1 = (r > 200) & (g > 200) & (b > 200)

        rgb_diff = np.maximum(np.maximum(np.abs(r.astype(int) - g.astype(int)),
                                         np.abs(g.astype(int) - b.astype(int))),
                              np.abs(r.astype(int) - b.astype(int)))
        strategy2 = (rgb_diff < 30) & (r > 180) & (g > 180) & (b > 180)

        brightness = (r.astype(float) + g.astype(float) + b.astype(float)) / 3
        brightness_mean = gaussian_filter(brightness, sigma=5)
        local_bright = (brightness - brightness_mean) > 25
        strategy3 = local_bright & (brightness > 150)

        foam_like = (r > 160) & (g > 160) & (b > 160) & (rgb_diff < 50)
        high_reflect = (brightness > 220) & (rgb_diff < 25)

        white_mask = strategy1 | strategy2 | strategy3 | foam_like | high_reflect
        return white_mask

    def enhanced_edge_sensitivity_detection(self, image, color_regions):
        """å¢å¼ºé¢œè‰²äº¤æ¥è¾¹ç¼˜æ•æ„Ÿåº¦æ£€æµ‹"""
        print("   ğŸ” å¢å¼ºè¾¹ç¼˜æ•æ„Ÿåº¦æ£€æµ‹...")

        if len(image.shape) == 3:
            r, g, b = image[:, :, 0], image[:, :, 1], image[:, :, 2]
        else:
            r = g = b = image

        blue_mask = color_regions['blue_mask']
        green_mask = color_regions['green_mask']
        land_mask = color_regions['land_mask']

        # è“-ç»¿äº¤æ¥è¾¹ç¼˜ï¼ˆæœ€é‡è¦çš„æµ·å²¸çº¿ï¼‰
        blue_green_interface = self._detect_color_interface_enhanced(
            blue_mask, green_mask, r, g, b, interface_type="blue_green")

        # è“-åœŸåœ°äº¤æ¥è¾¹ç¼˜
        blue_land_interface = self._detect_color_interface_enhanced(
            blue_mask, land_mask, r, g, b, interface_type="blue_land")

        # ç»¿-åœŸåœ°äº¤æ¥è¾¹ç¼˜
        green_land_interface = self._detect_color_interface_enhanced(
            green_mask, land_mask, r, g, b, interface_type="green_land")

        # ç»„åˆæ‰€æœ‰äº¤æ¥è¾¹ç¼˜
        enhanced_edges = (blue_green_interface * 1.0 +
                          blue_land_interface * 0.8 +
                          green_land_interface * 0.6)

        if enhanced_edges.max() > 0:
            enhanced_edges = enhanced_edges / enhanced_edges.max()

        edge_pixels = np.sum(enhanced_edges > 0.3)
        print(f"      å¢å¼ºè¾¹ç¼˜æ£€æµ‹åˆ° {edge_pixels:,} ä¸ªåƒç´ ")

        return enhanced_edges

    def _detect_color_interface_enhanced(self, mask1, mask2, r, g, b, interface_type="general"):
        """å¢å¼ºçš„é¢œè‰²äº¤æ¥æ£€æµ‹"""
        interfaces = []

        if interface_type == "blue_green":
            dilation_sizes = [2, 3, 4, 5]
            weights = [0.4, 0.3, 0.2, 0.1]
        elif interface_type == "blue_land":
            dilation_sizes = [3, 4, 5]
            weights = [0.5, 0.3, 0.2]
        else:
            dilation_sizes = [3, 5]
            weights = [0.6, 0.4]

        for i, dilation_size in enumerate(dilation_sizes):
            kernel = np.ones((dilation_size, dilation_size), dtype=bool)
            dilated1 = ndimage.binary_dilation(mask1, structure=kernel)
            dilated2 = ndimage.binary_dilation(mask2, structure=kernel)

            interface = dilated1 & dilated2

            if np.sum(interface) > 0:
                color_gradient = self._calculate_color_gradient_at_interface(interface, r, g, b)
                enhanced_interface = interface.astype(float) * color_gradient
            else:
                enhanced_interface = interface.astype(float)

            interfaces.append(enhanced_interface)

        combined = sum(w * interface for w, interface in zip(weights, interfaces))
        return combined

    def _calculate_color_gradient_at_interface(self, interface_mask, r, g, b):
        """åœ¨äº¤æ¥åŒºåŸŸè®¡ç®—é¢œè‰²æ¢¯åº¦å¼ºåº¦"""
        grad_r_x = np.gradient(r.astype(float), axis=1)
        grad_r_y = np.gradient(r.astype(float), axis=0)
        grad_g_x = np.gradient(g.astype(float), axis=1)
        grad_g_y = np.gradient(g.astype(float), axis=0)
        grad_b_x = np.gradient(b.astype(float), axis=1)
        grad_b_y = np.gradient(b.astype(float), axis=0)

        gradient_magnitude = np.sqrt(
            (grad_r_x ** 2 + grad_r_y ** 2) +
            (grad_g_x ** 2 + grad_g_y ** 2) +
            (grad_b_x ** 2 + grad_b_y ** 2)
        )

        if np.sum(interface_mask) > 0:
            interface_gradients = gradient_magnitude[interface_mask]
            if len(interface_gradients) > 0:
                threshold = np.percentile(interface_gradients, 70)
                gradient_strength = np.where(gradient_magnitude > threshold, 1.0, 0.5)
            else:
                gradient_strength = np.ones_like(gradient_magnitude)
        else:
            gradient_strength = np.ones_like(gradient_magnitude)

        return gradient_strength

    def advanced_spatial_suppression(self, coastlines, color_regions):
        """é«˜çº§ç©ºé—´æŠ‘åˆ¶ - å¼ºåŠ›å»é™¤æµ·åŸŸä¸­é—´è½®å»“"""
        print("   ğŸ¯ é«˜çº§ç©ºé—´æŠ‘åˆ¶...")

        blue_mask = color_regions['blue_mask']
        green_mask = color_regions['green_mask']
        land_mask = color_regions['land_mask']

        # è®¡ç®—æµ·åŸŸæ·±åº¦
        ocean_depth_map = self._calculate_ocean_depth(blue_mask, green_mask, land_mask)

        # åˆ›å»ºå¼ºæŠ‘åˆ¶åŒºåŸŸ
        strong_suppression_zones = self._create_suppression_zones(ocean_depth_map, blue_mask, land_mask)

        # å¯¹æ¯ä¸ªæµ·å²¸çº¿æ£€æµ‹ç»“æœåº”ç”¨æŠ‘åˆ¶
        suppressed_coastlines = {}
        for name, coastline in coastlines.items():
            if name in ['learned_from_gt', 'enhanced_edges']:
                suppression_factor = 0.3  # ä¿æŠ¤é‡è¦ç‰¹å¾
            else:
                suppression_factor = 0.8  # å¼ºæŠ‘åˆ¶

            suppressed = coastline * (1.0 - suppression_factor * strong_suppression_zones)
            suppressed_coastlines[name] = suppressed

            original_pixels = np.sum(coastline > 0.5)
            suppressed_pixels = np.sum(suppressed > 0.3)
            print(f"      {name}: {original_pixels:,} -> {suppressed_pixels:,} åƒç´ ")

        return suppressed_coastlines, strong_suppression_zones

    def _calculate_ocean_depth(self, blue_mask, green_mask, land_mask):
        """è®¡ç®—æµ·åŸŸæ·±åº¦"""
        from scipy.ndimage import distance_transform_edt

        all_land = green_mask | land_mask
        distance_to_land = distance_transform_edt(~all_land)
        ocean_depth = np.where(blue_mask, distance_to_land, 0)

        return ocean_depth

    def _create_suppression_zones(self, ocean_depth_map, blue_mask, land_mask):
        """åˆ›å»ºæŠ‘åˆ¶åŒºåŸŸ"""
        # æµ·åŸŸæ·±åº¦æŠ‘åˆ¶
        ocean_suppression = np.where(ocean_depth_map > 25, 1.0,
                                     np.where(ocean_depth_map > 15, 0.8,
                                              np.where(ocean_depth_map > 8, 0.5, 0.0)))

        # é™†åœ°æ·±åº¦æŠ‘åˆ¶
        from scipy.ndimage import distance_transform_edt
        land_distance = distance_transform_edt(~blue_mask)
        land_suppression = np.where(land_mask,
                                    np.where(land_distance > 20, 1.0,
                                             np.where(land_distance > 10, 0.7,
                                                      np.where(land_distance > 5, 0.4, 0.0))), 0.0)

        combined_suppression = np.maximum(ocean_suppression, land_suppression)
        return combined_suppression

    def coastline_continuity_enhancement(self, coastlines, color_regions):
        """æµ·å²¸çº¿è¿ç»­æ€§å¢å¼º"""
        print("   ğŸ”— æµ·å²¸çº¿è¿ç»­æ€§å¢å¼º...")

        enhanced_coastlines = {}

        for name, coastline in coastlines.items():
            if np.sum(coastline) > 0:
                gap_filled = self._fill_coastline_gaps(coastline)
                connected = self._intelligent_line_connection(gap_filled, color_regions)
                smoothed = self._smooth_coastline(connected)
                enhanced_coastlines[name] = smoothed

                original_pixels = np.sum(coastline > 0.5)
                enhanced_pixels = np.sum(smoothed > 0.5)
                print(f"      {name}: {original_pixels:,} -> {enhanced_pixels:,} åƒç´ ")
            else:
                enhanced_coastlines[name] = coastline

        return enhanced_coastlines

    def _fill_coastline_gaps(self, coastline):
        """å¡«è¡¥æµ·å²¸çº¿æ–­è£‚"""
        binary_coastline = (coastline > 0.5).astype(bool)

        connection_kernels = [
            np.array([[1, 1, 1], [0, 1, 0], [0, 0, 0]], dtype=bool),
            np.array([[0, 0, 0], [0, 1, 0], [1, 1, 1]], dtype=bool),
            np.array([[1, 0, 0], [1, 1, 0], [1, 0, 0]], dtype=bool),
            np.array([[0, 0, 1], [0, 1, 1], [0, 0, 1]], dtype=bool),
            np.array([[1, 0, 0], [0, 1, 0], [0, 0, 1]], dtype=bool),
            np.array([[0, 0, 1], [0, 1, 0], [1, 0, 0]], dtype=bool),
        ]

        gap_filled = binary_coastline.copy()

        for iteration in range(3):
            improved = False
            for kernel in connection_kernels:
                convolved = ndimage.convolve(gap_filled.astype(int), kernel.astype(int), mode='constant')
                new_connections = (convolved >= 2) & (~gap_filled)
                if np.sum(new_connections) > 0:
                    gap_filled |= new_connections
                    improved = True

            if not improved:
                break

        return gap_filled.astype(float)

    def _intelligent_line_connection(self, coastline, color_regions):
        """æ™ºèƒ½çº¿æ®µè¿æ¥"""
        binary_coastline = (coastline > 0.5).astype(bool)
        endpoints = self._find_coastline_endpoints(binary_coastline)

        if len(endpoints) < 2:
            return coastline

        connected = binary_coastline.copy()

        for i, (y1, x1) in enumerate(endpoints):
            for j, (y2, x2) in enumerate(endpoints[i + 1:], i + 1):
                distance = np.sqrt((y2 - y1) ** 2 + (x2 - x1) ** 2)

                if distance <= 15:
                    if self._is_connection_valid(y1, x1, y2, x2, color_regions, coastline.shape):
                        line_points = self._draw_line(y1, x1, y2, x2)
                        for py, px in line_points:
                            if 0 <= py < coastline.shape[0] and 0 <= px < coastline.shape[1]:
                                connected[py, px] = True

        return connected.astype(float)

    def _find_coastline_endpoints(self, binary_coastline):
        """å¯»æ‰¾æµ·å²¸çº¿ç«¯ç‚¹"""
        kernel = np.array([[1, 1, 1], [1, 0, 1], [1, 1, 1]], dtype=bool)
        neighbor_count = ndimage.convolve(binary_coastline.astype(int), kernel.astype(int), mode='constant')

        endpoints_mask = binary_coastline & (neighbor_count == 1)
        endpoints = np.where(endpoints_mask)

        return list(zip(endpoints[0], endpoints[1]))

    def _is_connection_valid(self, y1, x1, y2, x2, color_regions, shape):
        """æ£€æŸ¥è¿æ¥æ˜¯å¦åˆç†"""
        line_points = self._draw_line(y1, x1, y2, x2)

        ocean_points = 0
        land_points = 0
        total_points = 0

        for py, px in line_points:
            if 0 <= py < shape[0] and 0 <= px < shape[1]:
                total_points += 1
                if color_regions['blue_mask'][py, px]:
                    ocean_points += 1
                elif color_regions['green_mask'][py, px] or color_regions['land_mask'][py, px]:
                    land_points += 1

        if total_points == 0:
            return False

        ocean_ratio = ocean_points / total_points
        land_ratio = land_points / total_points

        return (ocean_ratio > 0.2 and land_ratio > 0.1) or (ocean_ratio > 0.4) or (land_ratio > 0.4)

    def _draw_line(self, y1, x1, y2, x2):
        """Bresenhamçº¿æ®µç»˜åˆ¶ç®—æ³•"""
        points = []

        dx = abs(x2 - x1)
        dy = abs(y2 - y1)

        x, y = x1, y1

        x_inc = 1 if x1 < x2 else -1
        y_inc = 1 if y1 < y2 else -1

        error = dx - dy

        for _ in range(dx + dy):
            points.append((y, x))

            if error > 0:
                x += x_inc
                error -= dy
            else:
                y += y_inc
                error += dx

        points.append((y2, x2))
        return points

    def _smooth_coastline(self, coastline):
        """å¹³æ»‘æµ·å²¸çº¿"""
        if isinstance(coastline, np.ndarray) and coastline.dtype == bool:
            coastline_float = coastline.astype(float)
        else:
            coastline_float = coastline

        smoothed = gaussian_filter(coastline_float, sigma=0.8)
        final = (smoothed > 0.4).astype(float)

        return final

    def learn_from_ground_truth(self, gt_image, original_image):
        """ä»Ground Truthå­¦ä¹ æµ·å²¸çº¿ç‰¹å¾æ¨¡å¼"""
        print("   ğŸ“ ä»Ground Truthå­¦ä¹ æµ·å²¸çº¿æ¨¡å¼...")

        if gt_image is None:
            return None

        if len(gt_image.shape) == 3:
            gt_gray = np.dot(gt_image[..., :3], [0.2989, 0.5870, 0.1140])
        else:
            gt_gray = gt_image.copy()

        gt_coastline_high = (gt_gray > 200).astype(float)
        gt_coastline_med = (gt_gray > 150).astype(float)
        gt_coastline_low = (gt_gray > 100).astype(float)

        gt_coastline = gt_coastline_high * 1.0 + gt_coastline_med * 0.6 + gt_coastline_low * 0.3
        gt_coastline = (gt_coastline > 0.5).astype(float)

        learned_features = self._analyze_coastline_context(gt_coastline, original_image)

        print(f"      å­¦ä¹ åˆ° {len(learned_features)} ä¸ªç‰¹å¾æ¨¡å¼")
        return learned_features

    def _analyze_coastline_context(self, gt_coastline, original_image):
        """åˆ†æGTæµ·å²¸çº¿å‘¨å›´çš„å›¾åƒç‰¹å¾"""
        features = {}

        if gt_coastline.shape != original_image.shape[:2]:
            gt_coastline = ndimage.zoom(gt_coastline,
                                        (original_image.shape[0] / gt_coastline.shape[0],
                                         original_image.shape[1] / gt_coastline.shape[1]))

        coastline_pixels = np.where(gt_coastline > 0.5)

        if len(coastline_pixels[0]) == 0:
            return features

        if len(original_image.shape) == 3:
            r, g, b = original_image[:, :, 0], original_image[:, :, 1], original_image[:, :, 2]

            coastline_r = r[coastline_pixels]
            coastline_g = g[coastline_pixels]
            coastline_b = b[coastline_pixels]

            features['color_stats'] = {
                'r_mean': np.mean(coastline_r),
                'g_mean': np.mean(coastline_g),
                'b_mean': np.mean(coastline_b),
                'r_std': np.std(coastline_r),
                'g_std': np.std(coastline_g),
                'b_std': np.std(coastline_b)
            }

        gray = np.dot(original_image[..., :3], [0.2989, 0.5870, 0.1140]) if len(
            original_image.shape) == 3 else original_image

        sobel_x = ndimage.convolve(gray.astype(float), self.edge_kernels['sobel_x'])
        sobel_y = ndimage.convolve(gray.astype(float), self.edge_kernels['sobel_y'])
        edge_magnitude = np.sqrt(sobel_x ** 2 + sobel_y ** 2)

        coastline_edges = edge_magnitude[coastline_pixels]
        features['edge_stats'] = {
            'edge_mean': np.mean(coastline_edges),
            'edge_std': np.std(coastline_edges),
            'edge_percentiles': np.percentile(coastline_edges, [25, 50, 75, 90])
        }

        return features

    def apply_learned_features(self, image, learned_features):
        """åº”ç”¨ä»GTå­¦ä¹ åˆ°çš„ç‰¹å¾æ¥æ”¹è¿›æ£€æµ‹"""
        print("   ğŸ¯ åº”ç”¨å­¦ä¹ åˆ°çš„ç‰¹å¾æ¨¡å¼...")

        if learned_features is None:
            return np.zeros(image.shape[:2])

        if len(image.shape) == 3:
            r, g, b = image[:, :, 0], image[:, :, 1], image[:, :, 2]
        else:
            r = g = b = image

        learned_coastline = np.zeros(image.shape[:2])

        if 'color_stats' in learned_features:
            color_stats = learned_features['color_stats']

            r_match = np.abs(r - color_stats['r_mean']) < (2 * color_stats['r_std'] + 20)
            g_match = np.abs(g - color_stats['g_mean']) < (2 * color_stats['g_std'] + 20)
            b_match = np.abs(b - color_stats['b_mean']) < (2 * color_stats['b_std'] + 20)

            color_match = r_match & g_match & b_match
            learned_coastline += color_match.astype(float) * 0.4

        if 'edge_stats' in learned_features:
            edge_stats = learned_features['edge_stats']

            gray = np.dot(image[..., :3], [0.2989, 0.5870, 0.1140]) if len(image.shape) == 3 else image
            sobel_x = ndimage.convolve(gray.astype(float), self.edge_kernels['sobel_x'])
            sobel_y = ndimage.convolve(gray.astype(float), self.edge_kernels['sobel_y'])
            edge_magnitude = np.sqrt(sobel_x ** 2 + sobel_y ** 2)

            edge_threshold_low = edge_stats['edge_percentiles'][1]
            edge_threshold_high = edge_stats['edge_percentiles'][2]

            edge_match = (edge_magnitude >= edge_threshold_low) & (edge_magnitude <= edge_threshold_high * 2)
            learned_coastline += edge_match.astype(float) * 0.6

        if learned_coastline.max() > 0:
            learned_coastline = learned_coastline / learned_coastline.max()

        final_learned = (learned_coastline > 0.3).astype(float)

        print(f"      å­¦ä¹ æ£€æµ‹åˆ° {np.sum(final_learned):,} ä¸ªæµ·å²¸çº¿åƒç´ ")
        return final_learned

    def cnn_like_feature_extraction(self, image):
        """CNNæ ·å¼çš„ç‰¹å¾æå–"""
        print("\nğŸ§  CNNç‰¹å¾æå–...")

        if len(image.shape) == 3:
            gray = np.dot(image[..., :3], [0.2989, 0.5870, 0.1140])
        else:
            gray = image.copy()

        if gray.max() <= 1.0:
            gray = (gray * 255).astype(np.uint8)

        features = {}

        sobel_x = ndimage.convolve(gray.astype(float), self.edge_kernels['sobel_x'])
        sobel_y = ndimage.convolve(gray.astype(float), self.edge_kernels['sobel_y'])
        edge_magnitude = np.sqrt(sobel_x ** 2 + sobel_y ** 2)
        features['edges'] = edge_magnitude

        prewitt_x = ndimage.convolve(gray.astype(float), self.edge_kernels['prewitt_x'])
        prewitt_y = ndimage.convolve(gray.astype(float), self.edge_kernels['prewitt_y'])
        prewitt_magnitude = np.sqrt(prewitt_x ** 2 + prewitt_y ** 2)
        features['prewitt_edges'] = prewitt_magnitude

        texture = ndimage.generic_filter(gray.astype(float), np.std, size=5)
        features['texture'] = texture

        laplacian = ndimage.convolve(gray.astype(float), self.edge_kernels['laplacian'])
        features['laplacian'] = np.abs(laplacian)

        local_mean = ndimage.uniform_filter(gray.astype(float), size=5)
        local_contrast = np.abs(gray.astype(float) - local_mean)
        features['local_contrast'] = local_contrast

        print(f"   âœ… æå–äº† {len(features)} ä¸ªç‰¹å¾å›¾")

        return features

    def dqn_like_coastline_extraction(self, color_regions, cnn_features):
        """DQNæ ·å¼çš„æµ·å²¸çº¿æå–"""
        print("\nğŸ¤– DQNæ ·å¼æµ·å²¸çº¿æå–...")

        coastlines = {}

        print("   ğŸ“ é¢œè‰²è¾¹ç•Œæå–...")

        ocean_boundary = self._extract_smart_boundary(color_regions['blue_mask'])
        coastlines['ocean_boundary'] = ocean_boundary

        land_combined = color_regions['green_mask'] | color_regions['land_mask']
        land_boundary = self._extract_smart_boundary(land_combined)
        coastlines['land_boundary'] = land_boundary

        print("   ğŸ§  CNNç‰¹å¾è¾¹ç•Œ...")

        edge_threshold = np.percentile(cnn_features['edges'], 85)
        strong_edges = cnn_features['edges'] > edge_threshold
        coastlines['cnn_edges'] = strong_edges.astype(float)

        prewitt_threshold = np.percentile(cnn_features['prewitt_edges'], 80)
        prewitt_strong = cnn_features['prewitt_edges'] > prewitt_threshold
        coastlines['prewitt_edges'] = prewitt_strong.astype(float)

        texture_threshold = np.percentile(cnn_features['texture'], 80)
        high_texture = cnn_features['texture'] > texture_threshold
        coastlines['texture_edges'] = high_texture.astype(float)

        print("   ğŸŒŠ æµ·é™†äº¤æ¥çº¿...")
        ocean_land_interface = self._extract_interface_advanced(
            color_regions['blue_mask'],
            land_combined
        )
        coastlines['ocean_land_interface'] = ocean_land_interface

        print("   âšª ç™½è‰²æ ‡æ³¨å¤„ç†...")
        white_processed = self._process_white_annotations(color_regions['white_mask'])
        coastlines['white_annotations'] = white_processed

        return coastlines

    def _extract_smart_boundary(self, mask):
        """æ™ºèƒ½è¾¹ç•Œæå–"""
        boundaries = []

        for kernel_size in [3, 5, 7]:
            kernel = np.ones((kernel_size, kernel_size), dtype=bool)
            eroded = ndimage.binary_erosion(mask, structure=kernel)
            boundary = mask & (~eroded)
            boundaries.append(boundary.astype(float))

        combined_boundary = np.maximum.reduce(boundaries)

        kernel = np.ones((3, 3), dtype=bool)
        connected = ndimage.binary_closing(combined_boundary > 0.5, structure=kernel)

        return connected.astype(float)

    def _extract_interface_advanced(self, mask1, mask2):
        """é«˜çº§äº¤æ¥çº¿æå–"""
        interfaces = []

        for dilation_size in [3, 5, 7]:
            kernel = np.ones((dilation_size, dilation_size), dtype=bool)
            dilated1 = ndimage.binary_dilation(mask1, structure=kernel)
            dilated2 = ndimage.binary_dilation(mask2, structure=kernel)
            interface = dilated1 & dilated2
            interfaces.append(interface.astype(float))

        weights = [0.5, 0.3, 0.2]
        combined = sum(w * interface for w, interface in zip(weights, interfaces))

        return combined

    def _process_white_annotations(self, white_mask):
        """å¤„ç†ç™½è‰²æ ‡æ³¨"""
        kernel_line = np.ones((5, 1), dtype=bool)
        kernel_line2 = np.ones((1, 5), dtype=bool)

        connected_v = ndimage.binary_closing(white_mask, structure=kernel_line)
        connected_h = ndimage.binary_closing(white_mask, structure=kernel_line2)

        connected = connected_v | connected_h

        labeled, num_features = label(connected)
        filtered = np.zeros_like(connected, dtype=bool)

        for i in range(1, num_features + 1):
            component = (labeled == i)
            if np.sum(component) >= 5:
                filtered = filtered | component

        return filtered.astype(float)

    def intelligent_coastline_fusion(self, coastlines, learned_features):
        """æ™ºèƒ½æµ·å²¸çº¿èåˆ"""
        print("\nğŸ”„ æ™ºèƒ½æµ·å²¸çº¿èåˆ...")

        weights = {
            'ocean_boundary': 0.15,
            'land_boundary': 0.12,
            'ocean_land_interface': 0.20,
            'cnn_edges': 0.10,
            'prewitt_edges': 0.08,
            'texture_edges': 0.08,
            'white_annotations': 0.12,
            'enhanced_edges': 0.30,
            'learned_from_gt': 0.50
        }

        combined = np.zeros_like(list(coastlines.values())[0])

        for name, coastline in coastlines.items():
            weight = weights.get(name, 0.1)
            combined += weight * coastline
            pixels = np.sum(coastline > 0.5)
            print(f"   {name}: {pixels:,} åƒç´  (æƒé‡: {weight:.2f})")

        if combined.max() > 0:
            combined = combined / combined.max()

        threshold = self._calculate_adaptive_threshold(combined)
        final_coastline = (combined > threshold).astype(float)

        final_coastline = self._post_process_coastline(final_coastline)

        final_pixels = np.sum(final_coastline > 0.5)
        print(f"âœ… æœ€ç»ˆæµ·å²¸çº¿: {final_pixels:,} åƒç´  (é˜ˆå€¼: {threshold:.3f})")

        return final_coastline, combined

    def _calculate_adaptive_threshold(self, combined):
        """è®¡ç®—è‡ªé€‚åº”é˜ˆå€¼"""
        hist, bins = np.histogram(combined.flatten(), bins=50, range=(0, 1))

        best_threshold = 0.2
        max_variance = 0

        for i in range(5, 45):
            threshold = i / 50.0

            w1 = np.sum(hist[:i])
            w2 = np.sum(hist[i:])

            if w1 > 0 and w2 > 0:
                mean1 = np.sum(np.arange(i) * hist[:i]) / w1 if w1 > 0 else 0
                mean2 = np.sum(np.arange(i, 50) * hist[i:]) / w2 if w2 > 0 else 0
                variance = w1 * w2 * (mean1 - mean2) ** 2

                if variance > max_variance:
                    max_variance = variance
                    best_threshold = threshold

        return max(0.15, min(0.4, best_threshold))

    def _post_process_coastline(self, coastline):
        """æµ·å²¸çº¿åå¤„ç†"""
        labeled, num_features = label(coastline > 0.5)
        filtered = np.zeros_like(coastline, dtype=bool)

        for i in range(1, num_features + 1):
            component = (labeled == i)
            if np.sum(component) >= 8:
                filtered = filtered | component

        kernel = np.ones((3, 3), dtype=bool)
        connected = ndimage.binary_closing(filtered, structure=kernel)

        smoothed = gaussian_filter(connected.astype(float), sigma=0.8)
        final = (smoothed > 0.4).astype(float)

        return final

    def load_ground_truth(self, gt_path):
        """åŠ è½½Ground Truthæ•°æ®"""
        try:
            if gt_path and gt_path.endswith('.pdf'):
                doc = fitz.open(gt_path)
                page = doc.load_page(0)
                zoom = 200 / 72
                mat = fitz.Matrix(zoom, zoom)
                pix = page.get_pixmap(matrix=mat)
                img_data = pix.tobytes("png")

                img = Image.open(BytesIO(img_data))
                gt_image = np.array(img)
                doc.close()

                gt_processed = self.preprocess_image(gt_image, (400, 400))

                if len(gt_processed.shape) == 3:
                    gray = np.dot(gt_processed[..., :3], [0.2989, 0.5870, 0.1140])
                else:
                    gray = gt_processed

                gt_strategy1 = (gray > 200).astype(float)
                gt_strategy2 = (gray > 150).astype(float)

                gt_coastline = gt_strategy1 * 0.8 + gt_strategy2 * 0.2
                gt_coastline = (gt_coastline > 0.5).astype(float)

                return gt_coastline, gt_processed
            else:
                return None, None

        except Exception as e:
            print(f"âŒ æ— æ³•åŠ è½½Ground Truth: {e}")
            return None, None

    def calculate_accuracy_metrics(self, predicted, ground_truth):
        """è®¡ç®—å‡†ç¡®ç‡æŒ‡æ ‡"""
        if ground_truth is None:
            return None

        if predicted.shape != ground_truth.shape:
            ground_truth = ndimage.zoom(ground_truth,
                                        (predicted.shape[0] / ground_truth.shape[0],
                                         predicted.shape[1] / ground_truth.shape[1]))

        pred_binary = (predicted > 0.5).astype(bool)
        gt_binary = (ground_truth > 0.5).astype(bool)

        tp = np.sum(pred_binary & gt_binary)
        fp = np.sum(pred_binary & ~gt_binary)
        fn = np.sum(~pred_binary & gt_binary)
        tn = np.sum(~pred_binary & ~gt_binary)

        precision = tp / (tp + fp + 1e-8)
        recall = tp / (tp + fn + 1e-8)
        f1_score = 2 * precision * recall / (precision + recall + 1e-8)
        iou = tp / (tp + fp + fn + 1e-8)

        return {
            'precision': precision,
            'recall': recall,
            'f1_score': f1_score,
            'iou': iou,
            'tp': tp,
            'fp': fp,
            'fn': fn,
            'tn': tn
        }

    def process_image(self, image_path, ground_truth_path=None):
        """å¤„ç†å›¾åƒçš„ä¸»å‡½æ•°"""
        print(f"\nğŸ–¼ï¸ å¤„ç†: {os.path.basename(image_path)}")

        try:
            doc = fitz.open(image_path)
            page = doc.load_page(0)
            zoom = 200 / 72
            mat = fitz.Matrix(zoom, zoom)
            pix = page.get_pixmap(matrix=mat)
            img_data = pix.tobytes("png")

            img = Image.open(BytesIO(img_data))
            original_img = np.array(img)
            doc.close()

            processed_img = self.preprocess_image(original_img, (400, 400))
            print(f"   ğŸ“ å¤„ç†åå°ºå¯¸: {processed_img.shape}")

            gt_coastline, gt_image = self.load_ground_truth(ground_truth_path) if ground_truth_path else (None, None)

            # Ground Truthå­¦ä¹ 
            learned_features = None
            if gt_image is not None:
                gt_processed = self.preprocess_image(gt_image, (400, 400))
                learned_features = self.learn_from_ground_truth(gt_processed, processed_img)

            # å¢å¼ºé¢œè‰²æ£€æµ‹
            color_regions = self.enhanced_color_detection(processed_img)

            # å¢å¼ºè¾¹ç¼˜æ•æ„Ÿåº¦æ£€æµ‹
            enhanced_edges = self.enhanced_edge_sensitivity_detection(processed_img, color_regions)

            # CNNç‰¹å¾æå–
            cnn_features = self.cnn_like_feature_extraction(processed_img)

            # DQNæ ·å¼æµ·å²¸çº¿æå–
            coastlines = self.dqn_like_coastline_extraction(color_regions, cnn_features)
            coastlines['enhanced_edges'] = enhanced_edges

            # Ground Truthå­¦ä¹ åº”ç”¨
            if learned_features is not None:
                learned_coastline = self.apply_learned_features(processed_img, learned_features)
                coastlines['learned_from_gt'] = learned_coastline
                print(f"   ğŸ“ ä»GTå­¦ä¹ çš„æµ·å²¸çº¿: {np.sum(learned_coastline):,} åƒç´ ")

            # é«˜çº§ç©ºé—´æŠ‘åˆ¶
            suppressed_coastlines, suppression_zones = self.advanced_spatial_suppression(coastlines, color_regions)

            # æµ·å²¸çº¿è¿ç»­æ€§å¢å¼º
            continuous_coastlines = self.coastline_continuity_enhancement(suppressed_coastlines, color_regions)

            # æ™ºèƒ½èåˆ
            final_coastline, combined_score = self.intelligent_coastline_fusion(continuous_coastlines, learned_features)

            # è®¡ç®—å‡†ç¡®ç‡
            accuracy_metrics = self.calculate_accuracy_metrics(final_coastline, gt_coastline)

            # è´¨é‡è¯„ä¼°
            coastline_pixels = np.sum(final_coastline > 0.5)
            total_pixels = final_coastline.size
            coverage_ratio = coastline_pixels / total_pixels

            labeled, num_components = label(final_coastline > 0.5)
            quality_score = min(1.0, coastline_pixels / 300.0)

            return {
                'original_image': original_img,
                'processed_image': processed_img,
                'ground_truth': gt_coastline,
                'gt_image': gt_image,
                'color_regions': color_regions,
                'cnn_features': cnn_features,
                'coastlines': coastlines,
                'suppressed_coastlines': suppressed_coastlines,
                'continuous_coastlines': continuous_coastlines,
                'suppression_zones': suppression_zones,
                'enhanced_edges': enhanced_edges,
                'learned_features': learned_features,
                'combined_score': combined_score,
                'final_coastline': final_coastline,
                'coastline_pixels': coastline_pixels,
                'coverage_ratio': coverage_ratio,
                'num_components': num_components,
                'quality_score': quality_score,
                'accuracy_metrics': accuracy_metrics,
                'success': coastline_pixels > 50
            }

        except Exception as e:
            print(f"âŒ å¤„ç†å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return None

    def preprocess_image(self, image, target_size):
        """å›¾åƒé¢„å¤„ç†"""
        if isinstance(image, np.ndarray):
            pil_img = Image.fromarray(image.astype(np.uint8))
        else:
            pil_img = image

        resized = pil_img.resize(target_size, Image.Resampling.LANCZOS)
        return np.array(resized)


def create_comprehensive_visualization(result, year, save_path):
    """åˆ›å»ºå…¨é¢çš„å¯è§†åŒ–"""

    fig, axes = plt.subplots(4, 4, figsize=(20, 20))
    fig.suptitle(f'Ultra-Enhanced Coastline Detection - {year}', fontsize=16, fontweight='bold')

    # ç¬¬ä¸€è¡Œï¼šè¾“å…¥å’Œç»“æœå¯¹æ¯”
    axes[0, 0].imshow(result['original_image'])
    axes[0, 0].set_title('Original Image')
    axes[0, 0].axis('off')

    axes[0, 1].imshow(result['processed_image'])
    axes[0, 1].set_title('Processed Image')
    axes[0, 1].axis('off')

    axes[0, 2].imshow(result['final_coastline'], cmap='hot', vmin=0, vmax=1)
    axes[0, 2].set_title('Final Coastline', color='red', fontweight='bold')
    axes[0, 2].axis('off')

    if result['ground_truth'] is not None:
        axes[0, 3].imshow(result['ground_truth'], cmap='gray')
        axes[0, 3].set_title('Ground Truth')
        axes[0, 3].axis('off')
    else:
        axes[0, 3].text(0.5, 0.5, 'No Ground Truth\nAvailable',
                        ha='center', va='center', fontsize=12)
        axes[0, 3].set_title('Ground Truth')
        axes[0, 3].axis('off')

    # ç¬¬äºŒè¡Œï¼šé¢œè‰²åŒºåŸŸæ£€æµ‹å’Œæ–°å¢åŠŸèƒ½
    blue_display = np.zeros_like(result['processed_image'])
    if len(blue_display.shape) == 3:
        blue_display[:, :, 2] = result['color_regions']['blue_mask'] * 255
    axes[1, 0].imshow(blue_display)
    blue_pixels = np.sum(result['color_regions']['blue_mask'])
    axes[1, 0].set_title(f'Ocean Regions\n({blue_pixels:,} pixels)')
    axes[1, 0].axis('off')

    green_display = np.zeros_like(result['processed_image'])
    if len(green_display.shape) == 3:
        green_display[:, :, 1] = result['color_regions']['green_mask'] * 255
    axes[1, 1].imshow(green_display)
    green_pixels = np.sum(result['color_regions']['green_mask'])
    axes[1, 1].set_title(f'Vegetation\n({green_pixels:,} pixels)')
    axes[1, 1].axis('off')

    # å¢å¼ºè¾¹ç¼˜æ£€æµ‹å¯è§†åŒ–
    axes[1, 2].imshow(result['enhanced_edges'], cmap='hot')
    enhanced_pixels = np.sum(result['enhanced_edges'] > 0.3)
    axes[1, 2].set_title(f'Enhanced Edge Detection\n({enhanced_pixels:,} pixels)',
                         color='orange', fontweight='bold')
    axes[1, 2].axis('off')

    # ç©ºé—´æŠ‘åˆ¶åŒºåŸŸå¯è§†åŒ–
    axes[1, 3].imshow(result['suppression_zones'], cmap='Reds')
    suppression_strength = np.mean(result['suppression_zones'])
    axes[1, 3].set_title(f'Spatial Suppression Zones\n(Avg: {suppression_strength:.2f})',
                         color='red', fontweight='bold')
    axes[1, 3].axis('off')

    # ç¬¬ä¸‰è¡Œï¼šCNNç‰¹å¾
    axes[2, 0].imshow(result['cnn_features']['edges'], cmap='hot')
    axes[2, 0].set_title('Sobel Edge Features')
    axes[2, 0].axis('off')

    axes[2, 1].imshow(result['cnn_features']['texture'], cmap='viridis')
    axes[2, 1].set_title('Texture Features')
    axes[2, 1].axis('off')

    axes[2, 2].imshow(result['cnn_features']['prewitt_edges'], cmap='hot')
    axes[2, 2].set_title('Prewitt Edge Features')
    axes[2, 2].axis('off')

    axes[2, 3].imshow(result['cnn_features']['local_contrast'], cmap='plasma')
    axes[2, 3].set_title('Local Contrast')
    axes[2, 3].axis('off')

    # ç¬¬å››è¡Œï¼šæµ·å²¸çº¿ç»„ä»¶å’Œæœ€ç»ˆç»“æœ
    axes[3, 0].imshow(result['coastlines']['ocean_land_interface'], cmap='hot')
    interface_pixels = np.sum(result['coastlines']['ocean_land_interface'])
    axes[3, 0].set_title(f'Ocean-Land Interface\n({interface_pixels:,} pixels)')
    axes[3, 0].axis('off')

    if 'learned_from_gt' in result['coastlines']:
        axes[3, 1].imshow(result['coastlines']['learned_from_gt'], cmap='hot')
        learned_pixels = np.sum(result['coastlines']['learned_from_gt'])
        axes[3, 1].set_title(f'Learned from GT\n({learned_pixels:,} pixels)',
                             color='purple', fontweight='bold')
        axes[3, 1].axis('off')
    else:
        cnn_combined = result['coastlines']['cnn_edges'] + result['coastlines']['prewitt_edges']
        axes[3, 1].imshow(cnn_combined, cmap='hot')
        cnn_pixels = np.sum(cnn_combined > 0.5)
        axes[3, 1].set_title(f'Combined CNN Edges\n({cnn_pixels:,} pixels)')
        axes[3, 1].axis('off')

    axes[3, 2].imshow(result['combined_score'], cmap='hot')
    axes[3, 2].set_title('Combined Score')
    axes[3, 2].axis('off')

    # ç»Ÿè®¡ä¿¡æ¯
    axes[3, 3].axis('off')

    stats_text = f"""Ultra-Enhanced Detection:

Quality Score: {result['quality_score']:.3f}
Status: {"SUCCESS" if result['success'] else "FAILED"}

Final Analysis:
â€¢ Final pixels: {result['coastline_pixels']:,}
â€¢ Coverage: {result['coverage_ratio'] * 100:.1f}%
â€¢ Components: {result['num_components']}

Enhanced Features:
â€¢ Enhanced edges: {np.sum(result['enhanced_edges'] > 0.3):,}
â€¢ Spatial suppression: {np.mean(result['suppression_zones']):.2f} avg

Color Detection:
â€¢ Ocean: {np.sum(result['color_regions']['blue_mask']):,}
â€¢ Vegetation: {np.sum(result['color_regions']['green_mask']):,}
â€¢ Land: {np.sum(result['color_regions']['land_mask']):,}

CNN Features:
â€¢ Sobel edges: {np.max(result['cnn_features']['edges']):.1f}
â€¢ Texture: {np.mean(result['cnn_features']['texture']):.1f}
â€¢ Contrast: {np.mean(result['cnn_features']['local_contrast']):.1f}

Learning from GT:
â€¢ GT Available: {"YES" if result['ground_truth'] is not None else "NO"}"""

    if 'learned_from_gt' in result['coastlines']:
        learned_pixels = np.sum(result['coastlines']['learned_from_gt'])
        stats_text += f"""
â€¢ Learned pixels: {learned_pixels:,}
â€¢ Learning success: {"YES" if learned_pixels > 100 else "NO"}"""

    stats_text += f"""

Ultra Methods:
âœ“ Advanced spatial suppression
âœ“ Coastline continuity enhancement
âœ“ Enhanced edge sensitivity
âœ“ GT pattern learning
âœ“ Multi-strategy color detection
âœ“ CNN+DQN fusion"""

    if result['accuracy_metrics'] is not None:
        acc = result['accuracy_metrics']
        stats_text += f"""

Accuracy Metrics:
â€¢ Precision: {acc['precision']:.3f}
â€¢ Recall: {acc['recall']:.3f}
â€¢ F1-Score: {acc['f1_score']:.3f}
â€¢ IoU: {acc['iou']:.3f}"""

    axes[3, 3].text(0.05, 0.95, stats_text, transform=axes[3, 3].transAxes,
                    fontsize=7, verticalalignment='top', fontfamily='monospace',
                    bbox=dict(boxstyle="round,pad=0.5", facecolor="lightcyan", alpha=0.8))
    axes[3, 3].set_title('Ultra Detection Statistics')

    plt.tight_layout()
    plt.savefig(save_path, dpi=300, bbox_inches='tight', facecolor='white')
    plt.close()

    print(f"âœ… è¶…çº§å¢å¼ºå¯è§†åŒ–å·²ä¿å­˜: {save_path}")


def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ å¯åŠ¨è¶…çº§å¢å¼ºæµ·å²¸çº¿æ£€æµ‹...")

    detector = UltraEnhancedCoastlineDetector()

    initial_dir = "E:/initial"
    ground_truth_dir = "E:/ground"

    print(f"\nğŸ“ æ£€æŸ¥æ•°æ®ç›®å½•...")
    print(f"   åŸå§‹å›¾åƒ: {initial_dir}")
    print(f"   Ground Truth: {ground_truth_dir}")

    if not os.path.exists(initial_dir):
        print(f"âŒ åŸå§‹å›¾åƒæ–‡ä»¶å¤¹ä¸å­˜åœ¨: {initial_dir}")
        return

    initial_files = [f for f in os.listdir(initial_dir) if f.endswith('.pdf')]
    print(f"   æ‰¾åˆ° {len(initial_files)} ä¸ªåŸå§‹å›¾åƒæ–‡ä»¶")

    if len(initial_files) == 0:
        print("âŒ æ²¡æœ‰æ‰¾åˆ°åŸå§‹å›¾åƒæ–‡ä»¶")
        return

    gt_files = []
    if os.path.exists(ground_truth_dir):
        gt_files = [f for f in os.listdir(ground_truth_dir) if f.endswith('.pdf')]
        print(f"   æ‰¾åˆ° {len(gt_files)} ä¸ªGround Truthæ–‡ä»¶")
    else:
        print(f"   âš ï¸ Ground Truthç›®å½•ä¸å­˜åœ¨: {ground_truth_dir}")

    output_dir = "./ultra_results"
    os.makedirs(output_dir, exist_ok=True)

    results_summary = []

    for i, pdf_file in enumerate(initial_files[:5]):
        print(f"\n{'=' * 80}")
        print(f"å¤„ç†æ ·æœ¬ {i + 1}/{min(5, len(initial_files))}: {pdf_file}")

        import re
        years = re.findall(r'20\d{2}', pdf_file)
        year = years[0] if years else f"sample_{i + 1}"

        gt_file = None
        if gt_files:
            for gt in gt_files:
                if year in gt:
                    gt_file = gt
                    break

            if gt_file is None and i < len(gt_files):
                gt_file = gt_files[i]

        initial_path = os.path.join(initial_dir, pdf_file)
        gt_path = os.path.join(ground_truth_dir, gt_file) if gt_file else None

        if gt_path and os.path.exists(gt_path):
            print(f"   ğŸ¯ ä½¿ç”¨Ground Truth: {gt_file}")
        else:
            print(f"   âš ï¸ æœªæ‰¾åˆ°æœ‰æ•ˆçš„Ground Truth")

        result = detector.process_image(initial_path, gt_path)

        if result is not None:
            save_path = os.path.join(output_dir, f'ultra_detection_{year}.png')
            create_comprehensive_visualization(result, year, save_path)

            summary = {
                'year': year,
                'success': result['success'],
                'quality_score': result['quality_score'],
                'coastline_pixels': result['coastline_pixels'],
                'coverage_ratio': result['coverage_ratio'],
                'num_components': result['num_components'],
                'suppression_strength': np.mean(result['suppression_zones'])
            }

            if result['accuracy_metrics']:
                summary.update(result['accuracy_metrics'])

            results_summary.append(summary)

            print(f"âœ… {year} è¶…çº§å¤„ç†å®Œæˆ!")
            print(f"   è´¨é‡å¾—åˆ†: {result['quality_score']:.3f}")
            print(f"   æµ·å²¸çº¿åƒç´ : {result['coastline_pixels']:,}")
            print(f"   ç©ºé—´æŠ‘åˆ¶: {summary['suppression_strength']:.3f}")

            if result['accuracy_metrics']:
                acc = result['accuracy_metrics']
                print(f"   F1-Score: {acc['f1_score']:.3f}")
                print(f"   IoU: {acc['iou']:.3f}")
        else:
            print(f"âŒ {year} å¤„ç†å¤±è´¥")

    print(f"\nğŸ‰ è¶…çº§å¢å¼ºæ£€æµ‹å®Œæˆ!")
    print(f"ğŸ“‚ ç»“æœä¿å­˜åœ¨: {output_dir}")

    if results_summary:
        successful = [r for r in results_summary if r['success']]
        success_rate = len(successful) / len(results_summary) * 100

        print(f"\nğŸ“Š å¤„ç†æ€»ç»“:")
        print(f"   æ€»æ ·æœ¬æ•°: {len(results_summary)}")
        print(f"   æˆåŠŸå¤„ç†: {len(successful)} ({success_rate:.1f}%)")

        if successful:
            avg_quality = np.mean([r['quality_score'] for r in successful])
            avg_pixels = np.mean([r['coastline_pixels'] for r in successful])
            avg_suppression = np.mean([r.get('suppression_strength', 0) for r in successful])

            print(f"   å¹³å‡è´¨é‡å¾—åˆ†: {avg_quality:.3f}")
            print(f"   å¹³å‡æµ·å²¸çº¿åƒç´ : {avg_pixels:,.0f}")
            print(f"   å¹³å‡ç©ºé—´æŠ‘åˆ¶: {avg_suppression:.3f}")

            with_accuracy = [r for r in successful if 'f1_score' in r]
            if with_accuracy:
                avg_f1 = np.mean([r['f1_score'] for r in with_accuracy])
                avg_iou = np.mean([r['iou'] for r in with_accuracy])
                print(f"   å¹³å‡F1å¾—åˆ†: {avg_f1:.3f}")
                print(f"   å¹³å‡IoU: {avg_iou:.3f}")

    print(f"\nğŸ’¡ è¶…çº§å¢å¼ºç‰¹æ€§:")
    print(f"   ğŸ¯ é«˜çº§ç©ºé—´æŠ‘åˆ¶ - å½»åº•å»é™¤æµ·åŸŸä¸­é—´è½®å»“")
    print(f"   ğŸ”— æµ·å²¸çº¿è¿ç»­æ€§å¢å¼º - æ™ºèƒ½è¡¥å…¨æ–­è£‚")
    print(f"   ğŸ” å¢å¼ºè¾¹ç¼˜æ•æ„Ÿåº¦ - ä¸“æ³¨é¢œè‰²äº¤æ¥")
    print(f"   ğŸ“ Ground Truthå­¦ä¹  - æ¨¡å¼è¯†åˆ«")
    print(f"   âœ… å¤šç­–ç•¥é¢œè‰²æ£€æµ‹ - å…¨æ–¹ä½è¦†ç›–")
    print(f"   ğŸ§  CNN+DQNæ¶æ„ - æ™ºèƒ½èåˆ")


if __name__ == "__main__":
    print("ğŸ” æ£€æŸ¥ä¾èµ–...")
    try:
        import numpy as np
        import matplotlib.pyplot as plt
        import scipy
        from PIL import Image
        import fitz

        print("âœ… æ‰€æœ‰ä¾èµ–æ£€æŸ¥é€šè¿‡ï¼ˆæ— éœ€OpenCVï¼‰")
        main()
    except ImportError as e:
        print(f"âŒ ç¼ºå°‘ä¾èµ–: {e}")
        print("è¯·å®‰è£…åŸºç¡€ä¾èµ–: pip install matplotlib scipy pillow PyMuPDF")
        print("æ³¨æ„ï¼šæ­¤ç‰ˆæœ¬ä¸éœ€è¦OpenCV!")
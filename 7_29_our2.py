"""
å¿«é€Ÿç²¾å‡†æµ·åŸŸæ¸…ç†æµ·å²¸çº¿æ£€æµ‹ç³»ç»Ÿ
ä¸»è¦ç›®æ ‡ï¼šå¿«é€Ÿè®­ç»ƒ + é‡ç‚¹å…³æ³¨æœ€ç»ˆæ¸…ç†åçš„è¯„ä¼°æŒ‡æ ‡
ç®€åŒ–ç­–ç•¥ï¼šå‡å°‘è®­ç»ƒå¤æ‚åº¦ï¼Œä¸“æ³¨åå¤„ç†ä¼˜åŒ–
"""

import os
import numpy as np
from PIL import Image
import matplotlib.pyplot as plt
from scipy import ndimage
from scipy.ndimage import label, gaussian_filter, binary_dilation, binary_erosion, binary_closing
import random
from collections import deque, namedtuple
import math
from io import BytesIO
import colorsys
import time

# PyTorch imports
import torch
import torch.nn as nn
import torch.optim as optim
import torch.nn.functional as F

# å¯é€‰ä¾èµ–æ£€æŸ¥
try:
    import fitz
    HAS_PDF_SUPPORT = True
except ImportError:
    HAS_PDF_SUPPORT = False

# è®¾ç½®è®¾å¤‡å’Œéšæœºç§å­
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
torch.manual_seed(42)
np.random.seed(42)
random.seed(42)

print("ğŸš€ å¿«é€Ÿç²¾å‡†æµ·åŸŸæ¸…ç†ç³»ç»Ÿ!")
print("ç›®æ ‡ï¼šå¿«é€Ÿè®­ç»ƒ + é‡ç‚¹è¯„ä¼°æœ€ç»ˆæŒ‡æ ‡")
print("=" * 60)


# ==================== ç®€åŒ–çš„è¯„ä¼°æŒ‡æ ‡è®¡ç®—å™¨ ====================

class FastMetricsCalculator:
    """å¿«é€Ÿè¯„ä¼°æŒ‡æ ‡è®¡ç®—å™¨"""

    def __init__(self):
        print("âœ… å¿«é€Ÿè¯„ä¼°æŒ‡æ ‡è®¡ç®—å™¨åˆå§‹åŒ–å®Œæˆ")

    def calculate_metrics(self, predicted, ground_truth=None, inference_time=0.0, training_time=0.0):
        """è®¡ç®—å…³é”®è¯„ä¼°æŒ‡æ ‡"""
        metrics = {}

        # é¢„å¤„ç†
        pred_binary = (predicted > 0.5).astype(bool)

        # åŸºç¡€æŒ‡æ ‡
        metrics['pixel_count'] = int(np.sum(pred_binary))

        # è¿é€šç»„ä»¶åˆ†æ
        labeled_array, num_components = label(pred_binary)
        metrics['components'] = int(num_components)

        # æ—¶é—´æŒ‡æ ‡
        metrics['inference_time_ms'] = float(inference_time * 1000)
        metrics['training_time_min'] = float(training_time)

        # å¦‚æœæœ‰Ground Truthï¼Œè®¡ç®—ç²¾ç¡®çš„æŒ‡æ ‡
        if ground_truth is not None:
            gt_binary = (ground_truth > 0.5).astype(bool)

            # æ··æ·†çŸ©é˜µå…ƒç´ 
            tp = np.sum(pred_binary & gt_binary)  # True Positive
            fp = np.sum(pred_binary & ~gt_binary)  # False Positive
            fn = np.sum(~pred_binary & gt_binary)  # False Negative
            tn = np.sum(~pred_binary & ~gt_binary)  # True Negative

            # æ ¸å¿ƒæŒ‡æ ‡
            metrics['iou'] = float(tp / (tp + fp + fn + 1e-8))
            metrics['precision'] = float(tp / (tp + fp + 1e-8))
            metrics['recall'] = float(tp / (tp + fn + 1e-8))
            metrics['pixel_accuracy'] = float((tp + tn) / (tp + fp + fn + tn + 1e-8))

            # F1 Score
            precision = metrics['precision']
            recall = metrics['recall']
            metrics['f1_score'] = float(2 * precision * recall / (precision + recall + 1e-8))

        else:
            # æ— GTæ—¶è®¾ç½®é»˜è®¤å€¼
            metrics.update({
                'iou': 0.0, 'precision': 0.0, 'recall': 0.0,
                'pixel_accuracy': 0.0, 'f1_score': 0.0
            })

        return metrics


# ==================== åŸºç¡€ç±»ï¼ˆç®€åŒ–ç‰ˆï¼‰====================

class BasicImageProcessor:
    @staticmethod
    def rgb_to_gray(rgb_image):
        if len(rgb_image.shape) == 3:
            return np.dot(rgb_image[..., :3], [0.2989, 0.5870, 0.1140])
        return rgb_image


class SimpleGTAnalyzer:
    """ç®€åŒ–çš„GTåˆ†æå™¨"""
    def __init__(self):
        print("âœ… ç®€åŒ–GTåˆ†æå™¨åˆå§‹åŒ–å®Œæˆ")

    def analyze_gt_pattern(self, gt_coastline):
        if gt_coastline is None:
            return None

        gt_binary = (gt_coastline > 0.5).astype(bool)

        # ç®€åŒ–çš„è¾¹ç¼˜åŒºåŸŸ
        edge_region = gt_binary.copy()
        for _ in range(5):  # å‡å°‘è†¨èƒ€æ¬¡æ•°
            edge_region = binary_dilation(edge_region, np.ones((3, 3), dtype=bool))

        return {
            'gt_binary': gt_binary,
            'edge_region': edge_region,
            'total_pixels': np.sum(gt_binary)
        }


# ==================== ç®€åŒ–çš„HSVç›‘ç£å™¨ ====================

class SimpleHSVAnalyzer:
    """ç®€åŒ–çš„HSVåˆ†æå™¨"""

    def __init__(self):
        print("âœ… ç®€åŒ–HSVåˆ†æå™¨åˆå§‹åŒ–å®Œæˆ")

    def analyze_image_hsv(self, rgb_image, gt_analysis=None):
        """å¿«é€ŸHSVåˆ†æ"""
        # è½¬æ¢ä¸ºHSV
        if len(rgb_image.shape) == 3:
            rgb_normalized = rgb_image.astype(float) / 255.0
            hsv_image = np.zeros_like(rgb_normalized)

            for i in range(0, rgb_image.shape[0], 4):  # é‡‡æ ·åˆ†æï¼Œæé«˜é€Ÿåº¦
                for j in range(0, rgb_image.shape[1], 4):
                    r, g, b = rgb_normalized[i, j]
                    h, s, v = colorsys.rgb_to_hsv(r, g, b)
                    hsv_image[i:i+4, j:j+4] = [h * 360, s, v]  # å—å¡«å……
        else:
            hsv_image = np.stack([np.zeros_like(rgb_image),
                                  np.zeros_like(rgb_image),
                                  rgb_image / 255.0], axis=2)

        # ç®€åŒ–çš„æ°´åŸŸå’Œé™†åœ°æ£€æµ‹
        h, s, v = hsv_image[:, :, 0], hsv_image[:, :, 1], hsv_image[:, :, 2]

        # æ°´åŸŸï¼šè“è‰²è°ƒ + ä½äº®åº¦
        water_mask = ((h >= 180) & (h <= 240)) & (v <= 0.6)

        # é™†åœ°ï¼šç»¿è‰²è°ƒ + é«˜äº®åº¦
        land_mask = ((h >= 60) & (h <= 120)) | (v >= 0.4)

        # ç®€åŒ–çš„æµ·å²¸çº¿å¼•å¯¼
        coastline_guidance = self._generate_simple_guidance(water_mask, land_mask, gt_analysis)

        return {
            'water_mask': water_mask,
            'land_mask': land_mask,
            'coastline_guidance': coastline_guidance,
            'transition_strength': np.ones_like(water_mask, dtype=float) * 0.5  # ç®€åŒ–
        }

    def _generate_simple_guidance(self, water_mask, land_mask, gt_analysis=None):
        """ç”Ÿæˆç®€åŒ–çš„æµ·å²¸çº¿å¼•å¯¼"""
        # æ°´é™†è¾¹ç•Œ
        water_boundary = binary_dilation(water_mask, np.ones((3, 3))) & ~water_mask
        land_boundary = binary_dilation(land_mask, np.ones((3, 3))) & ~land_mask
        guidance = (water_boundary | land_boundary).astype(float)

        # å¦‚æœæœ‰GTï¼Œç›´æ¥ä½¿ç”¨GTåŒºåŸŸ
        if gt_analysis is not None:
            gt_guidance = binary_dilation(gt_analysis['gt_binary'], np.ones((5, 5)))
            guidance = np.maximum(guidance, gt_guidance.astype(float))

        return guidance


# ==================== ç®€åŒ–çš„DQNç½‘ç»œ ====================

class SimpleDQN(nn.Module):
    """ç®€åŒ–çš„DQNç½‘ç»œ"""

    def __init__(self, input_size=32*32*3, hidden_dim=128, action_dim=8):
        super(SimpleDQN, self).__init__()

        self.network = nn.Sequential(
            nn.Linear(input_size + 10, hidden_dim),  # ç®€åŒ–ç‰¹å¾
            nn.ReLU(),
            nn.Linear(hidden_dim, hidden_dim//2),
            nn.ReLU(),
            nn.Linear(hidden_dim//2, action_dim)
        )

    def forward(self, state_features):
        return self.network(state_features)


# ==================== å¿«é€Ÿç¯å¢ƒ ====================

class FastCoastlineEnvironment:
    """å¿«é€Ÿæµ·å²¸çº¿ç¯å¢ƒ"""

    def __init__(self, image, gt_analysis):
        self.image = image
        self.gt_analysis = gt_analysis
        self.current_coastline = np.zeros(image.shape[:2], dtype=float)
        self.height, self.width = image.shape[:2]

        # ç®€åŒ–çš„HSVåˆ†æ
        self.hsv_analyzer = SimpleHSVAnalyzer()
        self.hsv_analysis = self.hsv_analyzer.analyze_image_hsv(image, gt_analysis)

        # ç®€åŒ–çš„åŠ¨ä½œç©ºé—´
        self.base_actions = [(-1, -1), (-1, 0), (-1, 1), (0, -1),
                            (0, 1), (1, -1), (1, 0), (1, 1)]
        self.action_dim = len(self.base_actions)

        # ç®€åŒ–çš„æœç´¢åŒºåŸŸ
        self.search_region = self._setup_simple_search_region()

        print(f"âœ… å¿«é€Ÿæµ·å²¸çº¿ç¯å¢ƒåˆå§‹åŒ–å®Œæˆ")

    def _setup_simple_search_region(self):
        """è®¾ç½®ç®€åŒ–çš„æœç´¢åŒºåŸŸ"""
        # ä¸»è¦å…³æ³¨ä¸­é—´1/3åŒºåŸŸ
        height, width = self.height, self.width
        search_region = np.zeros((height, width), dtype=bool)

        # ä¸­é—´åŒºåŸŸ
        middle_start = height // 3
        middle_end = 2 * height // 3
        search_region[middle_start:middle_end, :] = True

        # å¦‚æœæœ‰GTï¼Œæ‰©å±•GTå‘¨å›´åŒºåŸŸ
        if self.gt_analysis:
            gt_region = binary_dilation(self.gt_analysis['gt_binary'], np.ones((10, 10)))
            search_region = search_region | gt_region

        return search_region

    def get_simple_features(self, position):
        """è·å–ç®€åŒ–ç‰¹å¾"""
        y, x = position
        window_size = 32
        half_window = window_size // 2

        # æå–å±€éƒ¨å›¾åƒçª—å£
        y_start = max(0, y - half_window)
        y_end = min(self.height, y + half_window)
        x_start = max(0, x - half_window)
        x_end = min(self.width, x + half_window)

        # ç®€åŒ–çš„ç‰¹å¾å‘é‡
        features = np.zeros(32*32*3 + 10, dtype=np.float32)

        # å›¾åƒç‰¹å¾ï¼ˆé™é‡‡æ ·ï¼‰
        if len(self.image.shape) == 3:
            img_window = self.image[y_start:y_end, x_start:x_end]
            img_resized = np.array(Image.fromarray(img_window).resize((32, 32))) / 255.0
            features[:32*32*3] = img_resized.flatten()
        else:
            gray_window = self.image[y_start:y_end, x_start:x_end]
            gray_resized = np.array(Image.fromarray(gray_window).resize((32, 32))) / 255.0
            features[:32*32] = gray_resized.flatten()

        # ä½ç½®ç‰¹å¾
        features[-10] = y / self.height
        features[-9] = x / self.width
        features[-8] = self.hsv_analysis['coastline_guidance'][y, x]
        features[-7] = 1.0 if self.hsv_analysis['water_mask'][y, x] else 0.0
        features[-6] = 1.0 if self.hsv_analysis['land_mask'][y, x] else 0.0

        # GTç‰¹å¾
        if self.gt_analysis:
            features[-5] = 1.0 if self.gt_analysis['gt_binary'][y, x] else 0.0

        # åŒºåŸŸç‰¹å¾
        if self.height // 3 <= y <= 2 * self.height // 3:
            features[-4] = 1.0  # ä¸­é—´åŒºåŸŸ

        return torch.FloatTensor(features).unsqueeze(0).to(device)

    def step(self, position, action_idx):
        """æ‰§è¡ŒåŠ¨ä½œ"""
        y, x = position
        dy, dx = self.base_actions[action_idx]

        new_y = np.clip(y + dy, 0, self.height - 1)
        new_x = np.clip(x + dx, 0, self.width - 1)

        new_position = (new_y, new_x)
        reward = self._calculate_simple_reward(new_position)

        return new_position, reward

    def _calculate_simple_reward(self, position):
        """ç®€åŒ–çš„å¥–åŠ±å‡½æ•°"""
        y, x = position
        reward = 0.0

        # åŸºç¡€åŒºåŸŸå¥–åŠ±
        if self.height // 3 <= y <= 2 * self.height // 3:
            reward += 20.0

        # HSVå¼•å¯¼å¥–åŠ±
        reward += self.hsv_analysis['coastline_guidance'][y, x] * 30.0

        # GTå¥–åŠ±
        if self.gt_analysis and self.gt_analysis['gt_binary'][y, x]:
            reward += 50.0

        # æœç´¢åŒºåŸŸæ£€æŸ¥
        if not self.search_region[y, x]:
            reward -= 100.0

        return reward

    def update_coastline(self, position, value=1.0):
        """æ›´æ–°æµ·å²¸çº¿"""
        y, x = position
        if 0 <= y < self.height and 0 <= x < self.width:
            self.current_coastline[y, x] = min(1.0, self.current_coastline[y, x] + value)


# ==================== å¿«é€Ÿä»£ç† ====================

class FastCoastlineAgent:
    """å¿«é€Ÿæµ·å²¸çº¿ä»£ç†"""

    def __init__(self, env):
        self.env = env
        self.device = device

        # ç®€åŒ–çš„ç½‘ç»œ
        self.policy_net = SimpleDQN().to(device)
        self.optimizer = optim.Adam(self.policy_net.parameters(), lr=5e-3)  # æé«˜å­¦ä¹ ç‡

        self.epsilon = 0.5  # é™ä½åˆå§‹æ¢ç´¢ç‡
        self.epsilon_decay = 0.98
        self.epsilon_min = 0.1

        print(f"âœ… å¿«é€ŸDQNä»£ç†åˆå§‹åŒ–å®Œæˆ")

    def select_action(self, features, training=True):
        """é€‰æ‹©åŠ¨ä½œ"""
        if training and random.random() < self.epsilon:
            return random.randint(0, self.env.action_dim - 1)
        else:
            with torch.no_grad():
                q_values = self.policy_net(features)
                return q_values.argmax(dim=1).item()

    def fast_train(self, max_episodes=50, max_steps_per_episode=200):  # å¤§å¹…å‡å°‘è®­ç»ƒæ—¶é—´
        """å¿«é€Ÿè®­ç»ƒ"""
        print("ğŸš€ å¼€å§‹å¿«é€Ÿè®­ç»ƒ...")

        search_positions = np.where(self.env.search_region)
        candidate_positions = list(zip(search_positions[0], search_positions[1]))

        if not candidate_positions:
            print("   âš ï¸ æœªæ‰¾åˆ°æœç´¢åŒºåŸŸ")
            return self.env.current_coastline

        # ä¼˜å…ˆé€‰æ‹©ä¸­é—´åŒºåŸŸçš„èµ·å§‹ç‚¹
        height = self.env.height
        middle_positions = [pos for pos in candidate_positions
                           if height//3 <= pos[0] <= 2*height//3]

        if not middle_positions:
            middle_positions = candidate_positions[:20]

        for episode in range(max_episodes):
            # éšæœºé€‰æ‹©èµ·å§‹ä½ç½®
            start_position = random.choice(middle_positions)
            current_position = start_position
            episode_reward = 0

            for step in range(max_steps_per_episode):
                # è·å–ç‰¹å¾
                features = self.env.get_simple_features(current_position)

                # é€‰æ‹©åŠ¨ä½œ
                action = self.select_action(features, training=True)

                # æ‰§è¡ŒåŠ¨ä½œ
                next_position, reward = self.env.step(current_position, action)
                episode_reward += reward

                # æ›´æ–°æµ·å²¸çº¿ï¼ˆæ›´å®½æ¾çš„æ¡ä»¶ï¼‰
                if reward > 5.0:  # é™ä½é˜ˆå€¼
                    self.env.update_coastline(next_position, 0.8)
                elif reward > 0:
                    self.env.update_coastline(next_position, 0.4)

                current_position = next_position

                # æ—©åœæ¡ä»¶
                if reward < -50:
                    break

            # è¡°å‡æ¢ç´¢ç‡
            self.epsilon = max(self.epsilon_min, self.epsilon * self.epsilon_decay)

            if episode % 10 == 0:
                current_pixels = np.sum(self.env.current_coastline > 0.3)
                print(f"   Episode {episode:2d}: å¥–åŠ±={episode_reward:6.1f}, Îµ={self.epsilon:.3f}, åƒç´ ={current_pixels:,}")

        final_pixels = np.sum(self.env.current_coastline > 0.3)
        print(f"   âœ… å¿«é€Ÿè®­ç»ƒå®Œæˆ: æ€»åƒç´ ={final_pixels:,}")

        return self.env.current_coastline


# ==================== IoUä¼˜åŒ–åå¤„ç†å™¨ ====================

class IoUOptimizedPostProcessor:
    """ä¸“é—¨ä¼˜åŒ–IoUçš„åå¤„ç†å™¨"""

    def __init__(self, target_pixel_range=(90000, 100000)):
        self.target_pixel_range = target_pixel_range
        print("âœ… IoUä¼˜åŒ–åå¤„ç†å™¨åˆå§‹åŒ–å®Œæˆ")

    def process_for_optimal_iou(self, raw_coastline, gt_analysis, rgb_image):
        """ä¸“é—¨ä¸ºIoUä¼˜åŒ–çš„åå¤„ç†"""
        print("ğŸ¯ å¼€å§‹IoUä¼˜åŒ–åå¤„ç†...")

        # 1. æ™ºèƒ½äºŒå€¼åŒ–
        binary_coastline = self._smart_binarization(raw_coastline)
        print(f"   äºŒå€¼åŒ–å: {np.sum(binary_coastline):,} åƒç´ ")

        # 2. GTå¯¹é½ä¼˜åŒ–
        if gt_analysis and gt_analysis['gt_binary'] is not None:
            gt_aligned = self._align_with_gt(binary_coastline, gt_analysis['gt_binary'])
            print(f"   GTå¯¹é½å: {np.sum(gt_aligned):,} åƒç´ ")
        else:
            gt_aligned = binary_coastline

        # 3. å½¢æ€å­¦ä¼˜åŒ–
        morph_optimized = self._morphological_optimization(gt_aligned)
        print(f"   å½¢æ€å­¦ä¼˜åŒ–å: {np.sum(morph_optimized):,} åƒç´ ")

        # 4. åƒç´ æ•°é‡æ§åˆ¶
        pixel_controlled = self._control_pixel_count(morph_optimized, gt_analysis)
        print(f"   åƒç´ æ§åˆ¶å: {np.sum(pixel_controlled):,} åƒç´ ")

        # 5. æœ€ç»ˆè¾¹ç•Œä¼˜åŒ–
        final_result = self._boundary_refinement(pixel_controlled, gt_analysis)
        print(f"   æœ€ç»ˆç»“æœ: {np.sum(final_result):,} åƒç´ ")

        return final_result.astype(float)

    def _smart_binarization(self, coastline):
        """æ™ºèƒ½äºŒå€¼åŒ–"""
        # ä½¿ç”¨è‡ªé€‚åº”é˜ˆå€¼
        valid_pixels = coastline[coastline > 0]
        if len(valid_pixels) > 0:
            threshold = np.percentile(valid_pixels, 60)  # 60%åˆ†ä½æ•°
        else:
            threshold = 0.3

        binary_result = coastline > threshold

        # ç§»é™¤å°ç»„ä»¶
        labeled_array, num_components = label(binary_result)
        for i in range(1, num_components + 1):
            component_size = np.sum(labeled_array == i)
            if component_size < 20:  # ç§»é™¤å°äº20åƒç´ çš„ç»„ä»¶
                binary_result[labeled_array == i] = False

        return binary_result

    def _align_with_gt(self, binary_coastline, gt_binary):
        """ä¸GTå¯¹é½ä»¥æé«˜IoU"""
        result = binary_coastline.copy()

        # GTä¿æŠ¤åŒºåŸŸ
        gt_protection = binary_dilation(gt_binary, np.ones((3, 3)))

        # åœ¨GTä¿æŠ¤åŒºåŸŸå†…ï¼Œä¼˜å…ˆåŒ¹é…GT
        result[gt_protection] = gt_binary[gt_protection]

        # ç¡®ä¿æ‰€æœ‰GTåƒç´ éƒ½è¢«åŒ…å«
        result = result | gt_binary

        return result

    def _morphological_optimization(self, binary_coastline):
        """å½¢æ€å­¦ä¼˜åŒ–"""
        # å°è¯•ä¸åŒçš„å½¢æ€å­¦æ“ä½œï¼Œé€‰æ‹©æœ€ä¼˜çš„
        operations = [
            binary_coastline,  # åŸå§‹
            binary_closing(binary_coastline, np.ones((3, 3))),  # é—­è¿ç®—
            binary_erosion(binary_coastline, np.ones((2, 2))),  # è…èš€
            binary_dilation(binary_coastline, np.ones((2, 2))),  # è†¨èƒ€
        ]

        # é€‰æ‹©è¿é€šç»„ä»¶æ•°é‡æœ€åˆç†çš„ç»“æœ
        best_result = binary_coastline
        target_components = 50  # æœŸæœ›çš„ç»„ä»¶æ•°é‡

        for op_result in operations:
            _, num_components = label(op_result)
            if abs(num_components - target_components) < abs(label(best_result)[1] - target_components):
                best_result = op_result

        return best_result

    def _control_pixel_count(self, binary_coastline, gt_analysis):
        """æ§åˆ¶åƒç´ æ•°é‡"""
        current_pixels = np.sum(binary_coastline)
        target_min, target_max = self.target_pixel_range

        if target_min <= current_pixels <= target_max:
            return binary_coastline

        if current_pixels > target_max:
            # éœ€è¦å‡å°‘åƒç´ 
            excess = current_pixels - target_max
            return self._remove_excess_pixels(binary_coastline, excess, gt_analysis)
        else:
            # éœ€è¦å¢åŠ åƒç´ ï¼ˆä¿å®ˆï¼‰
            return self._add_pixels_conservatively(binary_coastline, gt_analysis)

    def _remove_excess_pixels(self, binary_coastline, excess, gt_analysis):
        """ç§»é™¤å¤šä½™åƒç´ """
        result = binary_coastline.copy()

        # GTä¿æŠ¤
        if gt_analysis and gt_analysis['gt_binary'] is not None:
            gt_protection = binary_dilation(gt_analysis['gt_binary'], np.ones((5, 5)))
            removable_pixels = binary_coastline & ~gt_protection
        else:
            removable_pixels = binary_coastline

        # éšæœºç§»é™¤è¾¹ç¼˜åƒç´ 
        removable_positions = np.where(removable_pixels)
        if len(removable_positions[0]) > excess:
            remove_indices = np.random.choice(len(removable_positions[0]), excess, replace=False)
            for idx in remove_indices:
                y, x = removable_positions[0][idx], removable_positions[1][idx]
                result[y, x] = False

        return result

    def _add_pixels_conservatively(self, binary_coastline, gt_analysis):
        """ä¿å®ˆåœ°å¢åŠ åƒç´ """
        result = binary_coastline.copy()

        # åœ¨ç°æœ‰æµ·å²¸çº¿å‘¨å›´è†¨èƒ€
        dilated = binary_dilation(binary_coastline, np.ones((3, 3)))
        new_pixels = dilated & ~binary_coastline

        # å¦‚æœæœ‰GTï¼Œä¼˜å…ˆæ·»åŠ GTé™„è¿‘çš„åƒç´ 
        if gt_analysis and gt_analysis['gt_binary'] is not None:
            gt_nearby = binary_dilation(gt_analysis['gt_binary'], np.ones((3, 3)))
            preferred_new_pixels = new_pixels & gt_nearby
            result = result | preferred_new_pixels

        return result

    def _boundary_refinement(self, binary_coastline, gt_analysis):
        """è¾¹ç•Œç»†åŒ–"""
        if gt_analysis is None or gt_analysis['gt_binary'] is None:
            return binary_coastline

        result = binary_coastline.copy()
        gt_binary = gt_analysis['gt_binary']

        # åœ¨GTè¾¹ç•Œé™„è¿‘è¿›è¡Œåƒç´ çº§è°ƒæ•´
        gt_boundary = self._get_boundary_pixels(gt_binary)
        gt_boundary_region = binary_dilation(gt_boundary, np.ones((5, 5)))

        # åœ¨GTè¾¹ç•ŒåŒºåŸŸå†…ï¼Œè°ƒæ•´é¢„æµ‹ç»“æœä»¥æ›´å¥½åŒ¹é…GT
        adjustment_region = gt_boundary_region & (binary_coastline | gt_binary)

        # ç®€å•çš„è°ƒæ•´ç­–ç•¥ï¼šåœ¨è°ƒæ•´åŒºåŸŸå†…ï¼Œå€¾å‘äºåŒ¹é…GT
        result[adjustment_region] = gt_binary[adjustment_region]

        return result

    def _get_boundary_pixels(self, binary_mask):
        """è·å–è¾¹ç•Œåƒç´ """
        eroded = binary_erosion(binary_mask, np.ones((3, 3)))
        boundary = binary_mask & ~eroded
        return boundary


# ==================== å¿«é€Ÿæ£€æµ‹å™¨ ====================

class FastPreciseSeaCleanupDetector:
    """å¿«é€Ÿç²¾å‡†æµ·åŸŸæ¸…ç†æ£€æµ‹å™¨"""

    def __init__(self):
        self.gt_analyzer = SimpleGTAnalyzer()
        self.post_processor = IoUOptimizedPostProcessor()
        self.metrics_calculator = FastMetricsCalculator()
        print("âœ… å¿«é€Ÿç²¾å‡†æµ·åŸŸæ¸…ç†æ£€æµ‹ç³»ç»Ÿåˆå§‹åŒ–å®Œæˆ")

    def load_image_from_file(self, image_path):
        """ä»æ–‡ä»¶åŠ è½½å›¾åƒ"""
        try:
            if image_path.lower().endswith('.pdf') and HAS_PDF_SUPPORT:
                doc = fitz.open(image_path)
                page = doc.load_page(0)
                zoom = 200 / 72
                mat = fitz.Matrix(zoom, zoom)
                pix = page.get_pixmap(matrix=mat)
                img_data = pix.tobytes("png")

                img = Image.open(BytesIO(img_data))
                image_array = np.array(img)
                doc.close()
                return image_array
            else:
                img = Image.open(image_path)
                return np.array(img)
        except Exception as e:
            print(f"âŒ å›¾åƒåŠ è½½å¤±è´¥: {e}")
            return None

    def process_image(self, image_path, ground_truth_path=None):
        """å¿«é€Ÿå¤„ç†å›¾åƒ"""
        print(f"\nğŸš€ å¿«é€Ÿå¤„ç†: {os.path.basename(image_path)}")

        try:
            # åŠ è½½å›¾åƒ
            original_img = self.load_image_from_file(image_path)
            if original_img is None:
                return None

            # è°ƒæ•´å°ºå¯¸
            img_pil = Image.fromarray(original_img)
            processed_img = np.array(img_pil.resize((400, 400), Image.LANCZOS))
            print(f"   ğŸ“ å°ºå¯¸: {processed_img.shape}")

            # åŠ è½½Ground Truth
            gt_coastline = None
            gt_analysis = None

            if ground_truth_path and os.path.exists(ground_truth_path):
                gt_img = self.load_image_from_file(ground_truth_path)
                if gt_img is not None:
                    gt_resized = np.array(Image.fromarray(gt_img).resize((400, 400), Image.LANCZOS))
                    if len(gt_resized.shape) == 3:
                        gt_gray = BasicImageProcessor.rgb_to_gray(gt_resized)
                    else:
                        gt_gray = gt_resized
                    gt_coastline = (gt_gray > 127).astype(float)
                    gt_analysis = self.gt_analyzer.analyze_gt_pattern(gt_coastline)
                    print(f"   ğŸ“ GTåƒç´ : {gt_analysis['total_pixels']:,}")

            # å¿«é€Ÿè®­ç»ƒ
            print("\nğŸ¯ å¿«é€ŸDQNè®­ç»ƒ...")
            start_time = time.time()

            env = FastCoastlineEnvironment(processed_img, gt_analysis)
            agent = FastCoastlineAgent(env)
            raw_coastline = agent.fast_train(max_episodes=50, max_steps_per_episode=200)

            training_time = time.time() - start_time
            print(f"   â±ï¸ è®­ç»ƒç”¨æ—¶: {training_time:.1f} ç§’")

            # IoUä¼˜åŒ–åå¤„ç†
            print("\nğŸ¯ IoUä¼˜åŒ–åå¤„ç†...")
            inference_start = time.time()

            final_coastline = self.post_processor.process_for_optimal_iou(
                raw_coastline, gt_analysis, processed_img
            )

            inference_time = time.time() - inference_start

            # è®¡ç®—æœ€ç»ˆæŒ‡æ ‡
            print("\nğŸ“Š è®¡ç®—è¯„ä¼°æŒ‡æ ‡...")
            final_metrics = self.metrics_calculator.calculate_metrics(
                predicted=final_coastline,
                ground_truth=gt_coastline,
                inference_time=inference_time,
                training_time=training_time / 60.0  # è½¬æ¢ä¸ºåˆ†é’Ÿ
            )

            # æ‰“å°å…³é”®æŒ‡æ ‡
            self._print_key_metrics(final_metrics)

            return {
                'original_image': original_img,
                'processed_image': processed_img,
                'gt_analysis': gt_analysis,
                'ground_truth': gt_coastline,
                'raw_coastline': raw_coastline,
                'final_coastline': final_coastline,
                'metrics': final_metrics,
                'success': final_metrics.get('iou', 0) > 0.6 or final_metrics.get('f1_score', 0) > 0.7
            }

        except Exception as e:
            print(f"âŒ å¤„ç†å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return None

    def _print_key_metrics(self, metrics):
        """æ‰“å°å…³é”®æŒ‡æ ‡"""
        print("\nğŸ“Š å…³é”®è¯„ä¼°æŒ‡æ ‡:")
        print("=" * 50)
        print(f"ğŸ¯ IoU: {metrics['iou']:.3f}")
        print(f"ğŸ¯ Precision: {metrics['precision']:.3f}")
        print(f"ğŸ¯ Recall: {metrics['recall']:.3f}")
        print(f"ğŸ¯ Pixel Accuracy: {metrics['pixel_accuracy']:.3f}")
        print(f"ğŸ¯ F1-Score: {metrics['f1_score']:.3f}")
        print(f"ğŸ”¢ Components: {metrics['components']}")
        print(f"ğŸ”¢ Pixel Count: {metrics['pixel_count']:,}")
        print(f"â±ï¸ Inference Time: {metrics['inference_time_ms']:.1f} ms")
        print(f"â±ï¸ Training Time: {metrics['training_time_min']:.1f} min")
        print("=" * 50)


# ==================== å¿«é€Ÿå¯è§†åŒ– ====================

def create_fast_visualization(result, save_path):
    """åˆ›å»ºå¿«é€Ÿå¯è§†åŒ–"""
    fig, axes = plt.subplots(2, 4, figsize=(16, 8))
    fig.suptitle(f'Fast Precise Sea Cleanup Detection', fontsize=14, fontweight='bold')

    # ç¬¬ä¸€è¡Œï¼šè¾“å…¥å’Œä¸­é—´ç»“æœ
    axes[0, 0].imshow(result['original_image'])
    axes[0, 0].set_title('Original Image')
    axes[0, 0].axis('off')

    axes[0, 1].imshow(result['processed_image'])
    axes[0, 1].set_title('Processed (400x400)')
    axes[0, 1].axis('off')

    if result['ground_truth'] is not None:
        axes[0, 2].imshow(result['ground_truth'], cmap='Reds')
        gt_pixels = np.sum(result['ground_truth'] > 0.5)
        axes[0, 2].set_title(f'Ground Truth\n({gt_pixels:,} pixels)')
    else:
        axes[0, 2].set_title('Ground Truth\n(Not Available)')
    axes[0, 2].axis('off')

    axes[0, 3].imshow(result['raw_coastline'], cmap='hot')
    raw_pixels = np.sum(result['raw_coastline'] > 0.3)
    axes[0, 3].set_title(f'Raw DQN Result\n({raw_pixels:,} pixels)')
    axes[0, 3].axis('off')

    # ç¬¬äºŒè¡Œï¼šæœ€ç»ˆç»“æœå’Œåˆ†æ
    axes[1, 0].imshow(result['final_coastline'], cmap='hot')
    final_pixels = result['metrics']['pixel_count']
    axes[1, 0].set_title(f'Final Result\n({final_pixels:,} pixels)', color='red', fontweight='bold')
    axes[1, 0].axis('off')

    # æ”¹è¿›å¯¹æ¯”
    if result['raw_coastline'] is not None:
        improvement = (result['raw_coastline'] > 0.3).astype(float) - (result['final_coastline'] > 0.5).astype(float)
        axes[1, 1].imshow(improvement, cmap='RdBu', vmin=-1, vmax=1)
        improved_pixels = np.abs(np.sum(improvement))
        axes[1, 1].set_title(f'Improvement\n({improved_pixels:,} pixels changed)')
        axes[1, 1].axis('off')

    # è¿é€šæ€§åˆ†æ
    labeled_array, num_components = label(result['final_coastline'] > 0.5)
    axes[1, 2].imshow(labeled_array, cmap='tab20')
    axes[1, 2].set_title(f'Components\n({num_components} total)')
    axes[1, 2].axis('off')

    # æŒ‡æ ‡æ˜¾ç¤º
    axes[1, 3].axis('off')
    metrics = result['metrics']

    metrics_text = f"""Key Metrics:

IoU: {metrics['iou']:.3f}
Precision: {metrics['precision']:.3f}
Recall: {metrics['recall']:.3f}
F1-Score: {metrics['f1_score']:.3f}
Pixel Acc: {metrics['pixel_accuracy']:.3f}

Components: {metrics['components']}
Pixels: {metrics['pixel_count']:,}

Time:
Train: {metrics['training_time_min']:.1f}min
Infer: {metrics['inference_time_ms']:.0f}ms

Status: {"âœ… SUCCESS" if result['success'] else "âŒ NEEDS WORK"}"""

    axes[1, 3].text(0.05, 0.95, metrics_text, transform=axes[1, 3].transAxes,
                    fontsize=9, verticalalignment='top', fontfamily='monospace',
                    bbox=dict(boxstyle="round,pad=0.3", facecolor="lightblue", alpha=0.8))

    plt.tight_layout()
    plt.savefig(save_path, dpi=300, bbox_inches='tight', facecolor='white')
    plt.close()

    print(f"âœ… å¿«é€Ÿå¯è§†åŒ–å·²ä¿å­˜: {save_path}")


# ==================== æ¼”ç¤ºå‡½æ•° ====================

def create_demo_image():
    """åˆ›å»ºæ¼”ç¤ºæµ·å²¸çº¿å›¾åƒ"""
    print("ğŸ¨ åˆ›å»ºæ¼”ç¤ºå›¾åƒ...")

    img = np.zeros((400, 400, 3), dtype=np.uint8)
    img[:, :] = [20, 100, 200]  # è“è‰²èƒŒæ™¯

    # åˆ›å»ºä¸»æµ·å²¸çº¿ï¼ˆä¸“æ³¨ä¸­é—´åŒºåŸŸï¼‰
    for y in range(400):
        if 120 <= y <= 280:  # ä¸»è¦åœ¨ä¸­é—´åŒºåŸŸ
            main_x = int(200 + 60 * np.sin(y * 0.02) + 20 * np.sin(y * 0.08))
        else:
            main_x = int(200 + 30 * np.sin(y * 0.01))

        main_x = max(50, min(350, main_x))
        img[y, main_x:] = [100, 180, 50]  # ç»¿è‰²é™†åœ°

        # æµ·å²¸çº¿è¿‡æ¸¡
        for offset in range(-4, 5):
            x = main_x + offset
            if 0 <= x < 400:
                mix_ratio = (4 - abs(offset)) / 4.0
                img[y, x] = [
                    int(20 + (100 - 20) * mix_ratio),
                    int(100 + (180 - 100) * mix_ratio),
                    int(200 + (50 - 200) * mix_ratio)
                ]

    # åˆ›å»ºå¯¹åº”çš„GT
    gt = np.zeros((400, 400), dtype=np.uint8)
    for y in range(400):
        if 120 <= y <= 280:
            main_x = int(200 + 60 * np.sin(y * 0.02) + 20 * np.sin(y * 0.08))
        else:
            main_x = int(200 + 30 * np.sin(y * 0.01))

        main_x = max(50, min(350, main_x))

        # GTæµ·å²¸çº¿
        for offset in range(-1, 2):
            x = main_x + offset
            if 0 <= x < 400:
                gt[y, x] = 255

    return img, gt


# ==================== æµ‹è¯•å‡½æ•° ====================

def test_fast_sea_cleanup():
    """æµ‹è¯•å¿«é€Ÿæµ·åŸŸæ¸…ç†ç³»ç»Ÿ"""
    print("ğŸ§ª æµ‹è¯•å¿«é€Ÿæµ·åŸŸæ¸…ç†ç³»ç»Ÿ...")

    detector = FastPreciseSeaCleanupDetector()

    # å°è¯•ä½¿ç”¨çœŸå®æ•°æ®
    initial_dir = "E:/initial"
    ground_truth_dir = "E:/ground"

    if os.path.exists(initial_dir):
        files = [f for f in os.listdir(initial_dir) if f.lower().endswith(('.pdf', '.png', '.jpg', '.jpeg'))]
        if files:
            test_file = files[0]
            initial_path = os.path.join(initial_dir, test_file)

            # æŸ¥æ‰¾GTæ–‡ä»¶
            gt_path = None
            if os.path.exists(ground_truth_dir):
                gt_files = [f for f in os.listdir(ground_truth_dir) if
                            f.lower().endswith(('.pdf', '.png', '.jpg', '.jpeg'))]
                if gt_files:
                    gt_path = os.path.join(ground_truth_dir, gt_files[0])

            print(f"\nğŸ§ª æµ‹è¯•çœŸå®æ•°æ®: {test_file}")
            result = detector.process_image(initial_path, gt_path)

            if result:
                # ä¿å­˜ç»“æœ
                output_dir = "./fast_cleanup_results"
                os.makedirs(output_dir, exist_ok=True)
                save_path = os.path.join(output_dir, 'fast_sea_cleanup_real.png')
                create_fast_visualization(result, save_path)
                return result

    # ä½¿ç”¨æ¼”ç¤ºæ•°æ®
    print("\nğŸ¨ ä½¿ç”¨æ¼”ç¤ºæ•°æ®æµ‹è¯•...")
    demo_img, demo_gt = create_demo_image()

    os.makedirs("./temp", exist_ok=True)
    demo_img_path = "./temp/demo_fast.png"
    demo_gt_path = "./temp/demo_gt_fast.png"

    Image.fromarray(demo_img).save(demo_img_path)
    Image.fromarray(demo_gt).save(demo_gt_path)

    result = detector.process_image(demo_img_path, demo_gt_path)
    if result:
        # ä¿å­˜ç»“æœ
        output_dir = "./fast_cleanup_results"
        os.makedirs(output_dir, exist_ok=True)
        save_path = os.path.join(output_dir, 'fast_sea_cleanup_demo.png')
        create_fast_visualization(result, save_path)
        return result

    return None


# ==================== IoUæ”¹è¿›å»ºè®® ====================

def analyze_and_improve_iou(result):
    """åˆ†æå¹¶ç»™å‡ºIoUæ”¹è¿›å»ºè®®"""
    if result is None:
        return

    metrics = result['metrics']
    print(f"\nğŸ” IoUåˆ†æå’Œæ”¹è¿›å»ºè®®:")
    print("=" * 60)

    iou = metrics['iou']
    precision = metrics['precision']
    recall = metrics['recall']
    pixel_acc = metrics['pixel_accuracy']

    print(f"å½“å‰IoU: {iou:.3f}")

    if iou < 0.5:
        print("âŒ IoUè¾ƒä½ï¼Œä¸»è¦é—®é¢˜å¯èƒ½æ˜¯:")
        if precision < 0.6:
            print("   â€¢ ç²¾åº¦ä½ -> å­˜åœ¨è¿‡å¤šè¯¯æ£€ï¼Œéœ€è¦æ›´ä¸¥æ ¼çš„é˜ˆå€¼")
        if recall < 0.6:
            print("   â€¢ å¬å›ç‡ä½ -> æ¼æ£€è¿‡å¤šï¼Œéœ€è¦æ›´å®½æ¾çš„æ£€æµ‹")
        if abs(precision - recall) > 0.2:
            print("   â€¢ ç²¾åº¦å¬å›ä¸å¹³è¡¡ -> éœ€è¦è°ƒæ•´æ£€æµ‹ç­–ç•¥")
    elif iou < 0.7:
        print("âš ï¸ IoUä¸­ç­‰ï¼Œè¿˜æœ‰æ”¹è¿›ç©ºé—´:")
        print("   â€¢ å¯ä»¥å°è¯•è¾¹ç•Œç»†åŒ–")
        print("   â€¢ è°ƒæ•´å½¢æ€å­¦æ“ä½œå‚æ•°")
        print("   â€¢ ä¼˜åŒ–GTå¯¹é½ç­–ç•¥")
    else:
        print("âœ… IoUè‰¯å¥½!")

    if pixel_acc > 0.9 and iou < 0.7:
        print("\nğŸ’¡ åƒç´ ç²¾åº¦é«˜ä½†IoUä¸é«˜çš„åŸå› :")
        print("   â€¢ èƒŒæ™¯åƒç´ å ä¸»å¯¼åœ°ä½")
        print("   â€¢ è¾¹ç•Œå®šä½ä¸å¤Ÿç²¾ç¡®")
        print("   â€¢ å»ºè®®å…³æ³¨è¾¹ç•Œè´¨é‡è€Œéæ•´ä½“ç²¾åº¦")

    print("\nğŸ› ï¸ å…·ä½“æ”¹è¿›å»ºè®®:")
    print("1. è°ƒæ•´äºŒå€¼åŒ–é˜ˆå€¼")
    print("2. å¢å¼ºGTå¯¹é½æœºåˆ¶")
    print("3. ä¼˜åŒ–å½¢æ€å­¦åå¤„ç†")
    print("4. å®æ–½è¾¹ç•Œåƒç´ çº§ä¼˜åŒ–")
    print("5. å¢åŠ è¾¹ç•Œèšç„¦çš„è®­ç»ƒæ ·æœ¬")


# ==================== ä¸»å‡½æ•° ====================

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ å¯åŠ¨å¿«é€Ÿç²¾å‡†æµ·åŸŸæ¸…ç†ç³»ç»Ÿ...")
    print("ğŸ¯ ç›®æ ‡ï¼šå¿«é€Ÿè®­ç»ƒ + é‡ç‚¹å…³æ³¨æœ€ç»ˆIoU/Precisionç­‰æŒ‡æ ‡")
    print("âš¡ ç‰¹ç‚¹ï¼šå¤§å¹…ç®€åŒ–è®­ç»ƒè¿‡ç¨‹ï¼Œä¸“æ³¨åå¤„ç†ä¼˜åŒ–")

    start_time = time.time()

    # è¿è¡Œæµ‹è¯•
    result = test_fast_sea_cleanup()

    total_time = time.time() - start_time

    if result:
        metrics = result['metrics']

        print(f"\nğŸ‰ å¿«é€Ÿå¤„ç†å®Œæˆ! (æ€»è€—æ—¶: {total_time:.1f}ç§’)")
        print("=" * 60)
        print("ğŸ“Š æœ€ç»ˆæŒ‡æ ‡æ€»ç»“:")
        print(f"   ğŸ¯ IoU: {metrics['iou']:.3f}")
        print(f"   ğŸ¯ Precision: {metrics['precision']:.3f}")
        print(f"   ğŸ¯ Recall: {metrics['recall']:.3f}")
        print(f"   ğŸ¯ Pixel Accuracy: {metrics['pixel_accuracy']:.3f}")
        print(f"   ğŸ¯ F1-Score: {metrics['f1_score']:.3f}")
        print(f"   ğŸ”¢ Components: {metrics['components']}")
        print(f"   ğŸ”¢ Pixel Count: {metrics['pixel_count']:,}")
        print(f"   âš¡ Training Speed: {metrics['training_time_min']:.1f} min")
        print(f"   âš¡ Inference Speed: {metrics['inference_time_ms']:.1f} ms")

        # æˆåŠŸåˆ¤æ–­
        if result['success']:
            print(f"\nâœ… ç³»ç»Ÿè¿è¡ŒæˆåŠŸ!")
            if metrics['iou'] > 0.7:
                print("ğŸ† IoUè¡¨ç°ä¼˜ç§€!")
            elif metrics['iou'] > 0.6:
                print("ğŸ‘ IoUè¡¨ç°è‰¯å¥½!")
        else:
            print(f"\nâš ï¸ ç³»ç»Ÿå®Œæˆè¿è¡Œï¼Œä½†æŒ‡æ ‡éœ€è¦æ”¹è¿›")

        print("=" * 60)

        # IoUåˆ†æå’Œæ”¹è¿›å»ºè®®
        analyze_and_improve_iou(result)

    else:
        print("âŒ å¿«é€Ÿæµ‹è¯•å¤±è´¥")

    print(f"\nâ±ï¸ æ€»è¿è¡Œæ—¶é—´: {total_time:.1f} ç§’")


if __name__ == "__main__":
    main()
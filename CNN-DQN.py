print("ğŸ”§ æ”¹è¿›çš„æµ·å²¸çº¿æ£€æµ‹ç³»ç»Ÿ - ä¿®å¤å­—ç¬¦å’Œæå‡æ£€æµ‹æ•ˆæœ")
print("=" * 70)

import os
import numpy as np
import torch
import torch.nn as nn
from PIL import Image
import fitz
from scipy import ndimage
import matplotlib.pyplot as plt
import matplotlib
from collections import deque
import random

# ä¿®å¤ä¸­æ–‡å­—ä½“é—®é¢˜
plt.rcParams['font.sans-serif'] = ['DejaVu Sans', 'Arial', 'SimHei']
plt.rcParams['axes.unicode_minus'] = False


class ImprovedCoastalSystem:
    """æ”¹è¿›çš„æµ·å²¸çº¿æ£€æµ‹ç³»ç»Ÿ"""

    def __init__(self):
        # ç®€å•çš„ç½‘ç»œï¼ˆé¿å…è¿‡åº¦å¤æ‚ï¼‰
        self.param_ranges = {
            'white_threshold_low': (0.6, 0.85),  # ç™½è‰²æ£€æµ‹ä¸‹é™
            'white_threshold_high': (0.85, 0.98),  # ç™½è‰²æ£€æµ‹ä¸Šé™
            'tolerance': (0.02, 0.15),  # å®¹å¿åº¦
            'morphology_size': (1, 4),  # å½¢æ€å­¦å¤§å°
            'connectivity_min': (5, 30),  # æœ€å°è¿é€šåŒºåŸŸ
            'edge_enhance': (0.5, 2.5),  # è¾¹ç¼˜å¢å¼º
            'blur_factor': (0.0, 1.5)  # æ¨¡ç³Šå› å­
        }

        print("âœ… æ”¹è¿›ç³»ç»Ÿåˆå§‹åŒ–å®Œæˆ")

    def enhanced_white_detection(self, image, params=None):
        """æ”¹è¿›çš„ç™½è‰²æ£€æµ‹ç®—æ³•"""

        if params is None:
            params = {
                'white_threshold_low': 0.75,
                'white_threshold_high': 0.92,
                'tolerance': 0.08,
                'morphology_size': 2,
                'connectivity_min': 10,
                'edge_enhance': 1.2,
                'blur_factor': 0.3
            }

        print(f"ğŸ”§ ä½¿ç”¨æ£€æµ‹å‚æ•°:")
        for key, value in params.items():
            print(f"   {key}: {value:.3f}")

        # ç¡®ä¿å›¾åƒæ˜¯RGBæ ¼å¼
        if len(image.shape) == 3:
            rgb_image = image.copy()
            if rgb_image.max() <= 1.0:
                rgb_image = (rgb_image * 255).astype(np.uint8)
        else:
            gray = image.copy()
            if gray.max() <= 1.0:
                gray = (gray * 255).astype(np.uint8)
            rgb_image = np.stack([gray, gray, gray], axis=2)

        r, g, b = rgb_image[:, :, 0], rgb_image[:, :, 1], rgb_image[:, :, 2]

        # å¤šç­–ç•¥ç™½è‰²æ£€æµ‹
        strategies = {}

        # ç­–ç•¥1: ä¸¥æ ¼ç™½è‰²æ£€æµ‹
        white_high = int(params['white_threshold_high'] * 255)
        white_low = int(params['white_threshold_low'] * 255)

        strategies['strict'] = (r >= white_high) & (g >= white_high) & (b >= white_high)

        # ç­–ç•¥2: èŒƒå›´ç™½è‰²æ£€æµ‹
        tolerance = int(params['tolerance'] * 255)
        strategies['range'] = (
                (r >= white_low) & (g >= white_low) & (b >= white_low) &
                (np.abs(r.astype(int) - g.astype(int)) <= tolerance) &
                (np.abs(g.astype(int) - b.astype(int)) <= tolerance) &
                (np.abs(r.astype(int) - b.astype(int)) <= tolerance)
        )

        # ç­–ç•¥3: äº®åº¦æ£€æµ‹
        brightness = (r.astype(float) + g.astype(float) + b.astype(float)) / 3
        strategies['brightness'] = brightness >= (white_low + white_high) / 2

        # ç­–ç•¥4: ç›¸å¯¹äº®åº¦æ£€æµ‹ï¼ˆæ¯”å‘¨å›´äº®ï¼‰
        brightness_blur = ndimage.gaussian_filter(brightness, sigma=3)
        strategies['relative'] = (brightness - brightness_blur) > 20

        # ç»„åˆæ‰€æœ‰ç­–ç•¥
        white_mask = np.zeros_like(r, dtype=bool)
        for name, mask in strategies.items():
            white_mask |= mask
            pixels = np.sum(mask)
            print(f"   ç­–ç•¥ {name}: æ£€æµ‹åˆ° {pixels} ä¸ªç™½è‰²åƒç´ ")

        total_white = np.sum(white_mask)
        print(f"ğŸ¯ ç»„åˆæ£€æµ‹: {total_white} ä¸ªç™½è‰²åƒç´  ({total_white / white_mask.size * 100:.2f}%)")

        # å½¢æ€å­¦å¤„ç†
        morph_size = max(1, int(params['morphology_size']))
        if morph_size > 1:
            from scipy.ndimage import binary_closing, binary_opening, binary_dilation

            # ç»“æ„å…ƒç´ 
            kernel = np.ones((morph_size, morph_size), bool)

            # å…ˆè†¨èƒ€è¿æ¥æ–­è£‚ï¼Œå†è…èš€å»å™ªå£°
            white_mask = binary_dilation(white_mask, structure=kernel, iterations=1)
            white_mask = binary_closing(white_mask, structure=kernel, iterations=1)
            white_mask = binary_opening(white_mask, structure=kernel, iterations=1)

        # è¿é€šåŒºåŸŸè¿‡æ»¤
        min_size = int(params['connectivity_min'])
        if min_size > 0:
            from scipy.ndimage import label
            labeled, num_features = label(white_mask)

            filtered_mask = np.zeros_like(white_mask)
            for i in range(1, num_features + 1):
                component = (labeled == i)
                if np.sum(component) >= min_size:
                    filtered_mask |= component

            removed = total_white - np.sum(filtered_mask)
            white_mask = filtered_mask
            print(f"ğŸ” è¿é€šæ€§è¿‡æ»¤: ç§»é™¤ {removed} ä¸ªå™ªå£°åƒç´ ")

        # è¾¹ç¼˜å¢å¼º
        edge_factor = params.get('edge_enhance', 1.0)
        if edge_factor != 1.0:
            # è®¡ç®—è¾¹ç¼˜
            grad_x = np.abs(ndimage.sobel(white_mask.astype(float), axis=1))
            grad_y = np.abs(ndimage.sobel(white_mask.astype(float), axis=0))
            edges = grad_x + grad_y

            # å¢å¼ºè¾¹ç¼˜åŒºåŸŸ
            enhanced = white_mask.astype(float) + (edge_factor - 1.0) * edges
            white_mask = enhanced > 0.5

        # è½»å¾®æ¨¡ç³Šå¹³æ»‘
        blur_sigma = params.get('blur_factor', 0)
        if blur_sigma > 0:
            white_mask_float = ndimage.gaussian_filter(white_mask.astype(float), sigma=blur_sigma)
            white_mask = white_mask_float > 0.3  # é™ä½é˜ˆå€¼ä¿ç•™æ›´å¤šç»†èŠ‚

        final_pixels = np.sum(white_mask)
        print(f"âœ… æœ€ç»ˆæ£€æµ‹: {final_pixels} ä¸ªæµ·å²¸çº¿åƒç´ ")

        return white_mask.astype(float), strategies, {
            'rgb_image': rgb_image,
            'total_white_pixels': final_pixels,
            'detection_ratio': final_pixels / white_mask.size
        }

    def smart_parameter_adjustment(self, image, initial_params, max_iterations=5):
        """æ™ºèƒ½å‚æ•°è°ƒæ•´"""

        best_params = initial_params.copy()
        best_score = 0
        best_result = None

        print(f"ğŸ¯ å¼€å§‹æ™ºèƒ½å‚æ•°è°ƒæ•´ (æœ€å¤š{max_iterations}æ¬¡è¿­ä»£)...")

        for iteration in range(max_iterations):
            print(f"\n  è¿­ä»£ {iteration + 1}:")

            # æµ‹è¯•å½“å‰å‚æ•°
            result, strategies, info = self.enhanced_white_detection(image, best_params)

            # è®¡ç®—å¾—åˆ†ï¼ˆåŸºäºæ£€æµ‹åˆ°çš„åƒç´ æ•°é‡å’Œåˆ†å¸ƒï¼‰
            pixel_count = info['total_white_pixels']
            ratio = info['detection_ratio']

            # ç†æƒ³çš„æµ·å²¸çº¿åƒç´ æ¯”ä¾‹åº”è¯¥åœ¨0.5%-5%ä¹‹é—´
            if 0.005 <= ratio <= 0.05:
                ratio_score = 1.0
            elif 0.001 <= ratio <= 0.1:
                ratio_score = 0.5
            else:
                ratio_score = 0.1

            # è¿é€šæ€§å¾—åˆ†ï¼ˆæ›´å°‘ä½†æ›´å¤§çš„è¿é€šåŒºåŸŸæ›´å¥½ï¼‰
            from scipy.ndimage import label
            labeled, num_components = label(result > 0.5)
            if num_components > 0:
                avg_component_size = pixel_count / num_components
                connectivity_score = min(1.0, avg_component_size / 50.0)
            else:
                connectivity_score = 0.0

            # ç»¼åˆå¾—åˆ†
            current_score = ratio_score * 0.6 + connectivity_score * 0.4

            print(f"    åƒç´ æ•°: {pixel_count}, æ¯”ä¾‹: {ratio:.3%}")
            print(f"    è¿é€šåŒºåŸŸ: {num_components}, å¹³å‡å¤§å°: {avg_component_size:.1f}")
            print(f"    å¾—åˆ†: {current_score:.3f}")

            if current_score > best_score:
                best_score = current_score
                best_params = best_params.copy()
                best_result = result
                print(f"    âœ… æ›´æ–°æœ€ä½³å‚æ•° (å¾—åˆ†: {best_score:.3f})")
            else:
                print(f"    âš ï¸ æœªæ”¹è¿› (æœ€ä½³å¾—åˆ†: {best_score:.3f})")

            # å¦‚æœå¾—åˆ†å·²ç»å¾ˆå¥½ï¼Œæå‰åœæ­¢
            if best_score > 0.8:
                print(f"    ğŸ‰ è¾¾åˆ°æ»¡æ„æ•ˆæœï¼Œæå‰åœæ­¢")
                break

            # è°ƒæ•´å‚æ•°è¿›è¡Œä¸‹ä¸€æ¬¡å°è¯•
            if iteration < max_iterations - 1:
                # æ ¹æ®å½“å‰ç»“æœè°ƒæ•´å‚æ•°
                if pixel_count < 100:  # æ£€æµ‹å¤ªå°‘ï¼Œé™ä½é˜ˆå€¼
                    best_params['white_threshold_low'] = max(0.6, best_params['white_threshold_low'] - 0.05)
                    best_params['tolerance'] = min(0.15, best_params['tolerance'] + 0.02)
                elif pixel_count > 5000:  # æ£€æµ‹å¤ªå¤šï¼Œæé«˜é˜ˆå€¼
                    best_params['white_threshold_high'] = min(0.98, best_params['white_threshold_high'] + 0.02)
                    best_params['tolerance'] = max(0.02, best_params['tolerance'] - 0.01)

                if num_components > 20:  # å¤ªå¤šç¢ç‰‡ï¼Œå¢åŠ è¿é€šæ€§è¦æ±‚
                    best_params['connectivity_min'] = min(30, best_params['connectivity_min'] + 5)
                    best_params['morphology_size'] = min(4, best_params['morphology_size'] + 0.5)

        print(f"\nğŸ† å‚æ•°è°ƒæ•´å®Œæˆï¼Œæœ€ä½³å¾—åˆ†: {best_score:.3f}")
        return best_params, best_result, best_score

    def process_image(self, image_path):
        """å¤„ç†å•å¼ å›¾åƒ"""
        print(f"\nğŸ–¼ï¸ å¤„ç†å›¾åƒ: {os.path.basename(image_path)}")

        try:
            # åŠ è½½å›¾åƒ
            doc = fitz.open(image_path)
            page = doc.load_page(0)
            zoom = 300 / 72  # æé«˜åˆ†è¾¨ç‡
            mat = fitz.Matrix(zoom, zoom)
            pix = page.get_pixmap(matrix=mat)
            img_data = pix.tobytes("png")

            from io import BytesIO
            img = Image.open(BytesIO(img_data))
            original_img = np.array(img)
            doc.close()

            # é¢„å¤„ç†
            processed_img = self.preprocess_image(original_img, (512, 512))

            # åˆå§‹å‚æ•°
            initial_params = {
                'white_threshold_low': 0.72,
                'white_threshold_high': 0.90,
                'tolerance': 0.1,
                'morphology_size': 2,
                'connectivity_min': 15,
                'edge_enhance': 1.5,
                'blur_factor': 0.5
            }

            # æ™ºèƒ½å‚æ•°è°ƒæ•´
            best_params, best_result, score = self.smart_parameter_adjustment(
                processed_img, initial_params, max_iterations=3
            )

            return {
                'original_image': original_img,
                'processed_image': processed_img,
                'initial_params': initial_params,
                'best_params': best_params,
                'coastline_result': best_result,
                'quality_score': score,
                'success': score > 0.3
            }

        except Exception as e:
            print(f"âŒ å¤„ç†å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return None

    def preprocess_image(self, image, target_size):
        """å›¾åƒé¢„å¤„ç†"""
        if isinstance(image, np.ndarray):
            pil_img = Image.fromarray(image.astype(np.uint8))
        else:
            pil_img = image

        resized = pil_img.resize(target_size, Image.Resampling.LANCZOS)
        return np.array(resized)


def create_improved_visualization(result, year, save_path):
    """åˆ›å»ºæ”¹è¿›çš„å¯è§†åŒ–ï¼ˆä¿®å¤ä¸­æ–‡æ˜¾ç¤ºï¼‰"""

    fig, axes = plt.subplots(3, 4, figsize=(20, 15))

    # ä½¿ç”¨è‹±æ–‡æ ‡é¢˜é¿å…å­—ç¬¦é—®é¢˜
    fig.suptitle(f'Improved Coastline Detection - {year}', fontsize=20, fontweight='bold')

    # ç¬¬ä¸€è¡Œï¼šåŸå§‹æ•°æ®å’Œç»“æœ
    axes[0, 0].imshow(result['original_image'])
    axes[0, 0].set_title('Original Image', fontsize=14)
    axes[0, 0].axis('off')

    axes[0, 1].imshow(result['processed_image'])
    axes[0, 1].set_title('Processed Image', fontsize=14)
    axes[0, 1].axis('off')

    axes[0, 2].imshow(result['coastline_result'], cmap='hot', vmin=0, vmax=1)
    axes[0, 2].set_title('Coastline Detection', fontsize=14, color='red', fontweight='bold')
    axes[0, 2].axis('off')

    # å åŠ ç»“æœ
    overlay = result['processed_image'].copy()
    if len(overlay.shape) == 3:
        overlay[:, :, 0] = np.maximum(overlay[:, :, 0], result['coastline_result'] * 255)
    else:
        overlay = np.stack([overlay] * 3, axis=2)
        overlay[:, :, 0] = np.maximum(overlay[:, :, 0], result['coastline_result'] * 255)

    axes[0, 3].imshow(overlay)
    axes[0, 3].set_title('Overlay Result', fontsize=14)
    axes[0, 3].axis('off')

    # ç¬¬äºŒè¡Œï¼šå‚æ•°å¯¹æ¯”
    axes[1, 0].axis('off')
    initial_text = "Initial Parameters:\n\n"
    for key, value in result['initial_params'].items():
        initial_text += f"{key}:\n  {value:.3f}\n"
    axes[1, 0].text(0.05, 0.95, initial_text, transform=axes[1, 0].transAxes,
                    fontsize=9, verticalalignment='top', fontfamily='monospace',
                    bbox=dict(boxstyle="round,pad=0.5", facecolor="lightblue"))
    axes[1, 0].set_title('Initial Parameters', fontsize=14)

    axes[1, 1].axis('off')
    best_text = "Optimized Parameters:\n\n"
    for key, value in result['best_params'].items():
        best_text += f"{key}:\n  {value:.3f}\n"
    axes[1, 1].text(0.05, 0.95, best_text, transform=axes[1, 1].transAxes,
                    fontsize=9, verticalalignment='top', fontfamily='monospace',
                    bbox=dict(boxstyle="round,pad=0.5", facecolor="lightgreen"))
    axes[1, 1].set_title('Optimized Parameters', fontsize=14)

    # å‚æ•°å˜åŒ–å¯¹æ¯”
    param_names = list(result['initial_params'].keys())
    initial_values = [result['initial_params'][p] for p in param_names]
    best_values = [result['best_params'][p] for p in param_names]

    x_pos = np.arange(len(param_names))
    width = 0.35

    axes[1, 2].bar(x_pos - width / 2, initial_values, width, label='Initial', alpha=0.7, color='blue')
    axes[1, 2].bar(x_pos + width / 2, best_values, width, label='Optimized', alpha=0.7, color='green')
    axes[1, 2].set_xlabel('Parameters')
    axes[1, 2].set_ylabel('Values')
    axes[1, 2].set_title('Parameter Comparison')
    axes[1, 2].set_xticks(x_pos)
    axes[1, 2].set_xticklabels([p.replace('_', '\n') for p in param_names], fontsize=8, rotation=45)
    axes[1, 2].legend()
    axes[1, 2].grid(True, alpha=0.3)

    # è´¨é‡å¾—åˆ†
    axes[1, 3].axis('off')
    score_text = f"""Quality Assessment:

Quality Score: {result['quality_score']:.3f}

Detection Status: {"SUCCESS" if result['success'] else "NEEDS IMPROVEMENT"}

Coastline Pixels: {np.sum(result['coastline_result'] > 0.5):,}

Coverage Ratio: {np.mean(result['coastline_result'] > 0.5) * 100:.2f}%

Assessment: """

    if result['quality_score'] > 0.7:
        assessment = "EXCELLENT"
        color = "green"
    elif result['quality_score'] > 0.4:
        assessment = "GOOD"
        color = "orange"
    else:
        assessment = "POOR"
        color = "red"

    score_text += assessment

    axes[1, 3].text(0.1, 0.9, score_text, transform=axes[1, 3].transAxes,
                    fontsize=12, verticalalignment='top', fontfamily='monospace',
                    bbox=dict(boxstyle="round,pad=0.5", facecolor="lightyellow"))
    axes[1, 3].set_title('Quality Assessment', fontsize=14)

    # ç¬¬ä¸‰è¡Œï¼šç»Ÿè®¡åˆ†æ
    # åƒç´ åˆ†å¸ƒ
    axes[2, 0].hist(result['coastline_result'].flatten(), bins=50, alpha=0.7, color='red')
    axes[2, 0].set_title('Pixel Distribution')
    axes[2, 0].set_xlabel('Pixel Values')
    axes[2, 0].set_ylabel('Frequency')
    axes[2, 0].grid(True, alpha=0.3)

    # äºŒå€¼åŒ–ç»“æœ
    binary_result = result['coastline_result'] > 0.5
    coastline_pixels = np.sum(binary_result)
    background_pixels = np.sum(~binary_result)

    axes[2, 1].pie([coastline_pixels, background_pixels],
                   labels=['Coastline', 'Background'],
                   autopct='%1.1f%%',
                   colors=['red', 'lightblue'])
    axes[2, 1].set_title('Pixel Ratio')

    # è¿é€šåŒºåŸŸåˆ†æ
    from scipy.ndimage import label
    labeled, num_components = label(binary_result)

    if num_components > 0:
        component_sizes = []
        for i in range(1, num_components + 1):
            size = np.sum(labeled == i)
            component_sizes.append(size)

        axes[2, 2].hist(component_sizes, bins=min(20, num_components), alpha=0.7, color='green')
        axes[2, 2].set_title(f'Component Sizes (n={num_components})')
        axes[2, 2].set_xlabel('Component Size')
        axes[2, 2].set_ylabel('Count')
        axes[2, 2].grid(True, alpha=0.3)
    else:
        axes[2, 2].text(0.5, 0.5, 'No Components\nDetected', ha='center', va='center')
        axes[2, 2].set_title('Component Analysis')

    # æ”¹è¿›æ€»ç»“
    axes[2, 3].axis('off')
    summary_text = f"""Improvement Summary:

System Features:
â€¢ Multi-strategy detection
â€¢ Smart parameter tuning  
â€¢ Connectivity filtering
â€¢ Edge enhancement
â€¢ Morphological processing

Detection Results:
â€¢ Components: {num_components}
â€¢ Total pixels: {coastline_pixels:,}
â€¢ Avg component: {coastline_pixels / max(1, num_components):.1f}

Quality Score: {result['quality_score']:.3f}/1.0
Status: {assessment}"""

    axes[2, 3].text(0.05, 0.95, summary_text, transform=axes[2, 3].transAxes,
                    fontsize=10, verticalalignment='top', fontfamily='monospace',
                    bbox=dict(boxstyle="round,pad=0.5", facecolor="lavender"))
    axes[2, 3].set_title('System Summary', fontsize=14)

    plt.tight_layout()
    plt.savefig(save_path, dpi=300, bbox_inches='tight', facecolor='white')
    plt.close()

    print(f"âœ… æ”¹è¿›ç‰ˆå¯è§†åŒ–å·²ä¿å­˜: {save_path}")


def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ å¯åŠ¨æ”¹è¿›ç‰ˆæµ·å²¸çº¿æ£€æµ‹ç³»ç»Ÿ...")

    # åˆå§‹åŒ–ç³»ç»Ÿ
    system = ImprovedCoastalSystem()

    # æ£€æŸ¥æ•°æ®
    initial_dir = "E:/initial"
    initial_files = [f for f in os.listdir(initial_dir) if f.endswith('.pdf')]

    print(f"ğŸ“ æ‰¾åˆ° {len(initial_files)} ä¸ªæµ‹è¯•æ–‡ä»¶")

    # åˆ›å»ºè¾“å‡ºç›®å½•
    output_dir = "./improved_coastline_results"
    os.makedirs(output_dir, exist_ok=True)

    # å¤„ç†å‰å‡ ä¸ªæ ·æœ¬
    for i, pdf_file in enumerate(initial_files[:3]):
        print(f"\n{'=' * 60}")
        print(f"å¤„ç†æ ·æœ¬ {i + 1}/{min(3, len(initial_files))}: {pdf_file}")

        # æå–å¹´ä»½
        import re
        years = re.findall(r'20\d{2}', pdf_file)
        year = years[0] if years else f"sample_{i + 1}"

        # å¤„ç†å›¾åƒ
        pdf_path = os.path.join(initial_dir, pdf_file)
        result = system.process_image(pdf_path)

        if result is not None:
            # åˆ›å»ºå¯è§†åŒ–
            save_path = os.path.join(output_dir, f'improved_coastline_{year}.png')
            create_improved_visualization(result, year, save_path)

            print(f"âœ… æ ·æœ¬ {year} å¤„ç†å®Œæˆï¼Œè´¨é‡å¾—åˆ†: {result['quality_score']:.3f}")
        else:
            print(f"âŒ æ ·æœ¬ {year} å¤„ç†å¤±è´¥")

    print(f"\nğŸ‰ æ”¹è¿›ç‰ˆæ£€æµ‹å®Œæˆï¼")
    print(f"ğŸ“‚ ç»“æœä¿å­˜åœ¨: {output_dir}")
    print(f"ğŸ’¡ æ”¹è¿›ç‰ˆç‰¹ç‚¹:")
    print(f"   âœ… ä¿®å¤ä¸­æ–‡å­—ç¬¦æ˜¾ç¤ºé—®é¢˜")
    print(f"   âœ… å¤šç­–ç•¥ç™½è‰²æ£€æµ‹ç®—æ³•")
    print(f"   âœ… æ™ºèƒ½å‚æ•°è‡ªåŠ¨è°ƒæ•´")
    print(f"   âœ… æ›´å®Œæ•´çš„æµ·å²¸çº¿æ£€æµ‹")


if __name__ == "__main__":
    main()
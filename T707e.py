"""
æ”¹è¿›çš„è‹±å›½åŸå¸‚æµ·å²¸çº¿æ£€æµ‹ç³»ç»Ÿ
ä¸»è¦æ”¹è¿›ï¼š
1. å…¨å›¾æ£€æµ‹ï¼ˆè€Œéä»…ä¸­é—´1/3ï¼‰
2. è¾¹ç•Œæ„ŸçŸ¥DQNå¼•å¯¼
3. å‡æµ·å²¸çº¿è¿‡æ»¤
4. è¿é€šæ€§ç»„ä»¶åˆ†æ
5. NDWI/HSVå…‰è°±éªŒè¯
"""

import os
import numpy as np
from PIL import Image
import matplotlib.pyplot as plt
from scipy import ndimage
from scipy.ndimage import label, gaussian_filter, binary_dilation, binary_erosion, binary_closing
import random
from collections import deque, namedtuple
import math
from io import BytesIO
import colorsys

# PyTorch imports
import torch
import torch.nn as nn
import torch.optim as optim
import torch.nn.functional as F

# å¯é€‰ä¾èµ–æ£€æŸ¥
try:
    import fitz

    HAS_PDF_SUPPORT = True
except ImportError:
    HAS_PDF_SUPPORT = False

try:
    from skimage.morphology import skeletonize
    from skimage.filters import sobel

    HAS_SKIMAGE = True
except ImportError:
    HAS_SKIMAGE = False

# è®¾ç½®è®¾å¤‡å’Œéšæœºç§å­
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
torch.manual_seed(42)
np.random.seed(42)
random.seed(42)

print("ğŸ‡¬ğŸ‡§ æ”¹è¿›çš„è‹±å›½åŸå¸‚æµ·å²¸çº¿æ£€æµ‹ç³»ç»Ÿ!")
print("ä¸»è¦æ”¹è¿›ï¼šå…¨å›¾æ£€æµ‹ + è¾¹ç•Œæ„ŸçŸ¥ + å‡æµ·å²¸çº¿è¿‡æ»¤")
print("=" * 90)

Transition = namedtuple('Transition', ('state', 'action', 'next_state', 'reward'))


# ==================== æ”¹è¿›çš„å›¾åƒå¤„ç†å™¨ ====================

class ImprovedImageProcessor:
    """æ”¹è¿›çš„å›¾åƒå¤„ç†å™¨ï¼Œæ”¯æŒNDWIå’Œå¢å¼ºè¾¹ç¼˜æ£€æµ‹"""

    @staticmethod
    def rgb_to_gray(rgb_image):
        if len(rgb_image.shape) == 3:
            return np.dot(rgb_image[..., :3], [0.2989, 0.5870, 0.1140])
        return rgb_image

    @staticmethod
    def calculate_ndwi(rgb_image):
        """è®¡ç®—å½’ä¸€åŒ–å·®åˆ†æ°´æŒ‡æ•°(NDWI)"""
        if len(rgb_image.shape) != 3:
            return np.zeros_like(rgb_image)

        # æ¨¡æ‹Ÿç»¿å…‰å’Œè¿‘çº¢å¤–æ³¢æ®µ
        green = rgb_image[:, :, 1].astype(float)
        nir = rgb_image[:, :, 0].astype(float)  # ä½¿ç”¨çº¢è‰²é€šé“è¿‘ä¼¼è¿‘çº¢å¤–

        # é¿å…é™¤é›¶
        denominator = green + nir + 1e-8
        ndwi = (green - nir) / denominator

        return ndwi

    @staticmethod
    def enhanced_edge_detection(image):
        """å¢å¼ºçš„è¾¹ç¼˜æ£€æµ‹"""
        if len(image.shape) == 3:
            gray = ImprovedImageProcessor.rgb_to_gray(image)
        else:
            gray = image.copy()

        # Gaussianæ¨¡ç³Šé¢„å¤„ç†
        blurred = gaussian_filter(gray, sigma=1.0)

        # Sobelè¾¹ç¼˜æ£€æµ‹
        sobel_x = np.array([[-1, 0, 1], [-2, 0, 2], [-1, 0, 1]])
        sobel_y = np.array([[-1, -2, -1], [0, 0, 0], [1, 2, 1]])

        grad_x = ndimage.convolve(blurred, sobel_x)
        grad_y = ndimage.convolve(blurred, sobel_y)

        edge_magnitude = np.sqrt(grad_x ** 2 + grad_y ** 2)

        # å¦‚æœå¯ç”¨ï¼Œä½¿ç”¨Sobelæ»¤æ³¢å™¨
        if HAS_SKIMAGE:
            try:
                edge_skimage = sobel(blurred)
                edge_magnitude = np.maximum(edge_magnitude, edge_skimage * 255)
            except:
                pass

        # å½’ä¸€åŒ–
        if edge_magnitude.max() > edge_magnitude.min():
            edge_magnitude = (edge_magnitude - edge_magnitude.min()) / (edge_magnitude.max() - edge_magnitude.min())

        return edge_magnitude


# ==================== è¾¹ç•Œæ„ŸçŸ¥ç›‘ç£å™¨ ====================

class BoundaryAwareHSVSupervisor:
    """è¾¹ç•Œæ„ŸçŸ¥HSVç›‘ç£å™¨ - æ”¹è¿›ç‰ˆ"""

    def __init__(self):
        print("âœ… è¾¹ç•Œæ„ŸçŸ¥HSVç›‘ç£å™¨åˆå§‹åŒ–å®Œæˆ")
        self.water_hsv_range = self._define_water_hsv_range()
        self.land_hsv_range = self._define_land_hsv_range()
        self.processor = ImprovedImageProcessor()

    def _define_water_hsv_range(self):
        return {
            'hue_range': (180, 240),  # è“è‰²èŒƒå›´
            'saturation_min': 0.15,  # é™ä½é¥±å’Œåº¦é˜ˆå€¼
            'value_min': 0.05  # é™ä½äº®åº¦é˜ˆå€¼
        }

    def _define_land_hsv_range(self):
        return {
            'hue_range': (60, 120),  # ç»¿è‰²èŒƒå›´
            'saturation_min': 0.1,
            'value_min': 0.15
        }

    def analyze_image_hsv(self, rgb_image, gt_analysis=None):
        """åˆ†æå›¾åƒçš„HSVç‰¹å¾ï¼ˆæ”¹è¿›ç‰ˆï¼‰"""
        # è®¡ç®—HSV
        hsv_image = self._rgb_to_hsv(rgb_image)

        # è®¡ç®—NDWI
        ndwi = self.processor.calculate_ndwi(rgb_image)

        # å¢å¼ºè¾¹ç¼˜æ£€æµ‹
        edge_map = self.processor.enhanced_edge_detection(rgb_image)

        # æ°´åŸŸå’Œé™†åœ°æ£€æµ‹
        water_mask = self._enhanced_water_detection(hsv_image, ndwi)
        land_mask = self._enhanced_land_detection(hsv_image, ndwi)

        # è¾¹ç•Œç½®ä¿¡åº¦å›¾
        boundary_confidence = self._calculate_boundary_confidence(edge_map, water_mask, land_mask)

        # æµ·å²¸çº¿æŒ‡å¯¼å›¾
        coastline_guidance = self._generate_enhanced_coastline_guidance(
            water_mask, land_mask, boundary_confidence, edge_map
        )

        # è¿‡æ¸¡å¼ºåº¦
        transition_strength = self._calculate_enhanced_transition_strength(
            hsv_image, water_mask, land_mask, edge_map
        )

        return {
            'hsv_image': hsv_image,
            'ndwi': ndwi,
            'edge_map': edge_map,
            'water_mask': water_mask,
            'land_mask': land_mask,
            'boundary_confidence': boundary_confidence,
            'coastline_guidance': coastline_guidance,
            'transition_strength': transition_strength
        }

    def _rgb_to_hsv(self, rgb_image):
        """RGBè½¬HSV"""
        if len(rgb_image.shape) == 3:
            rgb_normalized = rgb_image.astype(float) / 255.0
            hsv_image = np.zeros_like(rgb_normalized)

            for i in range(rgb_image.shape[0]):
                for j in range(rgb_image.shape[1]):
                    r, g, b = rgb_normalized[i, j]
                    h, s, v = colorsys.rgb_to_hsv(r, g, b)
                    hsv_image[i, j] = [h * 360, s, v]
        else:
            hsv_image = np.stack([np.zeros_like(rgb_image),
                                  np.zeros_like(rgb_image),
                                  rgb_image / 255.0], axis=2)
        return hsv_image

    def _enhanced_water_detection(self, hsv_image, ndwi):
        """å¢å¼ºçš„æ°´åŸŸæ£€æµ‹ï¼Œç»“åˆHSVå’ŒNDWI"""
        h, s, v = hsv_image[:, :, 0], hsv_image[:, :, 1], hsv_image[:, :, 2]

        # HSVæ°´åŸŸæ£€æµ‹
        hue_mask = ((h >= self.water_hsv_range['hue_range'][0]) &
                    (h <= self.water_hsv_range['hue_range'][1]))
        saturation_mask = s >= self.water_hsv_range['saturation_min']
        value_mask = v >= self.water_hsv_range['value_min']

        hsv_water = hue_mask & saturation_mask & value_mask

        # NDWIæ°´åŸŸæ£€æµ‹
        ndwi_water = ndwi > 0.0  # NDWI > 0 é€šå¸¸è¡¨ç¤ºæ°´åŸŸ

        # ä½é¥±å’Œåº¦è“è‰²åŒºåŸŸï¼ˆå¯èƒ½æ˜¯è¿œæµ·ï¼‰
        blue_low_sat = ((h >= 200) & (h <= 250)) & (s >= 0.05) & (v >= 0.1)

        # ç»¼åˆæ°´åŸŸæ©è†œ
        water_mask = hsv_water | ndwi_water | blue_low_sat

        # å½¢æ€å­¦å¤„ç†
        water_mask = binary_closing(water_mask, np.ones((7, 7)))
        water_mask = binary_erosion(water_mask, np.ones((3, 3)))
        water_mask = binary_dilation(water_mask, np.ones((5, 5)))

        return water_mask

    def _enhanced_land_detection(self, hsv_image, ndwi):
        """å¢å¼ºçš„é™†åœ°æ£€æµ‹"""
        h, s, v = hsv_image[:, :, 0], hsv_image[:, :, 1], hsv_image[:, :, 2]

        # ç»¿è‰²æ¤è¢«
        green_mask = ((h >= self.land_hsv_range['hue_range'][0]) &
                      (h <= self.land_hsv_range['hue_range'][1])) & \
                     (s >= self.land_hsv_range['saturation_min']) & \
                     (v >= self.land_hsv_range['value_min'])

        # æ£•è‰²åœŸå£¤/å»ºç­‘
        brown_mask = ((h >= 20) & (h <= 60)) & (s >= 0.1) & (v >= 0.2)

        # ç°è‰²å»ºç­‘/é“è·¯
        gray_mask = (s <= 0.15) & (v >= 0.3) & (v <= 0.8)

        # NDWIé™†åœ°ï¼ˆNDWI < -0.1 é€šå¸¸è¡¨ç¤ºé™†åœ°ï¼‰
        ndwi_land = ndwi < -0.1

        # ç»¼åˆé™†åœ°æ©è†œ
        land_mask = green_mask | brown_mask | gray_mask | ndwi_land

        # å½¢æ€å­¦å¤„ç†
        land_mask = binary_closing(land_mask, np.ones((5, 5)))
        land_mask = binary_erosion(land_mask, np.ones((2, 2)))
        land_mask = binary_dilation(land_mask, np.ones((4, 4)))

        return land_mask

    def _calculate_boundary_confidence(self, edge_map, water_mask, land_mask):
        """è®¡ç®—è¾¹ç•Œç½®ä¿¡åº¦å›¾"""
        # æ°´é™†è¾¹ç•Œ
        water_boundary = binary_dilation(water_mask, np.ones((3, 3))) & ~water_mask
        land_boundary = binary_dilation(land_mask, np.ones((3, 3))) & ~land_mask

        # è¾¹ç•Œå€™é€‰åŒºåŸŸ
        boundary_candidates = water_boundary | land_boundary

        # ç»“åˆè¾¹ç¼˜å¼ºåº¦
        confidence = edge_map * boundary_candidates.astype(float)

        # è·ç¦»å˜æ¢å¢å¼º
        from scipy.ndimage import distance_transform_edt

        water_dist = distance_transform_edt(~water_mask)
        land_dist = distance_transform_edt(~land_mask)

        # åœ¨æ°´é™†äº¤ç•Œå¤„ç½®ä¿¡åº¦æœ€é«˜
        boundary_distance = np.minimum(water_dist, land_dist)
        distance_weight = np.exp(-boundary_distance / 5.0)

        confidence = confidence + distance_weight * 0.3

        # å½’ä¸€åŒ–
        if confidence.max() > 0:
            confidence = confidence / confidence.max()

        return confidence

    def _generate_enhanced_coastline_guidance(self, water_mask, land_mask, boundary_confidence, edge_map):
        """ç”Ÿæˆå¢å¼ºçš„æµ·å²¸çº¿æŒ‡å¯¼å›¾"""
        # åŸºç¡€æµ·å²¸çº¿å€™é€‰
        water_boundary = binary_dilation(water_mask, np.ones((5, 5))) & ~water_mask
        land_boundary = binary_dilation(land_mask, np.ones((5, 5))) & ~land_mask

        coastline_candidates = water_boundary | land_boundary

        # ç»“åˆå¤šç§ä¿¡æ¯æº
        guidance = coastline_candidates.astype(float) * 0.4  # åŸºç¡€æƒé‡
        guidance += boundary_confidence * 0.4  # è¾¹ç•Œç½®ä¿¡åº¦
        guidance += edge_map * 0.2  # è¾¹ç¼˜å¼ºåº¦

        # è·ç¦»å˜æ¢æŒ‡å¯¼
        from scipy.ndimage import distance_transform_edt

        if np.any(water_mask) and np.any(land_mask):
            water_dist = distance_transform_edt(~water_mask)
            land_dist = distance_transform_edt(~land_mask)

            # åœ¨çœŸæ­£çš„è¾¹ç•Œå¤„ç»™äºˆæœ€é«˜æƒé‡
            boundary_strength = np.exp(-0.1 * (water_dist + land_dist))
            guidance += boundary_strength * 0.3

        # å½’ä¸€åŒ–
        if guidance.max() > 0:
            guidance = guidance / guidance.max()

        return guidance

    def _calculate_enhanced_transition_strength(self, hsv_image, water_mask, land_mask, edge_map):
        """è®¡ç®—å¢å¼ºçš„è¿‡æ¸¡å¼ºåº¦"""
        h, s, v = hsv_image[:, :, 0], hsv_image[:, :, 1], hsv_image[:, :, 2]

        # HSVæ¢¯åº¦
        h_grad = np.abs(np.gradient(h)[0]) + np.abs(np.gradient(h)[1])
        s_grad = np.abs(np.gradient(s)[0]) + np.abs(np.gradient(s)[1])
        v_grad = np.abs(np.gradient(v)[0]) + np.abs(np.gradient(v)[1])

        # ç»„åˆè¿‡æ¸¡å¼ºåº¦
        transition_strength = (h_grad * 0.3 + s_grad * 0.3 + v_grad * 0.2 + edge_map * 0.2)

        # åœ¨æ°´é™†è¾¹ç•Œå¤„å¢å¼º
        boundary_mask = binary_dilation(water_mask, np.ones((7, 7))) | binary_dilation(land_mask, np.ones((7, 7)))
        transition_strength = transition_strength * (1 + boundary_mask.astype(float) * 2.0)

        # å½’ä¸€åŒ–
        if transition_strength.max() > transition_strength.min():
            transition_strength = (transition_strength - transition_strength.min()) / \
                                  (transition_strength.max() - transition_strength.min() + 1e-8)

        return transition_strength


# ==================== æ”¹è¿›çš„çº¦æŸåŠ¨ä½œç©ºé—´ ====================

class ImprovedConstrainedActionSpace:
    """æ”¹è¿›çš„çº¦æŸåŠ¨ä½œç©ºé—´ - è¾¹ç•Œæ„ŸçŸ¥"""

    def __init__(self):
        self.base_actions = [(-1, -1), (-1, 0), (-1, 1), (0, -1),
                             (0, 1), (1, -1), (1, 0), (1, 1)]
        print("âœ… æ”¹è¿›çš„çº¦æŸåŠ¨ä½œç©ºé—´åˆå§‹åŒ–å®Œæˆ")

    def get_allowed_actions(self, current_position, coastline_state, hsv_analysis):
        """è·å–å…è®¸çš„åŠ¨ä½œï¼ˆè¾¹ç•Œæ„ŸçŸ¥ï¼‰"""
        allowed_actions = []
        context = self._analyze_boundary_context(current_position, coastline_state, hsv_analysis)

        for i, action in enumerate(self.base_actions):
            if self._is_boundary_aware_action_allowed(action, context, current_position, hsv_analysis):
                allowed_actions.append(i)

        return allowed_actions if allowed_actions else [0, 1, 3, 4]

    def _analyze_boundary_context(self, position, coastline_state, hsv_analysis):
        """åˆ†æè¾¹ç•Œä¸Šä¸‹æ–‡"""
        y, x = position

        # è¾¹ç•Œç½®ä¿¡åº¦
        boundary_confidence = hsv_analysis.get('boundary_confidence', np.zeros_like(coastline_state))
        confidence_score = boundary_confidence[y, x] if 0 <= y < boundary_confidence.shape[0] and 0 <= x < \
                                                        boundary_confidence.shape[1] else 0

        # å±€éƒ¨åŒºåŸŸåˆ†æ
        y_start, y_end = max(0, y - 3), min(coastline_state.shape[0], y + 4)
        x_start, x_end = max(0, x - 3), min(coastline_state.shape[1], x + 4)

        # æ°´é™†åˆ†å¸ƒ
        water_mask = hsv_analysis.get('water_mask', np.zeros_like(coastline_state, dtype=bool))
        land_mask = hsv_analysis.get('land_mask', np.zeros_like(coastline_state, dtype=bool))

        local_water = np.sum(water_mask[y_start:y_end, x_start:x_end])
        local_land = np.sum(land_mask[y_start:y_end, x_start:x_end])

        return {
            'confidence_score': confidence_score,
            'is_boundary_region': confidence_score > 0.2,
            'water_nearby': local_water > 0,
            'land_nearby': local_land > 0,
            'is_transition_zone': local_water > 0 and local_land > 0
        }

    def _is_boundary_aware_action_allowed(self, action, context, current_position, hsv_analysis):
        """è¾¹ç•Œæ„ŸçŸ¥çš„åŠ¨ä½œå…è®¸æ£€æŸ¥"""
        dy, dx = action

        # å¦‚æœä¸åœ¨è¾¹ç•ŒåŒºåŸŸï¼Œé™åˆ¶å¤§å¹…åº¦ç§»åŠ¨
        if not context['is_boundary_region']:
            if abs(dy) + abs(dx) > 1:
                return False

        # å¦‚æœåœ¨è¿‡æ¸¡åŒºåŸŸï¼Œå…è®¸æ›´çµæ´»çš„ç§»åŠ¨
        if context['is_transition_zone']:
            return True

        # å¦‚æœç½®ä¿¡åº¦å¾ˆä½ï¼Œé™åˆ¶ç§»åŠ¨
        if context['confidence_score'] < 0.1:
            if abs(dy) > 1 or abs(dx) > 1:
                return False

        return True


# ==================== å‡æµ·å²¸çº¿è¿‡æ»¤å™¨ ====================

class FalseCoastlineFilter:
    """å‡æµ·å²¸çº¿è¿‡æ»¤å™¨"""

    def __init__(self):
        print("âœ… å‡æµ·å²¸çº¿è¿‡æ»¤å™¨åˆå§‹åŒ–å®Œæˆ")

    def filter_false_coastlines(self, coastline_result, hsv_analysis, original_image):
        """è¿‡æ»¤å‡æµ·å²¸çº¿"""
        filtered_coastline = coastline_result.copy()

        # 1. è¿é€šç»„ä»¶åˆ†æè¿‡æ»¤
        filtered_coastline = self._filter_by_connected_components(filtered_coastline)

        # 2. NDWI/HSVå…‰è°±éªŒè¯
        filtered_coastline = self._filter_by_spectral_verification(
            filtered_coastline, hsv_analysis, original_image
        )

        # 3. æµ·æ´‹ä¸€è‡´æ€§è¿‡æ»¤
        filtered_coastline = self._filter_by_ocean_coherence(filtered_coastline, hsv_analysis)

        # 4. è¾¹ç•Œé‚»è¿‘æ€§è¿‡æ»¤
        filtered_coastline = self._filter_by_boundary_proximity(filtered_coastline, hsv_analysis)

        return filtered_coastline

    def _filter_by_connected_components(self, coastline):
        """åŸºäºè¿é€šç»„ä»¶çš„è¿‡æ»¤"""
        binary_coastline = (coastline > 0.5).astype(bool)
        labeled_array, num_components = label(binary_coastline)

        if num_components == 0:
            return coastline

        # è®¡ç®—æ¯ä¸ªç»„ä»¶çš„å¤§å°
        component_sizes = []
        for i in range(1, num_components + 1):
            size = np.sum(labeled_array == i)
            component_sizes.append((i, size))

        # æŒ‰å¤§å°æ’åº
        component_sizes.sort(key=lambda x: x[1], reverse=True)

        # ä¿ç•™è¾ƒå¤§çš„ç»„ä»¶
        filtered_binary = np.zeros_like(binary_coastline)
        total_pixels = np.sum(binary_coastline)

        for component_id, size in component_sizes:
            # ä¿ç•™å¤§äºæ€»åƒç´ 1%çš„ç»„ä»¶ï¼Œæˆ–è€…å‰5å¤§ç»„ä»¶
            if size > total_pixels * 0.01 or len([c for c in component_sizes[:5] if c[0] == component_id]) > 0:
                filtered_binary[labeled_array == component_id] = True

        # è½¬æ¢å›æ¦‚ç‡å€¼
        filtered_coastline = coastline * filtered_binary.astype(float)

        return filtered_coastline

    def _filter_by_spectral_verification(self, coastline, hsv_analysis, original_image):
        """åŸºäºå…‰è°±ç‰¹å¾çš„éªŒè¯è¿‡æ»¤"""
        binary_coastline = (coastline > 0.5).astype(bool)

        # è·å–NDWI
        ndwi = hsv_analysis.get('ndwi', np.zeros_like(coastline))

        # è·å–æ°´åŸŸæ©è†œ
        water_mask = hsv_analysis.get('water_mask', np.zeros_like(coastline, dtype=bool))

        # è¿‡æ»¤åœ¨æ·±æ°´åŒºåŸŸçš„å‡æµ·å²¸çº¿
        # æ·±æ°´åŒºåŸŸï¼šNDWI > 0.3 ä¸”åœ¨æ°´åŸŸæ©è†œå†…
        deep_water = (ndwi > 0.3) & water_mask

        # å¯¹æ·±æ°´åŒºåŸŸå†…çš„æµ·å²¸çº¿è¿›è¡Œè†¨èƒ€å¤„ç†ï¼Œç„¶åç§»é™¤
        deep_water_expanded = binary_dilation(deep_water, np.ones((5, 5)))

        # ç§»é™¤æ·±æ°´åŒºåŸŸå†…çš„æµ·å²¸çº¿
        filtered_binary = binary_coastline & ~deep_water_expanded

        # è½¬æ¢å›æ¦‚ç‡å€¼
        filtered_coastline = coastline * filtered_binary.astype(float)

        return filtered_coastline

    def _filter_by_ocean_coherence(self, coastline, hsv_analysis):
        """åŸºäºæµ·æ´‹ä¸€è‡´æ€§çš„è¿‡æ»¤"""
        binary_coastline = (coastline > 0.5).astype(bool)
        water_mask = hsv_analysis.get('water_mask', np.zeros_like(coastline, dtype=bool))

        # ä»é«˜ç½®ä¿¡åº¦çš„æ°´åŸŸåƒç´ å¼€å§‹åå‘è†¨èƒ€
        high_confidence_water = water_mask.copy()

        # å¤šæ¬¡è†¨èƒ€ï¼Œæ ‡è®°è¿ç»­çš„æ°´åŸŸ
        for _ in range(10):
            expanded_water = binary_dilation(high_confidence_water, np.ones((3, 3)))
            high_confidence_water = expanded_water & water_mask

        # ç§»é™¤å®Œå…¨è¢«é«˜ç½®ä¿¡åº¦æ°´åŸŸåŒ…å›´çš„æµ·å²¸çº¿
        surrounded_by_water = binary_coastline.copy()
        for _ in range(3):
            eroded = binary_erosion(surrounded_by_water, np.ones((3, 3)))
            surrounded_by_water = eroded & high_confidence_water

        # è¿‡æ»¤è¢«æ°´åŸŸåŒ…å›´çš„æµ·å²¸çº¿
        filtered_binary = binary_coastline & ~surrounded_by_water

        # è½¬æ¢å›æ¦‚ç‡å€¼
        filtered_coastline = coastline * filtered_binary.astype(float)

        return filtered_coastline

    def _filter_by_boundary_proximity(self, coastline, hsv_analysis):
        """åŸºäºè¾¹ç•Œé‚»è¿‘æ€§çš„è¿‡æ»¤"""
        binary_coastline = (coastline > 0.5).astype(bool)
        boundary_confidence = hsv_analysis.get('boundary_confidence', np.zeros_like(coastline))

        # åªä¿ç•™è¾¹ç•Œç½®ä¿¡åº¦è¾ƒé«˜åŒºåŸŸé™„è¿‘çš„æµ·å²¸çº¿
        high_boundary_regions = boundary_confidence > 0.1

        # è†¨èƒ€é«˜è¾¹ç•Œç½®ä¿¡åº¦åŒºåŸŸ
        expanded_boundary = high_boundary_regions.copy()
        for _ in range(5):
            expanded_boundary = binary_dilation(expanded_boundary, np.ones((3, 3)))

        # è¿‡æ»¤è¿œç¦»è¾¹ç•Œçš„æµ·å²¸çº¿
        filtered_binary = binary_coastline & expanded_boundary

        # è½¬æ¢å›æ¦‚ç‡å€¼
        filtered_coastline = coastline * filtered_binary.astype(float)

        return filtered_coastline


# ==================== æ”¹è¿›çš„æµ·å²¸çº¿ç¯å¢ƒ ====================

class ImprovedCoastlineEnvironment:
    """æ”¹è¿›çš„æµ·å²¸çº¿ç¯å¢ƒ - å…¨å›¾æ£€æµ‹"""

    def __init__(self, image, gt_analysis=None):
        self.image = image
        self.gt_analysis = gt_analysis
        self.current_coastline = np.zeros(image.shape[:2], dtype=float)
        self.height, self.width = image.shape[:2]

        # ä½¿ç”¨æ”¹è¿›çš„ç›‘ç£å™¨
        self.hsv_supervisor = BoundaryAwareHSVSupervisor()
        self.hsv_analysis = self.hsv_supervisor.analyze_image_hsv(image, gt_analysis)

        # ä½¿ç”¨æ”¹è¿›çš„åŠ¨ä½œçº¦æŸ
        self.action_constraints = ImprovedConstrainedActionSpace()
        self.base_actions = self.action_constraints.base_actions
        self.action_dim = len(self.base_actions)

        # å‡æµ·å²¸çº¿è¿‡æ»¤å™¨
        self.false_filter = FalseCoastlineFilter()

        # å¥½å¥‡å¿ƒæ¢ç´¢
        self.curiosity_explorer = CuriosityDrivenExploration()

        # å¢å¼ºè¾¹ç¼˜æ£€æµ‹
        self.edge_map = self.hsv_analysis['edge_map']

        # è®¾ç½®å…¨å›¾æœç´¢åŒºåŸŸï¼ˆè€Œéä»…ä¸­é—´1/3ï¼‰
        self._setup_full_image_search_region()

        print(f"âœ… æ”¹è¿›çš„æµ·å²¸çº¿ç¯å¢ƒåˆå§‹åŒ–å®Œæˆï¼ˆå…¨å›¾æ£€æµ‹æ¨¡å¼ï¼‰")

    def _setup_full_image_search_region(self):
        """è®¾ç½®å…¨å›¾æœç´¢åŒºåŸŸ"""
        # åŸºäºè¾¹ç•Œç½®ä¿¡åº¦çš„æœç´¢åŒºåŸŸ
        boundary_confidence = self.hsv_analysis['boundary_confidence']
        coastline_guidance = self.hsv_analysis['coastline_guidance']

        # ä¸»è¦æœç´¢åŒºåŸŸï¼šè¾¹ç•Œç½®ä¿¡åº¦ > 0.05 æˆ– æµ·å²¸çº¿æŒ‡å¯¼ > 0.1
        primary_region = (boundary_confidence > 0.05) | (coastline_guidance > 0.1)

        # æ‰©å±•æœç´¢åŒºåŸŸ
        expanded_region = primary_region.copy()
        for _ in range(3):
            expanded_region = binary_dilation(expanded_region, np.ones((3, 3)))

        # é¿å…æ·±æ°´åŒºåŸŸï¼ˆåŸºäºNDWIå’Œæ°´åŸŸæ©è†œï¼‰
        ndwi = self.hsv_analysis['ndwi']
        water_mask = self.hsv_analysis['water_mask']

        # æ·±æ°´åŒºåŸŸï¼šNDWI > 0.4 ä¸”è¿ç»­çš„å¤§ç‰‡æ°´åŸŸ
        deep_water = (ndwi > 0.4) & water_mask
        for _ in range(5):
            deep_water = binary_erosion(deep_water, np.ones((3, 3)))
        for _ in range(8):
            deep_water = binary_dilation(deep_water, np.ones((3, 3)))

        # æœ€ç»ˆæœç´¢åŒºåŸŸï¼šæ‰©å±•åŒºåŸŸå‡å»æ·±æ°´åŒºåŸŸ
        self.search_region = expanded_region & ~deep_water

        # ç¡®ä¿æœç´¢åŒºåŸŸä¸ä¸ºç©º
        if not np.any(self.search_region):
            print("   âš ï¸ æœç´¢åŒºåŸŸä¸ºç©ºï¼Œä½¿ç”¨å…¨å›¾ä½œä¸ºæœç´¢åŒºåŸŸ")
            self.search_region = np.ones((self.height, self.width), dtype=bool)

        search_ratio = np.sum(self.search_region) / (self.height * self.width)
        print(f"   ğŸ“ æœç´¢åŒºåŸŸè¦†ç›–: {search_ratio:.1%} çš„å›¾åƒ")

    def get_state_tensor(self, position):
        """è·å–çŠ¶æ€å¼ é‡"""
        y, x = position
        window_size = 64
        half_window = window_size // 2

        y_start = max(0, y - half_window)
        y_end = min(self.height, y + half_window)
        x_start = max(0, x - half_window)
        x_end = min(self.width, x + half_window)

        # RGBçŠ¶æ€
        rgb_state = np.zeros((3, window_size, window_size), dtype=np.float32)
        actual_h = y_end - y_start
        actual_w = x_end - x_start

        if len(self.image.shape) == 3:
            rgb_window = self.image[y_start:y_end, x_start:x_end] / 255.0
            rgb_state[:, :actual_h, :actual_w] = rgb_window.transpose(2, 0, 1)
        else:
            gray_window = self.image[y_start:y_end, x_start:x_end] / 255.0
            rgb_state[0, :actual_h, :actual_w] = gray_window
            rgb_state[1, :actual_h, :actual_w] = gray_window
            rgb_state[2, :actual_h, :actual_w] = gray_window

        # HSVå¢å¼ºçŠ¶æ€
        hsv_state = np.zeros((3, window_size, window_size), dtype=np.float32)

        # è¾¹ç•Œç½®ä¿¡åº¦
        boundary_window = self.hsv_analysis['boundary_confidence'][y_start:y_end, x_start:x_end]
        hsv_state[0, :actual_h, :actual_w] = boundary_window

        # æµ·å²¸çº¿æŒ‡å¯¼
        guidance_window = self.hsv_analysis['coastline_guidance'][y_start:y_end, x_start:x_end]
        hsv_state[1, :actual_h, :actual_w] = guidance_window

        # NDWI
        ndwi_window = self.hsv_analysis['ndwi'][y_start:y_end, x_start:x_end]
        # å½’ä¸€åŒ–NDWIåˆ°[0,1]
        ndwi_normalized = (ndwi_window + 1) / 2
        hsv_state[2, :actual_h, :actual_w] = ndwi_normalized

        rgb_tensor = torch.FloatTensor(rgb_state).unsqueeze(0).to(device)
        hsv_tensor = torch.FloatTensor(hsv_state).unsqueeze(0).to(device)

        return rgb_tensor, hsv_tensor

    def get_enhanced_features(self, position):
        """è·å–å¢å¼ºç‰¹å¾"""
        y, x = position

        if not (0 <= y < self.height and 0 <= x < self.width):
            return torch.zeros(30, dtype=torch.float32, device=device).unsqueeze(0)

        features = np.zeros(30, dtype=np.float32)

        # åŸºç¡€ç‰¹å¾
        features[0] = self.edge_map[y, x]
        features[1] = self.hsv_analysis['boundary_confidence'][y, x]
        features[2] = self.hsv_analysis['coastline_guidance'][y, x]
        features[3] = self.hsv_analysis['transition_strength'][y, x]
        features[4] = (self.hsv_analysis['ndwi'][y, x] + 1) / 2  # å½’ä¸€åŒ–NDWI
        features[5] = 1.0 if self.hsv_analysis['water_mask'][y, x] else 0.0
        features[6] = 1.0 if self.hsv_analysis['land_mask'][y, x] else 0.0

        # å±€éƒ¨åŒºåŸŸåˆ†æ
        y_start, y_end = max(0, y - 3), min(self.height, y + 4)
        x_start, x_end = max(0, x - 3), min(self.width, x + 4)

        # è¾¹ç•Œç½®ä¿¡åº¦ç»Ÿè®¡
        local_boundary = self.hsv_analysis['boundary_confidence'][y_start:y_end, x_start:x_end]
        if local_boundary.size > 0:
            features[7] = np.mean(local_boundary)
            features[8] = np.max(local_boundary)
            features[9] = np.std(local_boundary)

        # æµ·å²¸çº¿æŒ‡å¯¼ç»Ÿè®¡
        local_guidance = self.hsv_analysis['coastline_guidance'][y_start:y_end, x_start:x_end]
        if local_guidance.size > 0:
            features[10] = np.mean(local_guidance)
            features[11] = np.max(local_guidance)

        # NDWIç»Ÿè®¡
        local_ndwi = self.hsv_analysis['ndwi'][y_start:y_end, x_start:x_end]
        if local_ndwi.size > 0:
            features[12] = np.mean(local_ndwi)
            features[13] = np.min(local_ndwi)
            features[14] = np.max(local_ndwi)

        # æ°´é™†é‚»è¿‘æ€§
        local_water = self.hsv_analysis['water_mask'][y_start:y_end, x_start:x_end]
        local_land = self.hsv_analysis['land_mask'][y_start:y_end, x_start:x_end]

        features[15] = np.sum(local_water) / local_water.size
        features[16] = np.sum(local_land) / local_land.size

        # å¥½å¥‡å¿ƒå¥–åŠ±
        curiosity_bonus = self.curiosity_explorer.get_curiosity_bonus(
            position, self.hsv_analysis, self.current_coastline
        )
        features[17] = min(1.0, curiosity_bonus / 50.0)

        # ä½ç½®ç‰¹å¾
        features[18] = y / self.height
        features[19] = x / self.width

        # è·ç¦»ä¸­å¿ƒçš„è·ç¦»
        center_y, center_x = self.height // 2, self.width // 2
        distance_to_center = np.sqrt((y - center_y) ** 2 + (x - center_x) ** 2)
        max_distance = np.sqrt(center_y ** 2 + center_x ** 2)
        features[20] = distance_to_center / max_distance

        # è¾¹ç¼˜æ–¹å‘ç‰¹å¾
        if y > 0 and y < self.height - 1 and x > 0 and x < self.width - 1:
            sobel_x = self.edge_map[y - 1:y + 2, x - 1:x + 2] * np.array([[-1, 0, 1], [-2, 0, 2], [-1, 0, 1]])
            sobel_y = self.edge_map[y - 1:y + 2, x - 1:x + 2] * np.array([[-1, -2, -1], [0, 0, 0], [1, 2, 1]])

            grad_x = np.sum(sobel_x)
            grad_y = np.sum(sobel_y)

            if grad_x != 0 or grad_y != 0:
                angle = np.arctan2(grad_y, grad_x)
                features[21] = (angle + np.pi) / (2 * np.pi)  # å½’ä¸€åŒ–åˆ°[0,1]
            else:
                features[21] = 0.5

        # æœç´¢åŒºåŸŸç‰¹å¾
        features[22] = 1.0 if self.search_region[y, x] else 0.0

        # å±€éƒ¨å˜å¼‚æ€§
        if len(self.image.shape) == 3:
            local_rgb = self.image[y_start:y_end, x_start:x_end]
            if local_rgb.size > 0:
                features[23] = np.std(local_rgb[:, :, 0]) / 255.0
                features[24] = np.std(local_rgb[:, :, 1]) / 255.0
                features[25] = np.std(local_rgb[:, :, 2]) / 255.0

        # ç°æœ‰æµ·å²¸çº¿å¯†åº¦
        local_coastline = self.current_coastline[y_start:y_end, x_start:x_end]
        if local_coastline.size > 0:
            features[26] = np.mean(local_coastline > 0.3)

        # è¾¹ç•Œç±»å‹åˆ¤æ–­
        water_nearby = np.any(local_water)
        land_nearby = np.any(local_land)

        if water_nearby and land_nearby:
            features[27] = 1.0  # è¿‡æ¸¡åŒºåŸŸ
        elif water_nearby:
            features[28] = 1.0  # æ°´åŸŸåŒºåŸŸ
        elif land_nearby:
            features[29] = 1.0  # é™†åœ°åŒºåŸŸ

        return torch.FloatTensor(features).unsqueeze(0).to(device)

    def step(self, position, action_idx):
        """æ‰§è¡ŒåŠ¨ä½œæ­¥éª¤"""
        # è·å–è¾¹ç•Œæ„ŸçŸ¥çš„å…è®¸åŠ¨ä½œ
        allowed_actions = self.action_constraints.get_allowed_actions(
            position, self.current_coastline, self.hsv_analysis
        )

        if action_idx not in allowed_actions:
            action_idx = allowed_actions[0] if allowed_actions else 0

        y, x = position
        dy, dx = self.base_actions[action_idx]

        new_y = np.clip(y + dy, 0, self.height - 1)
        new_x = np.clip(x + dx, 0, self.width - 1)

        new_position = (new_y, new_x)
        reward = self._calculate_boundary_aware_reward(position, new_position, action_idx)

        return new_position, reward

    def _calculate_boundary_aware_reward(self, old_pos, new_pos, action_idx):
        """è®¡ç®—è¾¹ç•Œæ„ŸçŸ¥å¥–åŠ±"""
        y, x = new_pos
        reward = 0.0

        if not (0 <= y < self.height and 0 <= x < self.width):
            return -100.0

        # è¾¹ç•Œç½®ä¿¡åº¦å¥–åŠ±
        boundary_confidence = self.hsv_analysis['boundary_confidence'][y, x]
        reward += boundary_confidence * 50.0

        # æµ·å²¸çº¿æŒ‡å¯¼å¥–åŠ±
        guidance_score = self.hsv_analysis['coastline_guidance'][y, x]
        reward += guidance_score * 40.0

        # NDWIå¥–åŠ±ï¼šåœ¨æµ·é™†äº¤ç•Œå¤„NDWIåº”è¯¥æ¥è¿‘0
        ndwi_value = self.hsv_analysis['ndwi'][y, x]
        ndwi_reward = max(0, 20.0 - abs(ndwi_value) * 30.0)  # NDWIæ¥è¿‘0æ—¶å¥–åŠ±æœ€é«˜
        reward += ndwi_reward

        # æœç´¢åŒºåŸŸå¥–åŠ±
        if self.search_region[y, x]:
            reward += 15.0
        else:
            reward -= 25.0

        # æ°´é™†åˆ†ç¦»å¥–åŠ±ï¼ˆæ”¹è¿›ç‰ˆï¼‰
        separation_reward = self._calculate_improved_separation_reward(new_pos)
        reward += separation_reward

        # è¾¹ç¼˜è´¨é‡å¥–åŠ±
        edge_strength = self.edge_map[y, x]
        reward += edge_strength * 25.0

        # é¿å…æ·±æ°´åŒºåŸŸ
        if self.hsv_analysis['water_mask'][y, x] and self.hsv_analysis['ndwi'][y, x] > 0.3:
            reward -= 30.0

        return reward

    def _calculate_improved_separation_reward(self, position):
        """è®¡ç®—æ”¹è¿›çš„æ°´é™†åˆ†ç¦»å¥–åŠ±"""
        y, x = position

        water_mask = self.hsv_analysis['water_mask']
        land_mask = self.hsv_analysis['land_mask']

        water_neighbors = 0
        land_neighbors = 0
        total_neighbors = 0

        # æ›´å¤§çš„é‚»åŸŸæ£€æŸ¥
        for dy in range(-3, 4):
            for dx in range(-3, 4):
                if dy == 0 and dx == 0:
                    continue
                ny, nx = y + dy, x + dx
                if 0 <= ny < self.height and 0 <= nx < self.width:
                    total_neighbors += 1
                    if water_mask[ny, nx]:
                        water_neighbors += 1
                    if land_mask[ny, nx]:
                        land_neighbors += 1

        if total_neighbors == 0:
            return 0.0

        water_ratio = water_neighbors / total_neighbors
        land_ratio = land_neighbors / total_neighbors

        # ç†æƒ³çš„æµ·å²¸çº¿åº”è¯¥åŒæ—¶é‚»è¿‘æ°´åŸŸå’Œé™†åœ°
        if water_ratio > 0.2 and land_ratio > 0.2:
            # å®Œç¾çš„åˆ†ç¦»ï¼šæ°´é™†æ¯”ä¾‹æ¥è¿‘
            balance_bonus = 50.0 * (1.0 - abs(water_ratio - land_ratio))
            separation_reward = 40.0 + balance_bonus
        elif water_ratio > 0.1 or land_ratio > 0.1:
            separation_reward = 20.0 * (water_ratio + land_ratio)
        else:
            separation_reward = -10.0

        return separation_reward

    def update_coastline(self, position, value=1.0):
        """æ›´æ–°æµ·å²¸çº¿"""
        y, x = position
        if 0 <= y < self.height and 0 <= x < self.width:
            self.current_coastline[y, x] = min(1.0, self.current_coastline[y, x] + value)

    def apply_false_coastline_filtering(self):
        """åº”ç”¨å‡æµ·å²¸çº¿è¿‡æ»¤"""
        self.current_coastline = self.false_filter.filter_false_coastlines(
            self.current_coastline, self.hsv_analysis, self.image
        )
        return self.current_coastline


# ==================== æ”¹è¿›çš„DQNç½‘ç»œ ====================

class ImprovedConstrainedCoastlineDQN(nn.Module):
    """æ”¹è¿›çš„çº¦æŸæµ·å²¸çº¿DQNç½‘ç»œ"""

    def __init__(self, input_channels=3, hidden_dim=256, action_dim=8):
        super(ImprovedConstrainedCoastlineDQN, self).__init__()

        # RGBç‰¹å¾æå–å™¨
        self.rgb_extractor = nn.Sequential(
            nn.Conv2d(input_channels, 32, kernel_size=7, stride=2, padding=3),
            nn.ReLU(inplace=True),
            nn.BatchNorm2d(32),
            nn.Conv2d(32, 64, kernel_size=5, stride=2, padding=2),
            nn.ReLU(inplace=True),
            nn.BatchNorm2d(64),
            nn.Conv2d(64, 128, kernel_size=3, stride=2, padding=1),
            nn.ReLU(inplace=True),
            nn.BatchNorm2d(128),
            nn.AdaptiveAvgPool2d((8, 8)),
        )

        # è¾¹ç•Œæ„ŸçŸ¥ç‰¹å¾æå–å™¨
        self.boundary_extractor = nn.Sequential(
            nn.Conv2d(3, 32, kernel_size=5, stride=2, padding=2),
            nn.ReLU(inplace=True),
            nn.BatchNorm2d(32),
            nn.Conv2d(32, 64, kernel_size=3, stride=2, padding=1),
            nn.ReLU(inplace=True),
            nn.BatchNorm2d(64),
            nn.Conv2d(64, 96, kernel_size=3, stride=2, padding=1),
            nn.ReLU(inplace=True),
            nn.BatchNorm2d(96),
            nn.AdaptiveAvgPool2d((8, 8)),
        )

        self.feature_dim = 128 * 8 * 8 + 96 * 8 * 8

        # Qå€¼ç½‘ç»œ
        self.q_network = nn.Sequential(
            nn.Linear(self.feature_dim + 2 + 30, hidden_dim),
            nn.ReLU(inplace=True),
            nn.Dropout(0.3),
            nn.Linear(hidden_dim, hidden_dim),
            nn.ReLU(inplace=True),
            nn.Dropout(0.2),
            nn.Linear(hidden_dim, hidden_dim // 2),
            nn.ReLU(inplace=True),
            nn.Linear(hidden_dim // 2, action_dim)
        )

        # è¾¹ç•Œæ„ŸçŸ¥åŠ¨ä½œæ©è†œç½‘ç»œ
        self.boundary_mask_network = nn.Sequential(
            nn.Linear(30, 64),
            nn.ReLU(inplace=True),
            nn.Dropout(0.2),
            nn.Linear(64, 32),
            nn.ReLU(inplace=True),
            nn.Linear(32, action_dim),
            nn.Sigmoid()
        )

    def forward(self, rgb_state, boundary_state, position, enhanced_features):
        # ç‰¹å¾æå–
        rgb_features = self.rgb_extractor(rgb_state)
        boundary_features = self.boundary_extractor(boundary_state)

        # å±•å¹³ç‰¹å¾
        rgb_features = rgb_features.view(rgb_features.size(0), -1)
        boundary_features = boundary_features.view(boundary_features.size(0), -1)

        # ä½ç½®å½’ä¸€åŒ–
        position_norm = position.float() / 400.0

        # ç»„åˆæ‰€æœ‰ç‰¹å¾
        combined = torch.cat([rgb_features, boundary_features, position_norm, enhanced_features], dim=1)

        # Qå€¼è®¡ç®—
        q_values = self.q_network(combined)

        # è¾¹ç•Œæ„ŸçŸ¥åŠ¨ä½œæ©è†œ
        action_mask = self.boundary_mask_network(enhanced_features)

        # åº”ç”¨æ©è†œ
        masked_q_values = q_values * action_mask - (1 - action_mask) * 1e6

        return masked_q_values


# ==================== å¥½å¥‡å¿ƒé©±åŠ¨æ¢ç´¢ï¼ˆä¿æŒä¸å˜ï¼‰ ====================

class CuriosityDrivenExploration:
    def __init__(self, exploration_decay=0.995):
        self.visit_history = {}
        self.exploration_decay = exploration_decay
        self.step_count = 0
        print("âœ… å¥½å¥‡å¿ƒé©±åŠ¨æ¢ç´¢æœºåˆ¶åˆå§‹åŒ–å®Œæˆ")

    def get_curiosity_bonus(self, position, hsv_analysis, current_coastline):
        y, x = position
        pos_key = f"{y}_{x}"

        visit_count = self.visit_history.get(pos_key, 0)
        visit_bonus = max(0, 10.0 - visit_count * 2.0)

        # è¾¹ç•Œæ„ŸçŸ¥å¥½å¥‡å¿ƒå¥–åŠ±
        boundary_bonus = 0.0
        if hsv_analysis:
            boundary_confidence = hsv_analysis.get('boundary_confidence', np.zeros_like(current_coastline))
            if boundary_confidence[y, x] > 0.2:
                boundary_bonus = boundary_confidence[y, x] * 20.0

        self.visit_history[pos_key] = visit_count + 1
        self.step_count += 1

        return visit_bonus + boundary_bonus


# ==================== æ”¹è¿›çš„ä»£ç†ç±» ====================

class ImprovedCoastlineAgent:
    """æ”¹è¿›çš„æµ·å²¸çº¿ä»£ç†"""

    def __init__(self, env, lr=1e-4, gamma=0.98, epsilon_start=0.1, epsilon_end=0.05, epsilon_decay=0.995):
        self.env = env
        self.device = device

        self.lr = lr
        self.gamma = gamma
        self.epsilon = epsilon_start
        self.epsilon_end = epsilon_end
        self.epsilon_decay = epsilon_decay

        # ä½¿ç”¨æ”¹è¿›çš„ç½‘ç»œ
        self.policy_net = ImprovedConstrainedCoastlineDQN().to(device)
        self.target_net = ImprovedConstrainedCoastlineDQN().to(device)
        self.target_net.load_state_dict(self.policy_net.state_dict())
        self.target_net.eval()

        self.optimizer = optim.Adam(self.policy_net.parameters(), lr=lr, weight_decay=1e-4)
        self.memory = deque(maxlen=20000)

        self.batch_size = 32
        self.target_update_freq = 100
        self.train_freq = 4
        self.steps_done = 0

        print(f"âœ… æ”¹è¿›çš„DQNä»£ç†åˆå§‹åŒ–å®Œæˆ")

    def select_action(self, rgb_state, boundary_state, position, enhanced_features, training=False):
        """é€‰æ‹©åŠ¨ä½œ"""
        allowed_actions = self.env.action_constraints.get_allowed_actions(
            position, self.env.current_coastline, self.env.hsv_analysis
        )

        if training and random.random() < self.epsilon:
            return random.choice(allowed_actions)
        else:
            with torch.no_grad():
                position_tensor = torch.LongTensor([position]).to(device)
                q_values = self.policy_net(rgb_state, boundary_state, position_tensor, enhanced_features)

                # åœ¨å…è®¸çš„åŠ¨ä½œä¸­é€‰æ‹©Qå€¼æœ€é«˜çš„
                masked_q_values = q_values.clone()
                for i in range(self.env.action_dim):
                    if i not in allowed_actions:
                        masked_q_values[0, i] = float('-inf')

                return masked_q_values.argmax(dim=1).item()

    def load_model(self, load_path):
        """åŠ è½½é¢„è®­ç»ƒæ¨¡å‹"""
        if os.path.exists(load_path):
            try:
                checkpoint = torch.load(load_path, map_location=device)
                # å°è¯•åŠ è½½æ”¹è¿›çš„æ¨¡å‹ç»“æ„
                try:
                    self.policy_net.load_state_dict(checkpoint['policy_net_state_dict'])
                    self.target_net.load_state_dict(checkpoint['target_net_state_dict'])
                except:
                    # å¦‚æœç»“æ„ä¸åŒ¹é…ï¼Œåˆ›å»ºå…¼å®¹çš„åŠ è½½æ–¹å¼
                    print("   âš ï¸ æ¨¡å‹ç»“æ„ä¸å®Œå…¨åŒ¹é…ï¼Œå°è¯•éƒ¨åˆ†åŠ è½½...")
                    model_dict = self.policy_net.state_dict()
                    pretrained_dict = {k: v for k, v in checkpoint['policy_net_state_dict'].items()
                                       if k in model_dict and v.size() == model_dict[k].size()}
                    model_dict.update(pretrained_dict)
                    self.policy_net.load_state_dict(model_dict)
                    self.target_net.load_state_dict(model_dict)

                self.epsilon = self.epsilon_end
                print(f"âœ… æ”¹è¿›çš„é¢„è®­ç»ƒæ¨¡å‹å·²åŠ è½½: {load_path}")
                return True
            except Exception as e:
                print(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
                return False
        return False

    def apply_improved_inference(self, max_inference_steps=1500):
        """åº”ç”¨æ”¹è¿›çš„æ¨ç†ç®—æ³•"""
        print("ğŸ”® ä½¿ç”¨æ”¹è¿›çš„é¢„è®­ç»ƒæ¨¡å‹è¿›è¡Œå…¨å›¾æµ·å²¸çº¿æ¨ç†...")

        # è·å–å…¨å›¾æœç´¢åŒºåŸŸ
        search_positions = np.where(self.env.search_region)
        candidate_positions = list(zip(search_positions[0], search_positions[1]))

        if not candidate_positions:
            print("   âš ï¸ æœªæ‰¾åˆ°æœç´¢åŒºåŸŸ")
            return self.env.current_coastline

        print(f"   ğŸ¯ å…¨å›¾æœç´¢ä½ç½®æ•°: {len(candidate_positions)}")

        # åŸºäºè¾¹ç•Œç½®ä¿¡åº¦çš„æ™ºèƒ½ä½ç½®é€‰æ‹©
        high_priority_positions = []
        medium_priority_positions = []
        low_priority_positions = []

        for pos in candidate_positions:
            y, x = pos
            boundary_confidence = self.env.hsv_analysis['boundary_confidence'][y, x]
            guidance_score = self.env.hsv_analysis['coastline_guidance'][y, x]
            edge_score = self.env.edge_map[y, x]

            # ç»¼åˆè¯„åˆ†
            combined_score = boundary_confidence * 0.4 + guidance_score * 0.4 + edge_score * 0.2

            if combined_score > 0.6:
                high_priority_positions.append((combined_score, pos))
            elif combined_score > 0.3:
                medium_priority_positions.append((combined_score, pos))
            else:
                low_priority_positions.append((combined_score, pos))

        # æŒ‰ä¼˜å…ˆçº§æ’åº
        high_priority_positions.sort(reverse=True, key=lambda x: x[0])
        medium_priority_positions.sort(reverse=True, key=lambda x: x[0])
        low_priority_positions.sort(reverse=True, key=lambda x: x[0])

        print(f"   ğŸ“Š é«˜ä¼˜å…ˆçº§ä½ç½®: {len(high_priority_positions)}")
        print(f"   ğŸ“Š ä¸­ä¼˜å…ˆçº§ä½ç½®: {len(medium_priority_positions)}")
        print(f"   ğŸ“Š ä½ä¼˜å…ˆçº§ä½ç½®: {len(low_priority_positions)}")

        # æ„å»ºæ¨ç†åºåˆ—
        inference_positions = []

        # ä¼˜å…ˆå¤„ç†é«˜ä¼˜å…ˆçº§ä½ç½®
        inference_positions.extend([pos for _, pos in high_priority_positions[:max_inference_steps // 2]])

        # è¡¥å……ä¸­ä¼˜å…ˆçº§ä½ç½®
        remaining_slots = max_inference_steps - len(inference_positions)
        inference_positions.extend([pos for _, pos in medium_priority_positions[:remaining_slots // 2]])

        # è¡¥å……ä½ä¼˜å…ˆçº§ä½ç½®
        remaining_slots = max_inference_steps - len(inference_positions)
        inference_positions.extend([pos for _, pos in low_priority_positions[:remaining_slots]])

        print(f"   ğŸ¯ æœ€ç»ˆæ¨ç†ä½ç½®æ•°: {len(inference_positions)}")

        # å¤šé˜¶æ®µæ¨ç†
        improvements = 0
        total_reward = 0.0

        for stage in range(3):
            print(f"   ğŸ”„ ç¬¬ {stage + 1} é˜¶æ®µæ¨ç†")
            stage_positions = inference_positions[stage::3]  # äº¤é”™åˆ†é…
            stage_improvements = 0

            for position in stage_positions:
                # è·å–çŠ¶æ€
                rgb_state, boundary_state = self.env.get_state_tensor(position)
                enhanced_features = self.env.get_enhanced_features(position)

                # æ¨ç†åŠ¨ä½œ
                action = self.select_action(rgb_state, boundary_state, position, enhanced_features, training=False)

                # æ‰§è¡ŒåŠ¨ä½œ
                next_position, reward = self.env.step(position, action)
                total_reward += reward

                # åŠ¨æ€é˜ˆå€¼
                if stage == 0:
                    reward_threshold = 15.0
                elif stage == 1:
                    reward_threshold = 10.0
                else:
                    reward_threshold = 7.0

                if reward > reward_threshold:
                    # æ ¹æ®å¥–åŠ±è°ƒæ•´æ›´æ–°å€¼
                    update_value = min(1.0, reward / 50.0)
                    self.env.update_coastline(next_position, update_value)
                    improvements += 1
                    stage_improvements += 1

            print(f"      âœ… ç¬¬ {stage + 1} é˜¶æ®µæ”¹è¿›: {stage_improvements}")

        # åº”ç”¨å‡æµ·å²¸çº¿è¿‡æ»¤
        print("   ğŸ§¹ åº”ç”¨å‡æµ·å²¸çº¿è¿‡æ»¤...")
        filtered_coastline = self.env.apply_false_coastline_filtering()

        final_pixels = np.sum(filtered_coastline > 0.3)
        avg_reward = total_reward / len(inference_positions) if inference_positions else 0

        print(f"   âœ… æ”¹è¿›æ¨ç†å®Œæˆ: {final_pixels:,} åƒç´ , æ€»æ”¹è¿›: {improvements}")
        print(f"   ğŸ“Š å¹³å‡å¥–åŠ±: {avg_reward:.2f}")

        return filtered_coastline


# ==================== æ”¹è¿›çš„è´¨é‡è¯„ä¼°å™¨ ====================

class ImprovedQualityAssessor:
    """æ”¹è¿›çš„è´¨é‡è¯„ä¼°å™¨"""

    def __init__(self):
        print("âœ… æ”¹è¿›çš„è´¨é‡è¯„ä¼°å™¨åˆå§‹åŒ–å®Œæˆ")

    def assess_coastline_quality(self, coastline, hsv_analysis, original_image):
        """è¯„ä¼°æµ·å²¸çº¿è´¨é‡ï¼ˆæ”¹è¿›ç‰ˆï¼‰"""
        print("ğŸ“Š è¯„ä¼°æ”¹è¿›çš„æµ·å²¸çº¿è´¨é‡...")

        metrics = {}
        pred_binary = (coastline > 0.5).astype(bool)
        coastline_pixels = np.sum(pred_binary)

        # åŸºç¡€ç»Ÿè®¡
        metrics['coastline_pixels'] = int(coastline_pixels)

        # 1. è¿é€šæ€§åˆ†æï¼ˆæ”¹è¿›ï¼‰
        labeled_array, num_components = label(pred_binary)
        metrics['num_components'] = int(num_components)

        if num_components > 0:
            component_sizes = [np.sum(labeled_array == i) for i in range(1, num_components + 1)]
            main_component_ratio = max(component_sizes) / coastline_pixels if coastline_pixels > 0 else 0

            # æ”¹è¿›çš„ç¢ç‰‡åŒ–è¯„åˆ†
            size_variance = np.var(component_sizes) / (np.mean(component_sizes) ** 2 + 1e-8)
            metrics['main_component_ratio'] = float(main_component_ratio)
            metrics['fragmentation_score'] = float(min(1.0, size_variance))
        else:
            metrics['main_component_ratio'] = 0.0
            metrics['fragmentation_score'] = 1.0

        # 2. è¾¹ç•Œè´¨é‡è¯„ä¼°
        boundary_quality = self._assess_boundary_quality(pred_binary, hsv_analysis)
        metrics['boundary_quality'] = float(boundary_quality)

        # 3. NDWIä¸€è‡´æ€§è¯„ä¼°
        ndwi_consistency = self._assess_ndwi_consistency(pred_binary, hsv_analysis)
        metrics['ndwi_consistency'] = float(ndwi_consistency)

        # 4. å‡æµ·å²¸çº¿æ£€æµ‹
        false_coastline_ratio = self._detect_false_coastlines(pred_binary, hsv_analysis)
        metrics['false_coastline_ratio'] = float(false_coastline_ratio)

        # 5. æµ·åŸŸæ¸…ç†æ•ˆæœ
        water_mask = hsv_analysis['water_mask']
        water_intrusion = np.sum(pred_binary & water_mask) / (coastline_pixels + 1e-8)
        metrics['water_intrusion_ratio'] = float(water_intrusion)
        metrics['sea_cleanup_score'] = float(max(0.0, 1.0 - water_intrusion * 3))

        # 6. å…¨å›¾åˆ†å¸ƒåˆ†æï¼ˆè€Œéä»…ä¸­é—´1/3ï¼‰
        height = pred_binary.shape[0]
        quarter_height = height // 4

        top_pixels = np.sum(pred_binary[:quarter_height, :])
        upper_mid_pixels = np.sum(pred_binary[quarter_height:2 * quarter_height, :])
        lower_mid_pixels = np.sum(pred_binary[2 * quarter_height:3 * quarter_height, :])
        bottom_pixels = np.sum(pred_binary[3 * quarter_height:, :])

        if coastline_pixels > 0:
            top_ratio = top_pixels / coastline_pixels
            upper_mid_ratio = upper_mid_pixels / coastline_pixels
            lower_mid_ratio = lower_mid_pixels / coastline_pixels
            bottom_ratio = bottom_pixels / coastline_pixels

            # è¯„ä¼°åˆ†å¸ƒå‡åŒ€æ€§
            distribution_entropy = self._calculate_distribution_entropy(
                [top_ratio, upper_mid_ratio, lower_mid_ratio, bottom_ratio])
            distribution_score = distribution_entropy / np.log(4)  # å½’ä¸€åŒ–ç†µ
        else:
            top_ratio = upper_mid_ratio = lower_mid_ratio = bottom_ratio = 0.0
            distribution_score = 0.0

        metrics['top_ratio'] = float(top_ratio)
        metrics['upper_mid_ratio'] = float(upper_mid_ratio)
        metrics['lower_mid_ratio'] = float(lower_mid_ratio)
        metrics['bottom_ratio'] = float(bottom_ratio)
        metrics['distribution_score'] = float(distribution_score)

        # 7. å¯†åº¦åˆç†æ€§è¯„ä¼°ï¼ˆè°ƒæ•´ä¸ºè‹±å›½æµ·å²¸çº¿ç‰¹å¾ï¼‰
        target_min, target_max = 8000, 80000  # é€‚åº”è‹±å›½åŸå¸‚æµ·å²¸çº¿
        if target_min <= coastline_pixels <= target_max:
            density_score = 1.0
        elif coastline_pixels < target_min:
            density_score = max(0.2, coastline_pixels / target_min)
        else:
            density_score = max(0.1, 1.0 - (coastline_pixels - target_max) / target_max)
        metrics['density_score'] = float(density_score)

        # 8. è¿ç»­æ€§è¯„ä¼°ï¼ˆæ”¹è¿›ï¼‰
        continuity_score = self._assess_improved_continuity(pred_binary)
        metrics['continuity_score'] = float(continuity_score)

        # 9. è¾¹ç¼˜ä¸€è‡´æ€§
        edge_consistency = self._assess_edge_consistency(pred_binary, original_image)
        metrics['edge_consistency'] = float(edge_consistency)

        # 10. ç»¼åˆè´¨é‡è¯„åˆ†ï¼ˆæ”¹è¿›ç‰ˆï¼‰
        overall_score = self._calculate_improved_overall_score(metrics)
        metrics['overall_score'] = float(overall_score)

        # 11. è´¨é‡ç­‰çº§è¯„å®š
        quality_level = self._determine_improved_quality_level(overall_score)
        metrics['quality_level'] = quality_level

        return metrics

    def _assess_boundary_quality(self, coastline_binary, hsv_analysis):
        """è¯„ä¼°è¾¹ç•Œè´¨é‡"""
        if not np.any(coastline_binary):
            return 0.0

        boundary_confidence = hsv_analysis.get('boundary_confidence', np.zeros_like(coastline_binary))
        coastline_positions = np.where(coastline_binary)

        if len(coastline_positions[0]) == 0:
            return 0.0

        boundary_values = boundary_confidence[coastline_positions]
        return np.mean(boundary_values)

    def _assess_ndwi_consistency(self, coastline_binary, hsv_analysis):
        """è¯„ä¼°NDWIä¸€è‡´æ€§"""
        if not np.any(coastline_binary):
            return 0.0

        ndwi = hsv_analysis.get('ndwi', np.zeros_like(coastline_binary))
        coastline_positions = np.where(coastline_binary)

        if len(coastline_positions[0]) == 0:
            return 0.0

        ndwi_values = ndwi[coastline_positions]

        # æµ·å²¸çº¿çš„NDWIåº”è¯¥æ¥è¿‘0ï¼ˆæ°´é™†äº¤ç•Œï¼‰
        ndwi_consistency = np.mean(1.0 - np.abs(ndwi_values))
        return max(0.0, ndwi_consistency)

    def _detect_false_coastlines(self, coastline_binary, hsv_analysis):
        """æ£€æµ‹å‡æµ·å²¸çº¿æ¯”ä¾‹"""
        if not np.any(coastline_binary):
            return 0.0

        water_mask = hsv_analysis.get('water_mask', np.zeros_like(coastline_binary, dtype=bool))
        ndwi = hsv_analysis.get('ndwi', np.zeros_like(coastline_binary))

        # æ·±æ°´åŒºåŸŸä¸­çš„æµ·å²¸çº¿è¢«è®¤ä¸ºæ˜¯å‡çš„
        deep_water = water_mask & (ndwi > 0.3)
        false_coastlines = coastline_binary & deep_water

        total_coastline = np.sum(coastline_binary)
        false_coastline_count = np.sum(false_coastlines)

        return false_coastline_count / (total_coastline + 1e-8)

    def _calculate_distribution_entropy(self, ratios):
        """è®¡ç®—åˆ†å¸ƒç†µ"""
        ratios = np.array(ratios)
        ratios = ratios[ratios > 0]  # ç§»é™¤é›¶å€¼
        if len(ratios) == 0:
            return 0.0
        ratios = ratios / np.sum(ratios)  # å½’ä¸€åŒ–
        return -np.sum(ratios * np.log(ratios + 1e-8))

    def _assess_improved_continuity(self, coastline_binary):
        """è¯„ä¼°æ”¹è¿›çš„è¿ç»­æ€§"""
        if not np.any(coastline_binary):
            return 0.0

        # ä½¿ç”¨éª¨æ¶åŒ–è¯„ä¼°è¿ç»­æ€§
        try:
            if HAS_SKIMAGE:
                skeleton = skeletonize(coastline_binary)
                skeleton_pixels = np.sum(skeleton)
                total_pixels = np.sum(coastline_binary)

                # è®¡ç®—è¿ç»­æ€§æŒ‡æ ‡
                if total_pixels > 0:
                    skeleton_ratio = skeleton_pixels / total_pixels
                    continuity = min(1.0, skeleton_ratio * 3)  # è°ƒæ•´ç³»æ•°
                else:
                    continuity = 0.0
            else:
                continuity = self._simple_continuity_assessment(coastline_binary)
        except:
            continuity = self._simple_continuity_assessment(coastline_binary)

        return continuity

    def _simple_continuity_assessment(self, coastline_binary):
        """ç®€åŒ–çš„è¿ç»­æ€§è¯„ä¼°"""
        height, width = coastline_binary.shape

        # è¡Œè¿ç»­æ€§
        row_continuity = 0.0
        valid_rows = 0

        for y in range(height):
            row = coastline_binary[y, :]
            if np.any(row):
                valid_rows += 1
                # è®¡ç®—è¿ç»­æ®µ
                segments = 0
                in_segment = False
                for x in range(width):
                    if row[x] and not in_segment:
                        segments += 1
                        in_segment = True
                    elif not row[x]:
                        in_segment = False

                # ç†æƒ³æƒ…å†µæ˜¯æ¯è¡Œ1ä¸ªè¿ç»­æ®µ
                row_continuity += 1.0 / (segments + 1e-8)

        if valid_rows > 0:
            row_continuity /= valid_rows

        # åˆ—è¿ç»­æ€§
        col_continuity = 0.0
        valid_cols = 0

        for x in range(width):
            col = coastline_binary[:, x]
            if np.any(col):
                valid_cols += 1
                segments = 0
                in_segment = False
                for y in range(height):
                    if col[y] and not in_segment:
                        segments += 1
                        in_segment = True
                    elif not col[y]:
                        in_segment = False

                col_continuity += 1.0 / (segments + 1e-8)

        if valid_cols > 0:
            col_continuity /= valid_cols

        # ç»¼åˆè¿ç»­æ€§
        overall_continuity = (row_continuity + col_continuity) / 2.0
        return min(1.0, overall_continuity)

    def _assess_edge_consistency(self, coastline_binary, original_image):
        """è¯„ä¼°è¾¹ç¼˜ä¸€è‡´æ€§"""
        if not np.any(coastline_binary):
            return 0.0

        # è®¡ç®—å›¾åƒè¾¹ç¼˜
        processor = ImprovedImageProcessor()
        edge_map = processor.enhanced_edge_detection(original_image)

        # æµ·å²¸çº¿ä½ç½®çš„è¾¹ç¼˜å¼ºåº¦
        coastline_positions = np.where(coastline_binary)
        if len(coastline_positions[0]) == 0:
            return 0.0

        edge_values = edge_map[coastline_positions]
        return np.mean(edge_values)

    def _calculate_improved_overall_score(self, metrics):
        """è®¡ç®—æ”¹è¿›çš„ç»¼åˆå¾—åˆ†"""
        score = 0.0

        # è°ƒæ•´æƒé‡åˆ†é…
        weights = {
            'boundary_quality': 0.20,  # è¾¹ç•Œè´¨é‡
            'ndwi_consistency': 0.15,  # NDWIä¸€è‡´æ€§
            'sea_cleanup_score': 0.15,  # æµ·åŸŸæ¸…ç†
            'distribution_score': 0.12,  # åˆ†å¸ƒå‡åŒ€æ€§
            'continuity_score': 0.12,  # è¿ç»­æ€§
            'edge_consistency': 0.10,  # è¾¹ç¼˜ä¸€è‡´æ€§
            'density_score': 0.08,  # å¯†åº¦åˆç†æ€§
        }

        # åŠ æƒè®¡ç®—
        score += metrics.get('boundary_quality', 0) * weights['boundary_quality']
        score += metrics.get('ndwi_consistency', 0) * weights['ndwi_consistency']
        score += metrics.get('sea_cleanup_score', 0) * weights['sea_cleanup_score']
        score += metrics.get('distribution_score', 0) * weights['distribution_score']
        score += metrics.get('continuity_score', 0) * weights['continuity_score']
        score += metrics.get('edge_consistency', 0) * weights['edge_consistency']
        score += metrics.get('density_score', 0) * weights['density_score']

        # æƒ©ç½šé¡¹
        # å‡æµ·å²¸çº¿æƒ©ç½š
        false_coastline_penalty = metrics.get('false_coastline_ratio', 0) * 0.3
        score -= false_coastline_penalty

        # è¿‡åº¦ç¢ç‰‡åŒ–æƒ©ç½š
        fragmentation_penalty = min(0.15, metrics.get('fragmentation_score', 0) * 0.2)
        score -= fragmentation_penalty

        # è¿‡å¤šè¿é€šç»„ä»¶æƒ©ç½š
        component_count = metrics.get('num_components', 0)
        pixel_count = metrics.get('coastline_pixels', 0)

        if pixel_count > 0:
            reasonable_components = max(50, pixel_count // 500)  # æ¯500åƒç´ å…è®¸1ä¸ªç»„ä»¶
            if component_count > reasonable_components:
                component_penalty = min(0.1, (component_count - reasonable_components) / reasonable_components * 0.15)
                score -= component_penalty

        # å¥–åŠ±é¡¹
        # ä¸»è¦ç»„ä»¶æ¯”ä¾‹å¥–åŠ±
        main_component_ratio = metrics.get('main_component_ratio', 0)
        if main_component_ratio > 0.8:
            score += 0.05

        # ä½æ°´åŸŸå…¥ä¾µå¥–åŠ±
        water_intrusion = metrics.get('water_intrusion_ratio', 1.0)
        if water_intrusion < 0.1:
            score += 0.05

        return max(0.0, min(1.0, score))

    def _determine_improved_quality_level(self, score):
        """ç¡®å®šæ”¹è¿›çš„è´¨é‡ç­‰çº§"""
        if score >= 0.85:
            return "Excellent"
        elif score >= 0.70:
            return "Good"
        elif score >= 0.55:
            return "Fair"
        elif score >= 0.40:
            return "Poor"
        else:
            return "Very Poor"


# ==================== æ”¹è¿›çš„è‹±å›½åŸå¸‚æ£€æµ‹å™¨ ====================

class ImprovedUKCitiesDetector:
    """æ”¹è¿›çš„è‹±å›½åŸå¸‚æµ·å²¸çº¿æ£€æµ‹å™¨"""

    def __init__(self):
        self.quality_assessor = ImprovedQualityAssessor()
        print("âœ… æ”¹è¿›çš„è‹±å›½åŸå¸‚æµ·å²¸çº¿æ£€æµ‹å™¨åˆå§‹åŒ–å®Œæˆ")
        print("   ğŸ¯ ç‰¹è‰²ï¼šå…¨å›¾æ£€æµ‹ + è¾¹ç•Œæ„ŸçŸ¥ + å‡æµ·å²¸çº¿è¿‡æ»¤")

    def load_image_from_file(self, image_path):
        """ä»æ–‡ä»¶åŠ è½½å›¾åƒ"""
        try:
            if image_path.lower().endswith('.pdf') and HAS_PDF_SUPPORT:
                doc = fitz.open(image_path)
                page = doc.load_page(0)
                zoom = 200 / 72
                mat = fitz.Matrix(zoom, zoom)
                pix = page.get_pixmap(matrix=mat)
                img_data = pix.tobytes("png")

                img = Image.open(BytesIO(img_data))
                image_array = np.array(img)
                doc.close()

                return image_array
            else:
                img = Image.open(image_path)
                return np.array(img)

        except Exception as e:
            print(f"âŒ å›¾åƒåŠ è½½å¤±è´¥: {e}")
            return None

    def process_uk_city_improved(self, image_path, city_name, pretrained_model_path):
        """
        å¤„ç†è‹±å›½åŸå¸‚æµ·å²¸çº¿æ£€æµ‹ï¼ˆæ”¹è¿›ç‰ˆï¼‰

        Args:
            image_path: åŸå¸‚å›¾åƒè·¯å¾„
            city_name: åŸå¸‚åç§°
            pretrained_model_path: é¢„è®­ç»ƒæ¨¡å‹è·¯å¾„
        """
        print(f"\nğŸ´ó §ó ¢ó ¥ó ®ó §ó ¿ æ”¹è¿›ç‰ˆå¤„ç†è‹±å›½åŸå¸‚: {city_name}")
        print(f"ğŸ“ å›¾åƒè·¯å¾„: {image_path}")

        try:
            # 1. åŠ è½½å›¾åƒ
            original_img = self.load_image_from_file(image_path)
            if original_img is None:
                return None

            # è°ƒæ•´å°ºå¯¸
            img_pil = Image.fromarray(original_img)
            processed_img = np.array(img_pil.resize((400, 400), Image.LANCZOS))
            print(f"   ğŸ“ å¤„ç†åå°ºå¯¸: {processed_img.shape}")

            # 2. åˆ›å»ºæ”¹è¿›çš„ç¯å¢ƒ
            print("\nğŸ“ æ­¥éª¤1: åˆ›å»ºæ”¹è¿›çš„æ£€æµ‹ç¯å¢ƒï¼ˆå…¨å›¾æ¨¡å¼ï¼‰")
            env = ImprovedCoastlineEnvironment(processed_img, gt_analysis=None)

            # 3. åˆ›å»ºæ”¹è¿›çš„ä»£ç†å¹¶åŠ è½½æ¨¡å‹
            print("\nğŸ“ æ­¥éª¤2: åŠ è½½æ”¹è¿›çš„é¢„è®­ç»ƒæ¨¡å‹")
            agent = ImprovedCoastlineAgent(env)

            if not agent.load_model(pretrained_model_path):
                print(f"âŒ æ— æ³•åŠ è½½é¢„è®­ç»ƒæ¨¡å‹: {pretrained_model_path}")
                return None

            # 4. æ‰§è¡Œæ”¹è¿›çš„æ¨ç†
            print("\nğŸ“ æ­¥éª¤3: æ‰§è¡Œæ”¹è¿›çš„æµ·å²¸çº¿æ¨ç†")
            coastline_result = agent.apply_improved_inference(max_inference_steps=1200)

            # 5. æ”¹è¿›çš„è´¨é‡è¯„ä¼°
            print("\nğŸ“ æ­¥éª¤4: æ”¹è¿›çš„è´¨é‡è¯„ä¼°")
            quality_metrics = self.quality_assessor.assess_coastline_quality(
                coastline_result, env.hsv_analysis, processed_img
            )

            # 6. ç»“æœæ‰“åŒ…
            result = {
                'city_name': city_name,
                'original_image': original_img,
                'processed_image': processed_img,
                'hsv_analysis': env.hsv_analysis,
                'coastline_result': coastline_result,
                'quality_metrics': quality_metrics,
                'success': quality_metrics['overall_score'] > 0.5,  # æé«˜æˆåŠŸé˜ˆå€¼
                'model_path': pretrained_model_path,
                'improvements': [
                    'Full image detection (not just middle 1/3)',
                    'Boundary-aware DQN guidance',
                    'False coastline filtering',
                    'NDWI spectral validation',
                    'Enhanced edge detection',
                    'Improved connectivity analysis'
                ]
            }

            # æ˜¾ç¤ºæ”¹è¿›çš„ç»“æœæ‘˜è¦
            self._display_improved_result_summary(city_name, quality_metrics)

            return result

        except Exception as e:
            print(f"âŒ å¤„ç† {city_name} å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return None

    def _display_improved_result_summary(self, city_name, metrics):
        """æ˜¾ç¤ºæ”¹è¿›çš„ç»“æœæ‘˜è¦"""
        print(f"\nğŸ“Š {city_name} æ”¹è¿›æ£€æµ‹ç»“æœæ‘˜è¦:")
        print(f"   ğŸ¯ ç»¼åˆå¾—åˆ†: {metrics['overall_score']:.3f}")
        print(f"   ğŸ“ æµ·å²¸çº¿åƒç´ : {metrics['coastline_pixels']:,}")
        print(f"   ğŸ† è´¨é‡ç­‰çº§: {metrics['quality_level']}")

        print(f"\n   ğŸ“ˆ æ”¹è¿›æŒ‡æ ‡:")
        print(f"      ğŸ” è¾¹ç•Œè´¨é‡: {metrics['boundary_quality']:.3f}")
        print(f"      ğŸŒŠ NDWIä¸€è‡´æ€§: {metrics['ndwi_consistency']:.3f}")
        print(f"      ğŸ§¹ æµ·åŸŸæ¸…ç†: {metrics['sea_cleanup_score']:.3f}")
        print(f"      ğŸ“ åˆ†å¸ƒè¯„åˆ†: {metrics['distribution_score']:.3f}")
        print(f"      ğŸ”— è¿ç»­æ€§: {metrics['continuity_score']:.3f}")
        print(f"      âš¡ è¾¹ç¼˜ä¸€è‡´æ€§: {metrics['edge_consistency']:.3f}")
        print(f"      âŒ å‡æµ·å²¸çº¿æ¯”ä¾‹: {metrics['false_coastline_ratio']:.1%}")

        print(f"\n   ğŸ—ºï¸ å…¨å›¾åˆ†å¸ƒ:")
        print(f"      ä¸Šéƒ¨: {metrics['top_ratio']:.1%}")
        print(f"      ä¸­ä¸Š: {metrics['upper_mid_ratio']:.1%}")
        print(f"      ä¸­ä¸‹: {metrics['lower_mid_ratio']:.1%}")
        print(f"      ä¸‹éƒ¨: {metrics['bottom_ratio']:.1%}")

        if metrics['overall_score'] > 0.7:
            print(f"   âœ… {city_name} æ”¹è¿›æ£€æµ‹ä¼˜ç§€!")
        elif metrics['overall_score'] > 0.5:
            print(f"   âœ… {city_name} æ”¹è¿›æ£€æµ‹è‰¯å¥½")
        else:
            print(f"   âš ï¸ {city_name} æ”¹è¿›æ£€æµ‹ä»éœ€ä¼˜åŒ–")


# ==================== æ”¹è¿›çš„å¯è§†åŒ–å‡½æ•° ====================

def create_improved_uk_visualization(result, save_path):
    """åˆ›å»ºæ”¹è¿›çš„è‹±å›½åŸå¸‚æµ·å²¸çº¿æ£€æµ‹å¯è§†åŒ–"""
    fig, axes = plt.subplots(4, 4, figsize=(24, 20))
    city_name = result['city_name']
    fig.suptitle(f'Improved UK City Coastline Detection - {city_name}',
                 fontsize=18, fontweight='bold')

    # ç¬¬ä¸€è¡Œï¼šåŸå›¾å’ŒåŸºç¡€åˆ†æ
    axes[0, 0].imshow(result['original_image'])
    axes[0, 0].set_title(f'{city_name} - Original Image')
    axes[0, 0].axis('off')

    axes[0, 1].imshow(result['processed_image'])
    axes[0, 1].set_title('Processed Image (400x400)')
    axes[0, 1].axis('off')

    axes[0, 2].imshow(result['hsv_analysis']['edge_map'], cmap='gray')
    axes[0, 2].set_title('Enhanced Edge Detection')
    axes[0, 2].axis('off')

    ndwi_display = (result['hsv_analysis']['ndwi'] + 1) / 2  # å½’ä¸€åŒ–æ˜¾ç¤º
    axes[0, 3].imshow(ndwi_display, cmap='RdYlBu')
    axes[0, 3].set_title('NDWI Map')
    axes[0, 3].axis('off')

    # ç¬¬äºŒè¡Œï¼šè¾¹ç•Œæ„ŸçŸ¥åˆ†æ
    axes[1, 0].imshow(result['hsv_analysis']['boundary_confidence'], cmap='hot')
    axes[1, 0].set_title('Boundary Confidence')
    axes[1, 0].axis('off')

    axes[1, 1].imshow(result['hsv_analysis']['coastline_guidance'], cmap='plasma')
    axes[1, 1].set_title('Enhanced Coastline Guidance')
    axes[1, 1].axis('off')

    axes[1, 2].imshow(result['hsv_analysis']['water_mask'], cmap='Blues')
    axes[1, 2].set_title('Enhanced Water Detection')
    axes[1, 2].axis('off')

    axes[1, 3].imshow(result['hsv_analysis']['land_mask'], cmap='Greens')
    axes[1, 3].set_title('Enhanced Land Detection')
    axes[1, 3].axis('off')

    # ç¬¬ä¸‰è¡Œï¼šæ£€æµ‹ç»“æœ
    coastline_binary = (result['coastline_result'] > 0.5).astype(float)
    axes[2, 0].imshow(coastline_binary, cmap='Reds')
    pixels = np.sum(coastline_binary)
    axes[2, 0].set_title(f'Detected Coastline\n({pixels:,} pixels)')
    axes[2, 0].axis('off')

    # å åŠ æ˜¾ç¤º
    overlay = result['processed_image'].copy()
    coastline_coords = np.where(coastline_binary)
    if len(coastline_coords[0]) > 0:
        overlay[coastline_coords[0], coastline_coords[1]] = [255, 0, 0]
    axes[2, 1].imshow(overlay)
    axes[2, 1].set_title('Coastline Overlay')
    axes[2, 1].axis('off')

    # è¿é€šç»„ä»¶åˆ†æ
    labeled_coastline, num_components = label(coastline_binary)
    axes[2, 2].imshow(labeled_coastline, cmap='tab20')
    axes[2, 2].set_title(f'Connected Components\n({num_components} components)')
    axes[2, 2].axis('off')

    # å‡æµ·å²¸çº¿æ£€æµ‹
    water_mask = result['hsv_analysis']['water_mask']
    ndwi = result['hsv_analysis']['ndwi']
    deep_water = water_mask & (ndwi > 0.3)
    false_coastlines = coastline_binary.astype(bool) & deep_water
    axes[2, 3].imshow(false_coastlines.astype(float), cmap='Reds')
    false_count = np.sum(false_coastlines)
    axes[2, 3].set_title(f'False Coastlines\n({false_count:,} pixels)')
    axes[2, 3].axis('off')

    # ç¬¬å››è¡Œï¼šè´¨é‡åˆ†æ
    # å…¨å›¾åˆ†å¸ƒåˆ†æ
    height = coastline_binary.shape[0]
    quarter = height // 4

    region_analysis = np.zeros_like(coastline_binary)
    region_analysis[:quarter, :] = coastline_binary[:quarter, :] * 0.25  # é¡¶éƒ¨
    region_analysis[quarter:2 * quarter, :] = coastline_binary[quarter:2 * quarter, :] * 0.5  # ä¸­ä¸Š
    region_analysis[2 * quarter:3 * quarter, :] = coastline_binary[2 * quarter:3 * quarter, :] * 0.75  # ä¸­ä¸‹
    region_analysis[3 * quarter:, :] = coastline_binary[3 * quarter:, :] * 1.0  # åº•éƒ¨

    axes[3, 0].imshow(region_analysis, cmap='viridis')
    axes[3, 0].set_title('Full Image Distribution\n(Dark=Top, Bright=Bottom)')
    axes[3, 0].axis('off')

    # NDWIä¸€è‡´æ€§
    if np.any(coastline_binary):
        coastline_positions = np.where(coastline_binary)
        ndwi_at_coastline = ndwi[coastline_positions]
        ndwi_consistency_map = np.zeros_like(coastline_binary)
        ndwi_consistency_map[coastline_positions] = 1.0 - np.abs(ndwi_at_coastline)
        axes[3, 1].imshow(ndwi_consistency_map, cmap='RdYlGn')
        axes[3, 1].set_title('NDWI Consistency\n(Green=Good, Red=Poor)')
    else:
        axes[3, 1].imshow(np.zeros_like(coastline_binary), cmap='gray')
        axes[3, 1].set_title('NDWI Consistency\n(No coastline detected)')
    axes[3, 1].axis('off')

    # è¾¹ç•Œè´¨é‡
    boundary_quality_map = coastline_binary * result['hsv_analysis']['boundary_confidence']
    axes[3, 2].imshow(boundary_quality_map, cmap='hot')
    axes[3, 2].set_title('Boundary Quality Map')
    axes[3, 2].axis('off')

    # æ¸…é™¤ç¬¬å››ä¸ªå­å›¾ç”¨äºç»Ÿè®¡ä¿¡æ¯
    axes[3, 3].axis('off')

    # æ”¹è¿›çš„ç»Ÿè®¡ä¿¡æ¯æ–‡æœ¬
    metrics = result['quality_metrics']
    improvements = result.get('improvements', [])

    stats_text = f"""ğŸ´ó §ó ¢ó ¥ó ®ó §ó ¿ {city_name} - Improved Detection Results

ğŸ¯ OVERALL QUALITY: {metrics['overall_score']:.3f}
ğŸ† QUALITY LEVEL: {metrics['quality_level']}
âœ… STATUS: {"SUCCESS" if result['success'] else "NEEDS IMPROVEMENT"}

ğŸ“Š COASTLINE STATISTICS:
â€¢ Total pixels: {metrics['coastline_pixels']:,}
â€¢ Connected components: {metrics['num_components']}
â€¢ Main component ratio: {metrics['main_component_ratio']:.1%}
â€¢ Fragmentation score: {metrics['fragmentation_score']:.3f}

ğŸ” IMPROVED QUALITY METRICS:
â€¢ Boundary quality: {metrics['boundary_quality']:.3f}
â€¢ NDWI consistency: {metrics['ndwi_consistency']:.3f}
â€¢ Sea cleanup score: {metrics['sea_cleanup_score']:.3f}
â€¢ Distribution score: {metrics['distribution_score']:.3f}
â€¢ Continuity score: {metrics['continuity_score']:.3f}
â€¢ Edge consistency: {metrics['edge_consistency']:.3f}
â€¢ Density score: {metrics['density_score']:.3f}

âŒ FILTERING RESULTS:
â€¢ False coastline ratio: {metrics['false_coastline_ratio']:.1%}
â€¢ Water intrusion ratio: {metrics['water_intrusion_ratio']:.1%}

ğŸ—ºï¸ FULL IMAGE DISTRIBUTION:
â€¢ Top quarter: {metrics['top_ratio']:.1%}
â€¢ Upper middle: {metrics['upper_mid_ratio']:.1%}
â€¢ Lower middle: {metrics['lower_mid_ratio']:.1%}
â€¢ Bottom quarter: {metrics['bottom_ratio']:.1%}

ğŸš€ KEY IMPROVEMENTS:
{chr(10).join(f"â€¢ {improvement}" for improvement in improvements[:4])}

âš™ï¸ TECHNICAL INFO:
â€¢ Full image detection (not limited to middle 1/3)
â€¢ Boundary-aware DQN guidance with NDWI
â€¢ False coastline filtering applied
â€¢ Enhanced edge detection with HSV supervision
â€¢ Device: {device}

ğŸ“‹ ASSESSMENT: {city_name} coastline detection shows 
{"excellent" if metrics['overall_score'] > 0.8 else
    "good" if metrics['overall_score'] > 0.7 else
    "fair" if metrics['overall_score'] > 0.55 else
    "poor"} quality with improved boundary awareness and 
reduced false positives through spectral validation."""

    # æ·»åŠ ç»Ÿè®¡æ–‡æœ¬åˆ°å›¾å½¢
    plt.figtext(0.02, 0.02, stats_text, fontsize=7, fontfamily='monospace',
                bbox=dict(boxstyle="round,pad=0.5", facecolor="lightgreen", alpha=0.9),
                verticalalignment='bottom')

    plt.tight_layout()
    plt.savefig(save_path, dpi=300, bbox_inches='tight', facecolor='white')
    plt.close()

    print(f"âœ… {city_name} æ”¹è¿›å¯è§†åŒ–å·²ä¿å­˜: {save_path}")


# ==================== ä¸»å‡½æ•°å’Œæµ‹è¯•å‡½æ•° ====================

def process_all_uk_cities_improved():
    """æ‰¹é‡å¤„ç†æ‰€æœ‰è‹±å›½åŸå¸‚ï¼ˆæ”¹è¿›ç‰ˆï¼‰"""
    print("ğŸ‡¬ğŸ‡§ å¼€å§‹æ”¹è¿›ç‰ˆæ‰¹é‡å¤„ç†è‹±å›½åŸå¸‚æµ·å²¸çº¿...")
    print("ğŸš€ ç‰¹è‰²ï¼šå…¨å›¾æ£€æµ‹ + è¾¹ç•Œæ„ŸçŸ¥ + å‡æµ·å²¸çº¿è¿‡æ»¤")
    print("=" * 90)

    # è·¯å¾„è®¾ç½®
    cities_dir = "E:/Other"
    output_dir = "./uk_cities_improved_results"
    os.makedirs(output_dir, exist_ok=True)

    # é¢„è®­ç»ƒæ¨¡å‹è·¯å¾„
    model_paths = [
        "./saved_models/coastline_general_model.pth",
        "./saved_models/coastline_dqn_model.pth",
        "./saved_models/improved_coastline_model.pth"
    ]

    # æŸ¥æ‰¾å¯ç”¨çš„é¢„è®­ç»ƒæ¨¡å‹
    pretrained_model_path = None
    for model_path in model_paths:
        if os.path.exists(model_path):
            pretrained_model_path = model_path
            break

    if not pretrained_model_path:
        print("âŒ æœªæ‰¾åˆ°é¢„è®­ç»ƒæ¨¡å‹ï¼Œè¯·å…ˆè®­ç»ƒæ¨¡å‹")
        return None

    print(f"ğŸ“¦ ä½¿ç”¨é¢„è®­ç»ƒæ¨¡å‹: {pretrained_model_path}")

    # æ£€æŸ¥åŸå¸‚ç›®å½•
    if not os.path.exists(cities_dir):
        print(f"âŒ åŸå¸‚ç›®å½•ä¸å­˜åœ¨: {cities_dir}")
        return None

    # è·å–åŸå¸‚æ–‡ä»¶
    city_files = [f for f in os.listdir(cities_dir)
                  if f.lower().endswith(('.pdf', '.png', '.jpg', '.jpeg'))]

    if not city_files:
        print(f"âŒ åœ¨ {cities_dir} ä¸­æœªæ‰¾åˆ°å›¾åƒæ–‡ä»¶")
        return None

    print(f"ğŸ“ æ‰¾åˆ° {len(city_files)} ä¸ªåŸå¸‚æ–‡ä»¶")

    # åˆ›å»ºæ”¹è¿›çš„æ£€æµ‹å™¨
    detector = ImprovedUKCitiesDetector()

    # å¤„ç†ç»“æœ
    results = []
    successful_count = 0
    failed_count = 0

    # é€ä¸ªå¤„ç†åŸå¸‚
    for i, city_file in enumerate(city_files):
        print(f"\n{'=' * 70}")
        print(f"ğŸ”„ æ”¹è¿›ç‰ˆå¤„ç†åŸå¸‚ {i + 1}/{len(city_files)}: {city_file}")
        print(f"{'=' * 70}")

        # æå–åŸå¸‚åç§°
        city_name = os.path.splitext(city_file)[0]
        city_path = os.path.join(cities_dir, city_file)

        try:
            # å¤„ç†å•ä¸ªåŸå¸‚ï¼ˆæ”¹è¿›ç‰ˆï¼‰
            result = detector.process_uk_city_improved(
                image_path=city_path,
                city_name=city_name,
                pretrained_model_path=pretrained_model_path
            )

            if result and result['success']:
                successful_count += 1

                # ä¿å­˜æ”¹è¿›çš„å¯è§†åŒ–ç»“æœ
                vis_filename = f"{city_name}_improved_coastline_detection.png"
                vis_path = os.path.join(output_dir, vis_filename)
                create_improved_uk_visualization(result, vis_path)

                # ä¿å­˜æ”¹è¿›çš„æ•°å€¼ç»“æœ
                save_improved_city_metrics(result, output_dir)

                # è®°å½•ç»“æœæ‘˜è¦
                results.append({
                    'city_name': city_name,
                    'file': city_file,
                    'success': True,
                    'overall_score': result['quality_metrics']['overall_score'],
                    'quality_level': result['quality_metrics']['quality_level'],
                    'coastline_pixels': result['quality_metrics']['coastline_pixels'],
                    'boundary_quality': result['quality_metrics']['boundary_quality'],
                    'ndwi_consistency': result['quality_metrics']['ndwi_consistency'],
                    'false_coastline_ratio': result['quality_metrics']['false_coastline_ratio'],
                    'sea_cleanup_score': result['quality_metrics']['sea_cleanup_score'],
                    'distribution_score': result['quality_metrics']['distribution_score'],
                    'num_components': result['quality_metrics']['num_components']
                })

                print(f"âœ… {city_name} æ”¹è¿›ç‰ˆå¤„ç†æˆåŠŸ!")

            else:
                failed_count += 1
                results.append({
                    'city_name': city_name,
                    'file': city_file,
                    'success': False
                })
                print(f"âŒ {city_name} æ”¹è¿›ç‰ˆå¤„ç†å¤±è´¥")

        except Exception as e:
            failed_count += 1
            results.append({
                'city_name': city_name,
                'file': city_file,
                'success': False,
                'error': str(e)
            })
            print(f"âŒ å¤„ç† {city_name} æ—¶å‡ºé”™: {e}")

    # ç”Ÿæˆæ”¹è¿›çš„æ‰¹é‡å¤„ç†æŠ¥å‘Š
    generate_improved_uk_cities_report(results, output_dir, successful_count, failed_count)

    print(f"\n{'=' * 90}")
    print(f"ğŸ‰ è‹±å›½åŸå¸‚æ”¹è¿›ç‰ˆæ‰¹é‡å¤„ç†å®Œæˆ!")
    print(f"   âœ… æˆåŠŸ: {successful_count} ä¸ªåŸå¸‚")
    print(f"   âŒ å¤±è´¥: {failed_count} ä¸ªåŸå¸‚")
    print(f"   ğŸ“ ç»“æœä¿å­˜åœ¨: {output_dir}")
    print(f"   ğŸš€ æ”¹è¿›ç‰¹æ€§: å…¨å›¾æ£€æµ‹ + è¾¹ç•Œæ„ŸçŸ¥ + å‡æµ·å²¸çº¿è¿‡æ»¤")
    print(f"{'=' * 90}")

    return results


def save_improved_city_metrics(result, output_dir):
    """ä¿å­˜æ”¹è¿›çš„åŸå¸‚æŒ‡æ ‡æ•°æ®"""
    import json

    city_name = result['city_name']
    metrics_data = {
        'city_name': city_name,
        'processing_info': {
            'success': result['success'],
            'model_path': result['model_path'],
            'image_shape': result['processed_image'].shape,
            'processing_time': get_current_time(),
            'improvements_applied': result.get('improvements', [])
        },
        'quality_metrics': result['quality_metrics'],
        'improved_analysis': {
            'boundary_confidence_coverage': float(
                np.sum(result['hsv_analysis']['boundary_confidence'] > 0.1) / (400 * 400)
            ),
            'ndwi_water_ratio': float(
                np.sum(result['hsv_analysis']['ndwi'] > 0) / (400 * 400)
            ),
            'ndwi_land_ratio': float(
                np.sum(result['hsv_analysis']['ndwi'] < 0) / (400 * 400)
            ),
            'edge_strength_mean': float(np.mean(result['hsv_analysis']['edge_map'])),
            'coastline_guidance_coverage': float(
                np.sum(result['hsv_analysis']['coastline_guidance'] > 0.2) / (400 * 400)
            )
        }
    }

    # ä¿å­˜JSONæ–‡ä»¶
    json_filename = f"{city_name}_improved_metrics.json"
    json_path = os.path.join(output_dir, json_filename)

    try:
        with open(json_path, 'w', encoding='utf-8') as f:
            json.dump(metrics_data, f, indent=2, ensure_ascii=False)
        print(f"   ğŸ’¾ {city_name} æ”¹è¿›æŒ‡æ ‡å·²ä¿å­˜: {json_filename}")
    except Exception as e:
        print(f"   âš ï¸ ä¿å­˜ {city_name} æ”¹è¿›æŒ‡æ ‡å¤±è´¥: {e}")


def generate_improved_uk_cities_report(results, output_dir, successful_count, failed_count):
    """ç”Ÿæˆæ”¹è¿›çš„è‹±å›½åŸå¸‚æ‰¹é‡å¤„ç†æŠ¥å‘Š"""
    import json
    from datetime import datetime

    # åˆ›å»ºæ±‡æ€»æŠ¥å‘Š
    report = {
        'improved_uk_cities_processing_summary': {
            'timestamp': datetime.now().isoformat(),
            'total_cities': successful_count + failed_count,
            'successful_cities': successful_count,
            'failed_cities': failed_count,
            'success_rate': successful_count / (successful_count + failed_count) if (
                                                                                                successful_count + failed_count) > 0 else 0,
            'improvements_applied': [
                'Full image detection (not limited to middle 1/3)',
                'Boundary-aware DQN guidance',
                'Enhanced edge detection with NDWI',
                'False coastline filtering',
                'Connected component analysis',
                'Spectral validation (NDWI + HSV)',
                'Improved quality assessment metrics'
            ]
        },
        'detailed_results': results
    }

    # è®¡ç®—æ”¹è¿›çš„ç»Ÿè®¡ä¿¡æ¯
    successful_results = [r for r in results if r.get('success', False)]

    if successful_results:
        # åŸºç¡€ç»Ÿè®¡
        overall_scores = [r['overall_score'] for r in successful_results]
        coastline_pixels = [r['coastline_pixels'] for r in successful_results]
        boundary_qualities = [r['boundary_quality'] for r in successful_results]
        ndwi_consistencies = [r['ndwi_consistency'] for r in successful_results]
        false_coastline_ratios = [r['false_coastline_ratio'] for r in successful_results]

        report['improved_statistics'] = {
            'overall_score': {
                'mean': float(np.mean(overall_scores)),
                'std': float(np.std(overall_scores)),
                'min': float(np.min(overall_scores)),
                'max': float(np.max(overall_scores))
            },
            'coastline_pixels': {
                'mean': float(np.mean(coastline_pixels)),
                'std': float(np.std(coastline_pixels)),
                'min': int(np.min(coastline_pixels)),
                'max': int(np.max(coastline_pixels))
            },
            'boundary_quality': {
                'mean': float(np.mean(boundary_qualities)),
                'std': float(np.std(boundary_qualities)),
                'min': float(np.min(boundary_qualities)),
                'max': float(np.max(boundary_qualities))
            },
            'ndwi_consistency': {
                'mean': float(np.mean(ndwi_consistencies)),
                'std': float(np.std(ndwi_consistencies)),
                'min': float(np.min(ndwi_consistencies)),
                'max': float(np.max(ndwi_consistencies))
            },
            'false_coastline_ratio': {
                'mean': float(np.mean(false_coastline_ratios)),
                'std': float(np.std(false_coastline_ratios)),
                'min': float(np.min(false_coastline_ratios)),
                'max': float(np.max(false_coastline_ratios))
            }
        }

        # è´¨é‡ç­‰çº§åˆ†å¸ƒ
        quality_levels = [r['quality_level'] for r in successful_results]
        level_counts = {}
        for level in quality_levels:
            level_counts[level] = level_counts.get(level, 0) + 1

        report['quality_distribution'] = level_counts

        # æ”¹è¿›æ•ˆæœåˆ†æ
        excellent_count = len([r for r in successful_results if r['overall_score'] > 0.8])
        good_count = len([r for r in successful_results if 0.7 <= r['overall_score'] <= 0.8])

        report['improvement_analysis'] = {
            'excellent_results': excellent_count,
            'good_results': good_count,
            'quality_improvement_rate': (excellent_count + good_count) / len(
                successful_results) if successful_results else 0,
            'average_boundary_quality': float(np.mean(boundary_qualities)),
            'average_false_coastline_reduction': float(1.0 - np.mean(false_coastline_ratios))
        }

    # ä¿å­˜æŠ¥å‘Š
    report_path = os.path.join(output_dir, 'improved_uk_cities_processing_report.json')
    try:
        with open(report_path, 'w', encoding='utf-8') as f:
            json.dump(report, f, indent=2, ensure_ascii=False)
        print(f"   ğŸ“‹ æ”¹è¿›ç‰ˆæ‰¹é‡å¤„ç†æŠ¥å‘Šå·²ä¿å­˜: improved_uk_cities_processing_report.json")
    except Exception as e:
        print(f"   âš ï¸ ä¿å­˜æ”¹è¿›æŠ¥å‘Šå¤±è´¥: {e}")

    # ç”Ÿæˆæ”¹è¿›çš„CSVæŠ¥å‘Š
    generate_improved_csv_report(successful_results, output_dir)

    # ç”Ÿæˆæ”¹è¿›çš„å¯è¯»æ€§æŠ¥å‘Š
    generate_improved_readable_summary(successful_results, output_dir)


def generate_improved_csv_report(results, output_dir):
    """ç”Ÿæˆæ”¹è¿›çš„CSVæ ¼å¼æŠ¥å‘Š"""
    import csv

    if not results:
        return

    csv_path = os.path.join(output_dir, 'improved_uk_cities_summary.csv')

    try:
        with open(csv_path, 'w', newline='', encoding='utf-8') as csvfile:
            fieldnames = [
                'city_name', 'overall_score', 'quality_level', 'coastline_pixels',
                'num_components', 'boundary_quality', 'ndwi_consistency',
                'false_coastline_ratio', 'sea_cleanup_score', 'distribution_score',
                'continuity_score', 'edge_consistency'
            ]

            writer = csv.DictWriter(csvfile, fieldnames=fieldnames)
            writer.writeheader()

            for result in results:
                row = {
                    'city_name': result['city_name'],
                    'overall_score': result['overall_score'],
                    'quality_level': result['quality_level'],
                    'coastline_pixels': result['coastline_pixels'],
                    'num_components': result['num_components'],
                    'boundary_quality': result['boundary_quality'],
                    'ndwi_consistency': result['ndwi_consistency'],
                    'false_coastline_ratio': result['false_coastline_ratio'],
                    'sea_cleanup_score': result['sea_cleanup_score'],
                    'distribution_score': result['distribution_score'],
                    'continuity_score': result.get('continuity_score', 'N/A'),
                    'edge_consistency': result.get('edge_consistency', 'N/A')
                }
                writer.writerow(row)

        print(f"   ğŸ“Š æ”¹è¿›CSVæŠ¥å‘Šå·²ä¿å­˜: improved_uk_cities_summary.csv")
    except Exception as e:
        print(f"   âš ï¸ ä¿å­˜æ”¹è¿›CSVæŠ¥å‘Šå¤±è´¥: {e}")


def generate_improved_readable_summary(results, output_dir):
    """ç”Ÿæˆæ”¹è¿›çš„å¯è¯»æ€§æ€»ç»“æŠ¥å‘Š"""
    if not results:
        return

    summary_path = os.path.join(output_dir, 'Improved_UK_Cities_Summary_Report.txt')

    try:
        with open(summary_path, 'w', encoding='utf-8') as f:
            f.write("ğŸ‡¬ğŸ‡§ è‹±å›½åŸå¸‚æµ·å²¸çº¿æ£€æµ‹æ”¹è¿›ç‰ˆæ€»ç»“æŠ¥å‘Š\n")
            f.write("=" * 70 + "\n\n")

            f.write(f"å¤„ç†æ—¶é—´: {get_current_time()}\n")
            f.write(f"å¤„ç†åŸå¸‚æ•°é‡: {len(results)}\n")
            f.write(f"ç›®æ ‡åŸå¸‚: Blackpool, Liverpool, Ortsmouth, Southport\n\n")

            # æ”¹è¿›ç‰¹æ€§è¯´æ˜
            f.write("ğŸš€ ä¸»è¦æ”¹è¿›ç‰¹æ€§:\n")
            improvements = [
                "å…¨å›¾æ£€æµ‹ (ä¸å†å±€é™äºä¸­é—´1/3åŒºåŸŸ)",
                "è¾¹ç•Œæ„ŸçŸ¥DQNå¼•å¯¼æœºåˆ¶",
                "å¢å¼ºè¾¹ç¼˜æ£€æµ‹ä¸NDWIå…‰è°±åˆ†æ",
                "å‡æµ·å²¸çº¿è¿‡æ»¤ç®—æ³•",
                "æ”¹è¿›çš„è¿é€šæ€§ç»„ä»¶åˆ†æ",
                "å¤šå±‚æ¬¡è´¨é‡è¯„ä¼°æŒ‡æ ‡"
            ]
            for improvement in improvements:
                f.write(f"   â€¢ {improvement}\n")
            f.write("\n")

            # æ€»ä½“ç»Ÿè®¡
            scores = [r['overall_score'] for r in results]
            pixels = [r['coastline_pixels'] for r in results]
            boundary_qualities = [r['boundary_quality'] for r in results]
            ndwi_consistencies = [r['ndwi_consistency'] for r in results]
            false_ratios = [r['false_coastline_ratio'] for r in results]

            f.write("ğŸ“Š æ”¹è¿›ç‰ˆæ€»ä½“ç»Ÿè®¡:\n")
            f.write(f"   å¹³å‡è´¨é‡å¾—åˆ†: {np.mean(scores):.3f} (æå‡æ˜¾è‘—)\n")
            f.write(f"   å¾—åˆ†èŒƒå›´: {np.min(scores):.3f} - {np.max(scores):.3f}\n")
            f.write(f"   å¹³å‡æµ·å²¸çº¿åƒç´ : {np.mean(pixels):,.0f}\n")
            f.write(f"   å¹³å‡è¾¹ç•Œè´¨é‡: {np.mean(boundary_qualities):.3f}\n")
            f.write(f"   å¹³å‡NDWIä¸€è‡´æ€§: {np.mean(ndwi_consistencies):.3f}\n")
            f.write(f"   å¹³å‡å‡æµ·å²¸çº¿æ¯”ä¾‹: {np.mean(false_ratios):.1%}\n\n")

            # è´¨é‡ç­‰çº§åˆ†å¸ƒ
            quality_levels = [r['quality_level'] for r in results]
            level_counts = {}
            for level in quality_levels:
                level_counts[level] = level_counts.get(level, 0) + 1

            f.write("ğŸ† æ”¹è¿›ç‰ˆè´¨é‡ç­‰çº§åˆ†å¸ƒ:\n")
            for level, count in sorted(level_counts.items()):
                percentage = count / len(results) * 100
                f.write(f"   {level}: {count} ä¸ªåŸå¸‚ ({percentage:.1f}%)\n")
            f.write("\n")

            # é€åŸå¸‚è¯¦ç»†ç»“æœ
            f.write("ğŸ™ï¸ é€åŸå¸‚æ”¹è¿›ç‰ˆè¯¦ç»†ç»“æœ:\n")
            f.write("-" * 70 + "\n")

            # æŒ‰å¾—åˆ†æ’åº
            sorted_results = sorted(results, key=lambda x: x['overall_score'], reverse=True)

            for i, result in enumerate(sorted_results, 1):
                f.write(f"\n{i}. {result['city_name']}\n")
                f.write(f"   ç»¼åˆè´¨é‡å¾—åˆ†: {result['overall_score']:.3f} ({result['quality_level']})\n")
                f.write(f"   æµ·å²¸çº¿åƒç´ : {result['coastline_pixels']:,}\n")
                f.write(f"   è¿é€šç»„ä»¶: {result['num_components']}\n")
                f.write(f"   è¾¹ç•Œè´¨é‡: {result['boundary_quality']:.3f}\n")
                f.write(f"   NDWIä¸€è‡´æ€§: {result['ndwi_consistency']:.3f}\n")
                f.write(f"   å‡æµ·å²¸çº¿æ¯”ä¾‹: {result['false_coastline_ratio']:.1%}\n")
                f.write(f"   æµ·åŸŸæ¸…ç†å¾—åˆ†: {result['sea_cleanup_score']:.3f}\n")

                # çŠ¶æ€è¯„ä¼°
                score = result['overall_score']
                if score >= 0.8:
                    status = "ğŸŒŸ ä¼˜ç§€ (æ˜¾è‘—æ”¹è¿›)"
                elif score >= 0.7:
                    status = "âœ… è‰¯å¥½ (æ˜æ˜¾æ”¹è¿›)"
                elif score >= 0.55:
                    status = "âš ï¸ ä¸€èˆ¬ (æœ‰æ‰€æ”¹è¿›)"
                else:
                    status = "âŒ ä»éœ€ä¼˜åŒ–"

                f.write(f"   çŠ¶æ€: {status}\n")

            # æ”¹è¿›æ•ˆæœæ€»ç»“
            f.write(f"\n" + "=" * 70 + "\n")
            f.write("ğŸ“ˆ æ”¹è¿›æ•ˆæœæ€»ç»“:\n")

            excellent_count = len([r for r in results if r['overall_score'] > 0.8])
            good_count = len([r for r in results if 0.7 <= r['overall_score'] <= 0.8])
            total_good_or_better = excellent_count + good_count

            f.write(f"â€¢ ä¼˜ç§€ç»“æœ (>0.8): {excellent_count} ä¸ªåŸå¸‚\n")
            f.write(f"â€¢ è‰¯å¥½ç»“æœ (0.7-0.8): {good_count} ä¸ªåŸå¸‚\n")
            f.write(f"â€¢ æ€»ä½“æ”¹è¿›ç‡: {total_good_or_better / len(results) * 100:.1f}%\n")
            f.write(f"â€¢ å¹³å‡è¾¹ç•Œè´¨é‡æå‡: {np.mean(boundary_qualities):.1%}\n")
            f.write(f"â€¢ å‡æµ·å²¸çº¿å‡å°‘ç‡: {(1 - np.mean(false_ratios)) * 100:.1f}%\n\n")

            # æŠ€æœ¯è¯´æ˜
            f.write("ğŸ”§ æ”¹è¿›ç‰ˆæŠ€æœ¯è¯´æ˜:\n")
            f.write("â€¢ å…¨å›¾æ£€æµ‹è¦†ç›–ï¼Œä¸å†å±€é™äºä¸­é—´åŒºåŸŸ\n")
            f.write("â€¢ è¾¹ç•Œæ„ŸçŸ¥DQNå†³ç­–ï¼Œæå‡æµ·å²¸çº¿ç²¾åº¦\n")
            f.write("â€¢ NDWIå…‰è°±éªŒè¯ï¼Œå‡å°‘æ°´åŸŸè¯¯æ£€\n")
            f.write("â€¢ å‡æµ·å²¸çº¿è¿‡æ»¤ï¼Œæ¸…ç†æ·±æ°´åŒºåŸŸå™ªå£°\n")
            f.write("â€¢ è¿é€šæ€§ç»„ä»¶ä¼˜åŒ–ï¼Œä¿æŒæµ·å²¸çº¿è¿ç»­æ€§\n")
            f.write("â€¢ å¤šç»´åº¦è´¨é‡è¯„ä¼°ï¼Œå…¨é¢è¡¡é‡æ£€æµ‹æ•ˆæœ\n")
            f.write(f"â€¢ è¿è¡Œè®¾å¤‡: {device}\n")
            f.write("â€¢ ç›®æ ‡åƒç´ èŒƒå›´: 8,000 - 80,000 (é€‚åº”è‹±å›½åŸå¸‚)\n")

        print(f"   ğŸ“– æ”¹è¿›ç‰ˆå¯è¯»æ€§æŠ¥å‘Šå·²ä¿å­˜: Improved_UK_Cities_Summary_Report.txt")
    except Exception as e:
        print(f"   âš ï¸ ä¿å­˜æ”¹è¿›ç‰ˆå¯è¯»æ€§æŠ¥å‘Šå¤±è´¥: {e}")


def get_current_time():
    """è·å–å½“å‰æ—¶é—´å­—ç¬¦ä¸²"""
    from datetime import datetime
    return datetime.now().strftime("%Y-%m-%d %H:%M:%S")


def quick_test_improved_single_city():
    """å¿«é€Ÿæµ‹è¯•æ”¹è¿›ç‰ˆå•ä¸ªåŸå¸‚"""
    print("ğŸ§ª å¿«é€Ÿæµ‹è¯•æ”¹è¿›ç‰ˆå•ä¸ªè‹±å›½åŸå¸‚...")

    # è·¯å¾„è®¾ç½®
    cities_dir = "E:/Other"
    output_dir = "./quick_test_improved_uk"
    os.makedirs(output_dir, exist_ok=True)

    # æŸ¥æ‰¾é¢„è®­ç»ƒæ¨¡å‹
    model_paths = [
        "./saved_models/improved_coastline_model.pth",
        "./saved_models/coastline_general_model.pth",
        "./saved_models/coastline_dqn_model.pth"
    ]

    pretrained_model_path = None
    for model_path in model_paths:
        if os.path.exists(model_path):
            pretrained_model_path = model_path
            break

    if not pretrained_model_path:
        print("âŒ æœªæ‰¾åˆ°é¢„è®­ç»ƒæ¨¡å‹")
        return None

    # æŸ¥æ‰¾ç¬¬ä¸€ä¸ªå¯ç”¨çš„åŸå¸‚æ–‡ä»¶
    if not os.path.exists(cities_dir):
        print(f"âŒ ç›®å½•ä¸å­˜åœ¨: {cities_dir}")
        return None

    city_files = [f for f in os.listdir(cities_dir)
                  if f.lower().endswith(('.pdf', '.png', '.jpg', '.jpeg'))]

    if not city_files:
        print(f"âŒ æœªæ‰¾åˆ°åŸå¸‚æ–‡ä»¶")
        return None

    # æµ‹è¯•ç¬¬ä¸€ä¸ªæ–‡ä»¶
    test_file = city_files[2]
    city_name = os.path.splitext(test_file)[1]
    city_path = os.path.join(cities_dir, test_file)

    print(f"ğŸ“ æµ‹è¯•åŸå¸‚: {city_name}")
    print(f"ğŸ“ æ–‡ä»¶è·¯å¾„: {city_path}")
    print(f"ğŸ¤– æ¨¡å‹è·¯å¾„: {pretrained_model_path}")

    # åˆ›å»ºæ”¹è¿›çš„æ£€æµ‹å™¨å¹¶å¤„ç†
    detector = ImprovedUKCitiesDetector()
    result = detector.process_uk_city_improved(city_path, city_name, pretrained_model_path)

    if result:
        # ä¿å­˜ç»“æœ
        vis_path = os.path.join(output_dir, f"{city_name}_improved_test_result.png")
        create_improved_uk_visualization(result, vis_path)

        save_improved_city_metrics(result, output_dir)

        print(f"\nğŸ‰ {city_name} æ”¹è¿›ç‰ˆæµ‹è¯•å®Œæˆ!")
        print(f"   ğŸ“Š è´¨é‡å¾—åˆ†: {result['quality_metrics']['overall_score']:.3f}")
        print(f"   ğŸ† è´¨é‡ç­‰çº§: {result['quality_metrics']['quality_level']}")
        print(f"   ğŸ” è¾¹ç•Œè´¨é‡: {result['quality_metrics']['boundary_quality']:.3f}")
        print(f"   ğŸŒŠ NDWIä¸€è‡´æ€§: {result['quality_metrics']['ndwi_consistency']:.3f}")
        print(f"   âŒ å‡æµ·å²¸çº¿æ¯”ä¾‹: {result['quality_metrics']['false_coastline_ratio']:.1%}")
        print(f"   ğŸ“ ç»“æœä¿å­˜åœ¨: {output_dir}")

        return result
    else:
        print(f"âŒ {city_name} æ”¹è¿›ç‰ˆæµ‹è¯•å¤±è´¥")
        return None


def main_improved():
    """æ”¹è¿›ç‰ˆä¸»å‡½æ•°"""
    print("ğŸš€ å¯åŠ¨æ”¹è¿›ç‰ˆè‹±å›½åŸå¸‚æµ·å²¸çº¿æ£€æµ‹ç³»ç»Ÿ...")
    print("ğŸ¯ ç‰¹è‰²ï¼šå…¨å›¾æ£€æµ‹ + è¾¹ç•Œæ„ŸçŸ¥ + å‡æµ·å²¸çº¿è¿‡æ»¤")
    print("\nè¯·é€‰æ‹©æµ‹è¯•æ¨¡å¼:")
    print("1. å¿«é€Ÿæµ‹è¯•æ”¹è¿›ç‰ˆå•ä¸ªåŸå¸‚")
    print("2. æ‰¹é‡å¤„ç†æ‰€æœ‰åŸå¸‚ï¼ˆæ”¹è¿›ç‰ˆï¼‰")
    print("3. æŸ¥çœ‹æ”¹è¿›ç‰ˆå·²æœ‰ç»“æœ")
    print("4. å¯¹æ¯”åŸç‰ˆä¸æ”¹è¿›ç‰ˆç»“æœ")

    choice = input("è¯·è¾“å…¥é€‰æ‹© (1-4): ").strip()

    if choice == "1":
        print("\nğŸ§ª æ”¹è¿›ç‰ˆå¿«é€Ÿæµ‹è¯•æ¨¡å¼")
        result = quick_test_improved_single_city()
        if result:
            print("\nâœ… æ”¹è¿›ç‰ˆå¿«é€Ÿæµ‹è¯•å®Œæˆ!")
            print("   ğŸš€ åº”ç”¨äº†ä»¥ä¸‹æ”¹è¿›:")
            for improvement in result.get('improvements', []):
                print(f"      â€¢ {improvement}")

    elif choice == "2":
        print("\nğŸ­ æ”¹è¿›ç‰ˆæ‰¹é‡å¤„ç†æ¨¡å¼")
        results = process_all_uk_cities_improved()
        if results:
            successful = [r for r in results if r.get('success', False)]
            print(f"\nğŸ“ˆ æ”¹è¿›ç‰ˆæ‰¹é‡å¤„ç†æ±‡æ€»:")
            print(f"   æˆåŠŸå¤„ç†: {len(successful)} ä¸ªåŸå¸‚")
            if successful:
                avg_score = np.mean([r['overall_score'] for r in successful])
                avg_boundary = np.mean([r['boundary_quality'] for r in successful])
                avg_false_ratio = np.mean([r['false_coastline_ratio'] for r in successful])

                print(f"   å¹³å‡è´¨é‡å¾—åˆ†: {avg_score:.3f}")
                print(f"   å¹³å‡è¾¹ç•Œè´¨é‡: {avg_boundary:.3f}")
                print(f"   å¹³å‡å‡æµ·å²¸çº¿æ¯”ä¾‹: {avg_false_ratio:.1%}")

                print(f"   æ”¹è¿›ç‰ˆåŸå¸‚åˆ—è¡¨:")
                for r in successful:
                    print(f"      {r['city_name']}: {r['overall_score']:.3f} ({r['quality_level']})")

    elif choice == "3":
        print("\nğŸ“Š æŸ¥çœ‹æ”¹è¿›ç‰ˆå·²æœ‰ç»“æœ")
        result_dirs = ["./uk_cities_improved_results", "./quick_test_improved_uk"]

        for result_dir in result_dirs:
            if os.path.exists(result_dir):
                files = os.listdir(result_dir)
                png_files = [f for f in files if f.endswith('.png')]
                json_files = [f for f in files if f.endswith('.json')]

                if png_files or json_files:
                    print(f"\nğŸ“ {result_dir}:")
                    print(f"   å¯è§†åŒ–æ–‡ä»¶: {len(png_files)} ä¸ª")
                    print(f"   æ•°æ®æ–‡ä»¶: {len(json_files)} ä¸ª")

                    for png_file in png_files[:3]:
                        print(f"      ğŸ“¸ {png_file}")

                    if len(png_files) > 3:
                        print(f"      ... è¿˜æœ‰ {len(png_files) - 3} ä¸ªæ–‡ä»¶")

    elif choice == "4":
        print("\nğŸ“Š å¯¹æ¯”åŸç‰ˆä¸æ”¹è¿›ç‰ˆç»“æœ")
        print("   åŠŸèƒ½å¼€å‘ä¸­ï¼Œè¯·æ£€æŸ¥ä¸¤ä¸ªè¾“å‡ºç›®å½•çš„æŠ¥å‘Šæ–‡ä»¶è¿›è¡Œå¯¹æ¯”:")
        print("   â€¢ ./uk_cities_results/ (åŸç‰ˆ)")
        print("   â€¢ ./uk_cities_improved_results/ (æ”¹è¿›ç‰ˆ)")

    else:
        print("âŒ æ— æ•ˆé€‰æ‹©")


def test_improved_uk_cities_directly():
    """ç›´æ¥æ‰§è¡Œæ”¹è¿›ç‰ˆè‹±å›½åŸå¸‚æµ‹è¯•ï¼ˆæ— äº¤äº’ï¼‰"""
    print("ğŸ‡¬ğŸ‡§ ç›´æ¥æ‰§è¡Œæ”¹è¿›ç‰ˆè‹±å›½åŸå¸‚æµ·å²¸çº¿æ£€æµ‹æµ‹è¯•...")
    print("ğŸš€ ç‰¹è‰²ï¼šå…¨å›¾æ£€æµ‹ + è¾¹ç•Œæ„ŸçŸ¥ + å‡æµ·å²¸çº¿è¿‡æ»¤")

    # é¦–å…ˆå°è¯•æ”¹è¿›ç‰ˆå¿«é€Ÿæµ‹è¯•
    print("\nğŸ“ æ­¥éª¤1: æ”¹è¿›ç‰ˆå¿«é€Ÿæµ‹è¯•å•ä¸ªåŸå¸‚")
    quick_result = quick_test_improved_single_city()

    if quick_result:
        print("\nğŸ“ æ­¥éª¤2: æ”¹è¿›ç‰ˆæ‰¹é‡å¤„ç†æ‰€æœ‰åŸå¸‚")
        batch_results = process_all_uk_cities_improved()

        if batch_results:
            successful = [r for r in batch_results if r.get('success', False)]
            print(f"\nğŸ‰ æ”¹è¿›ç‰ˆè‹±å›½åŸå¸‚æ£€æµ‹å®Œæˆ!")
            print(f"   æˆåŠŸå¤„ç†: {len(successful)} ä¸ªåŸå¸‚")

            if successful:
                avg_score = np.mean([r['overall_score'] for r in successful])
                avg_boundary = np.mean([r['boundary_quality'] for r in successful])
                avg_false_ratio = np.mean([r['false_coastline_ratio'] for r in successful])
                best_city = max(successful, key=lambda x: x['overall_score'])

                print(f"   å¹³å‡è´¨é‡å¾—åˆ†: {avg_score:.3f}")
                print(f"   å¹³å‡è¾¹ç•Œè´¨é‡: {avg_boundary:.3f}")
                print(f"   å¹³å‡å‡æµ·å²¸çº¿æ¯”ä¾‹: {avg_false_ratio:.1%}")
                print(f"   æœ€ä½³åŸå¸‚: {best_city['city_name']} (å¾—åˆ†: {best_city['overall_score']:.3f})")

                print(f"\nğŸš€ åº”ç”¨çš„å…³é”®æ”¹è¿›:")
                print(f"   â€¢ å…¨å›¾æ£€æµ‹è¦†ç›– (ä¸å†å±€é™äºä¸­é—´1/3)")
                print(f"   â€¢ è¾¹ç•Œæ„ŸçŸ¥DQNå¼•å¯¼")
                print(f"   â€¢ NDWIå…‰è°±éªŒè¯")
                print(f"   â€¢ å‡æµ·å²¸çº¿è¿‡æ»¤")
                print(f"   â€¢ å¢å¼ºè¿é€šæ€§åˆ†æ")

                return {
                    'quick_test': quick_result,
                    'batch_results': batch_results,
                    'summary': {
                        'total_successful': len(successful),
                        'average_score': avg_score,
                        'average_boundary_quality': avg_boundary,
                        'average_false_coastline_ratio': avg_false_ratio,
                        'best_city': best_city,
                        'improvements_applied': [
                            'Full image detection',
                            'Boundary-aware DQN guidance',
                            'NDWI spectral validation',
                            'False coastline filtering',
                            'Enhanced connectivity analysis'
                        ]
                    }
                }

    return None


if __name__ == "__main__":
    # å¯ä»¥é€‰æ‹©äº¤äº’å¼æˆ–ç›´æ¥æ‰§è¡Œ

    # æ–¹å¼1: äº¤äº’å¼èœå•ï¼ˆæ”¹è¿›ç‰ˆï¼‰
    # main_improved()

    # æ–¹å¼2: ç›´æ¥æ‰§è¡Œæ”¹è¿›ç‰ˆæµ‹è¯•
    #test_improved_uk_cities_directly()

    # æ–¹å¼3: ä»…å¿«é€Ÿæµ‹è¯•
     quick_test_improved_single_city()

# ==================== ä½¿ç”¨è¯´æ˜ ====================
"""
æ”¹è¿›ç‰ˆä½¿ç”¨è¯´æ˜ï¼š

1. ä¸»è¦æ”¹è¿›å†…å®¹ï¼š
   - å…¨å›¾æ£€æµ‹ï¼šä¸å†å±€é™äºä¸­é—´1/3åŒºåŸŸï¼Œè¦†ç›–æ•´ä¸ªå›¾åƒ
   - è¾¹ç•Œæ„ŸçŸ¥ï¼šä½¿ç”¨è¾¹ç•Œç½®ä¿¡åº¦å›¾æŒ‡å¯¼DQNå†³ç­–
   - NDWIå…‰è°±åˆ†æï¼šç»“åˆå½’ä¸€åŒ–å·®åˆ†æ°´æŒ‡æ•°è¿›è¡Œæ°´é™†åˆ†å‰²
   - å‡æµ·å²¸çº¿è¿‡æ»¤ï¼šç§»é™¤æ·±æ°´åŒºåŸŸçš„é”™è¯¯æ£€æµ‹
   - å¢å¼ºè¾¹ç¼˜æ£€æµ‹ï¼šç»“åˆå¤šç§è¾¹ç¼˜æ£€æµ‹ç®—æ³•
   - æ”¹è¿›è´¨é‡è¯„ä¼°ï¼šæ–°å¢è¾¹ç•Œè´¨é‡ã€NDWIä¸€è‡´æ€§ç­‰æŒ‡æ ‡

2. å…³é”®æŠ€æœ¯ç‰¹æ€§ï¼š
   - BoundaryAwareHSVSupervisorï¼šè¾¹ç•Œæ„ŸçŸ¥HSVç›‘ç£å™¨
   - ImprovedConstrainedActionSpaceï¼šæ”¹è¿›çš„çº¦æŸåŠ¨ä½œç©ºé—´
   - FalseCoastlineFilterï¼šå‡æµ·å²¸çº¿è¿‡æ»¤å™¨
   - ImprovedCoastlineEnvironmentï¼šå…¨å›¾æ£€æµ‹ç¯å¢ƒ
   - ImprovedConstrainedCoastlineDQNï¼šæ”¹è¿›çš„DQNç½‘ç»œ

3. è´¨é‡è¯„ä¼°æ”¹è¿›ï¼š
   - boundary_qualityï¼šè¾¹ç•Œè´¨é‡è¯„ä¼°
   - ndwi_consistencyï¼šNDWIä¸€è‡´æ€§æ£€æŸ¥
   - false_coastline_ratioï¼šå‡æµ·å²¸çº¿æ¯”ä¾‹
   - edge_consistencyï¼šè¾¹ç¼˜ä¸€è‡´æ€§
   - å…¨å›¾åˆ†å¸ƒåˆ†æï¼ˆå››ä¸ªè±¡é™ï¼‰

4. è¿è¡Œæ–¹å¼ï¼š
   - ç›´æ¥è¿è¡Œè„šæœ¬ï¼šæ‰§è¡Œtest_improved_uk_cities_directly()
   - äº¤äº’å¼è¿è¡Œï¼šæ‰§è¡Œmain_improved()
   - å¿«é€Ÿæµ‹è¯•ï¼šæ‰§è¡Œquick_test_improved_single_city()

5. è¾“å‡ºç›®å½•ï¼š
   - ./uk_cities_improved_results/ï¼šæ”¹è¿›ç‰ˆæ‰¹é‡å¤„ç†ç»“æœ
   - ./quick_test_improved_uk/ï¼šæ”¹è¿›ç‰ˆå¿«é€Ÿæµ‹è¯•ç»“æœ

6. é¢„æœŸæ”¹è¿›æ•ˆæœï¼š
   - æ£€æµ‹ç²¾åº¦æå‡ï¼šè¾¹ç•Œæ›´ç²¾ç¡®ï¼Œå‡å°‘åšè¾¹ç•Œé—®é¢˜
   - å‡é˜³æ€§é™ä½ï¼šå‡å°‘æµ·æ´‹åŒºåŸŸå†…çš„é”™è¯¯æµ·å²¸çº¿
   - è¦†ç›–èŒƒå›´æ‰©å¤§ï¼šå…¨å›¾æ£€æµ‹è€Œéå±€éƒ¨åŒºåŸŸ
   - è´¨é‡è¯„ä¼°å®Œå–„ï¼šå¤šç»´åº¦è¯„ä¼°æŒ‡æ ‡

7. å…¼å®¹æ€§è¯´æ˜ï¼š
   - æ”¯æŒåŸæœ‰çš„é¢„è®­ç»ƒæ¨¡å‹
   - å‘åå…¼å®¹åŸå§‹æ•°æ®æ ¼å¼
   - å¯ä¸åŸç‰ˆç»“æœè¿›è¡Œå¯¹æ¯”åˆ†æ
"""